

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&#34;auto&#34;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="懂一点点">
  <meta name="author" content="Gotcha">
  <meta name="keywords" content="">
  
  <title>大数据基础 - Gotcha的笔记总结</title>

  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/github-markdown-css@4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@10.4.0/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css" />
  



<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_ba1fz6golrf.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.8.11","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"copy_btn":true,"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"baidu":"cd190160b5401a029cee361d013e32a1","google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"U8yaiFQ2fUef4ujWTig83mSL-gzGzoHsz","app_key":"akCMytdeJqrMuKP84F4oblqz","server_url":"https://u8yaifq2.lc-cn-n1-shared.com"}},"search_path":"/local-search.xml"};
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.4.0"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Gotcha的笔记总结</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner" id="banner" parallax=true
         style="background: url('/img/background/01.jpg') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="page-header text-center fade-in-up">
            <span class="h2" id="subtitle" title="大数据基础">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2021-01-04 00:00" pubdate>
        2021年1月4日 凌晨
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      32.3k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      1084
       分钟
    </span>
  

  
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">大数据基础</h1>
            
              <p class="note note-info">
                
                  本文最后更新于：2021年1月14日 凌晨
                
              </p>
            
            <div class="markdown-body">
              <h1 id="一、概述"><a href="#一、概述" class="headerlink" title="一、概述"></a>一、概述</h1><p>对于“大数据”（Big data）研究机构Gartner给出了这样的定义。“大数据”是需要新处理模式才能具有更强的决策力、洞察发现力和流程优化能力来适应海量、高增长率和多样化的信息资产。</p>
<p>麦肯锡全球研究所给出的定义是：一种规模大到在获取、存储、管理、分析方面大大超出了传统数据库软件工具能力范围的数据集合，<strong>具有海量的数据规模</strong>、<strong>快速的数据流转</strong>、<strong>多样的数据类型</strong>和<strong>价值密度低</strong>四大特征</p>
<h2 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h2><h3 id="搭建流程"><a href="#搭建流程" class="headerlink" title="搭建流程"></a>搭建流程</h3><ol>
<li><p>创建虚拟机</p>
<ul>
<li>安装虚拟机 VMWare</li>
<li>创建虚拟机</li>
<li>安装 CentOS</li>
<li>组成集群</li>
</ul>
</li>
<li><p>配置每台主机</p>
<ul>
<li>关闭防火墙</li>
<li>关闭 SELinux</li>
<li>设置主机名</li>
<li>重启</li>
<li>设置时钟同步服务</li>
<li>配置用户权限</li>
<li>免密登录</li>
</ul>
</li>
<li><p>安装辅助软件</p>
<ul>
<li>JDK</li>
<li>Zookeeper</li>
</ul>
</li>
<li><p>安装 Hadoop</p>
<ul>
<li><p>下载并解压</p>
</li>
<li><p>修改配置</p>
</li>
<li><p>分发到每个节点</p>
</li>
<li><p>格式化 HDFS</p>
</li>
<li><p>启动集群</p>
</li>
</ul>
</li>
</ol>
<hr>
<h3 id="创建虚拟机"><a href="#创建虚拟机" class="headerlink" title="创建虚拟机"></a>创建虚拟机</h3><ul>
<li>安装完成虚拟机与CentOS后，对<strong>VmWare生成的网关地址</strong>进行配置，使用NAT模式</li>
</ul>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/1.2.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="网络模式"><a href="#网络模式" class="headerlink" title="网络模式"></a>网络模式</h4><h5 id="桥接"><a href="#桥接" class="headerlink" title="桥接"></a>桥接</h5><ul>
<li>把虚拟出来的网卡直接连接外部的路由器， 看起来就好像是网络中多出了一台真正的计算机一样</li>
<li>从路由器来看， 虚拟机等同于局域网内其它的物理机</li>
</ul>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/1.3.png" srcset="/img/loading.gif" lazyload></p>
<h5 id="NAT"><a href="#NAT" class="headerlink" title="NAT"></a>NAT</h5><p>NAT（Network Address Translation，网络地址转换），借助于NAT，私有地址的”内部”网络通过路由器发送数据包时，私有地址被转换成合法的IP地址，一个局域网只需使用少量IP地址（甚至是1个）即可实现私有地址网络内所有计算机与Internet的通信需求。</p>
<p>NAT将自动修改IP报文的源IP地址和目的IP地址，Ip地址校验则在NAT处理过程中自动完成。有些应用程序将源IP地址嵌入到IP报文的数据部分中，所以还需要同时对报文的数据部分进行修改，以匹配IP头中已经修改过的源IP地址。否则，在报文数据部分嵌入IP地址的应用程序就不能正常工作。</p>
<ul>
<li>在宿主机中创建一个子网， 把虚拟机放入子网中， 子网中有一个NAT服务</li>
</ul>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/1.4.png" srcset="/img/loading.gif" lazyload></p>
<h5 id="仅主机"><a href="#仅主机" class="headerlink" title="仅主机"></a>仅主机</h5><ul>
<li>创建子网， 把虚拟机放入这个子网</li>
</ul>
<h4 id="其他设置"><a href="#其他设置" class="headerlink" title="其他设置"></a>其他设置</h4><ul>
<li>在分配<strong>内存</strong>的时候， 需要在总内存大小的基础上，减去2-4G作为物理机系统内存，，剩余的除以3，作为每台虚拟机的内存<ul>
<li>此台物理PC内存24G，我建立了三个虚拟机，内存都设置的4G</li>
</ul>
</li>
<li>在分配<strong>硬盘</strong>的时候，选用默认的40G</li>
</ul>
<h3 id="物理机网络适配器配置"><a href="#物理机网络适配器配置" class="headerlink" title="物理机网络适配器配置"></a>物理机网络适配器配置</h3><p>对物理机中虚拟机网络适配器进行设置，IP设为静态IP，<strong>与VmWare生成的网关地址放在同一个子网内</strong></p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/1.10.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="集群规划"><a href="#集群规划" class="headerlink" title="集群规划"></a>集群规划</h3><table>
<thead>
<tr>
<th>IP</th>
<th>主机名</th>
<th>环境配置</th>
<th>安装</th>
</tr>
</thead>
<tbody><tr>
<td>192.168.127.110</td>
<td>node01</td>
<td>关防火墙和selinux, host映射, 时钟同步</td>
<td>JDK, NameNode, ResourceManager, Zookeeper</td>
</tr>
<tr>
<td>192.168.127.120</td>
<td>node02</td>
<td>关防火墙和selinux, host映射, 时钟同步</td>
<td>JDK, DataNode, NodeManager, Zeekeeper</td>
</tr>
<tr>
<td>192.168.127.130</td>
<td>node03</td>
<td>关防火墙和selinux, host映射, 时钟同步</td>
<td>JDK, DataNode, NodeManager, Zeekeeper</td>
</tr>
</tbody></table>
<h4 id="设置MAC地址"><a href="#设置MAC地址" class="headerlink" title="设置MAC地址"></a>设置MAC地址</h4><ul>
<li>分别找到每一台虚拟机MAC地址，并在虚拟机<code>/etc/udev/rules.d/70-persistent-net.rules</code>文件下配置<ul>
<li>  <code>vim /etc/udev/rules.d/70-persistent-net.rules</code></li>
</ul>
</li>
</ul>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/1.5.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/1.6.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="设置IP地址"><a href="#设置IP地址" class="headerlink" title="设置IP地址"></a>设置IP地址</h4><p>分别在每一台虚拟机的<code>/etc/sysconfig/network-scripts/ifcfg-eth0</code>文件下配置IP地址</p>
<ul>
<li>  <code>vim /etc/sysconfig/network-scripts/ifcfg-eth0</code></li>
</ul>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/1.7.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="设置主机名"><a href="#设置主机名" class="headerlink" title="设置主机名"></a>设置主机名</h4><p>分别在每一台虚拟机的<code>/ect/sysconfig/network</code>文件下配置主机名</p>
<ul>
<li><code>vim /ect/sysconfig/network</code></li>
</ul>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/1.8.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="设置IP与域名映射"><a href="#设置IP与域名映射" class="headerlink" title="设置IP与域名映射"></a>设置IP与域名映射</h4><p>分别在每一台虚拟机的<code>/ect/hosts</code>文件下配置IP与域名映射关系</p>
<ul>
<li>  <code>vim /etc/hosts</code></li>
</ul>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/1.9.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="环境配置"><a href="#环境配置" class="headerlink" title="环境配置"></a>环境配置</h2><h3 id="虚拟机关闭防火墙"><a href="#虚拟机关闭防火墙" class="headerlink" title="虚拟机关闭防火墙"></a>虚拟机关闭防火墙</h3><p>三台机器执行以下命令（root用户来执行）</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">service iptables stop   #关闭防火墙<br>chkconfig iptables off  #禁止开机启动<br></code></pre></td></tr></table></figure>

<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/1.11.png" srcset="/img/loading.gif" lazyload></p>
<blockquote>
<p>关闭防火墙时，如果提示下图</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/image-20211104092404746.png" srcset="/img/loading.gif" lazyload alt="image-20211104092404746"></p>
<p>是因为centos7后是使用的基于iptable的systemctl stop firewalld</p>
<p>解决方法：</p>
<p><code>yum install iptables-services</code></p>
<p>查看防火墙状态</p>
<figure class="highlight ada"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ada">firewall-cmd <span class="hljs-comment">--state</span><br></code></pre></td></tr></table></figure>

<p>停止firewall</p>
<figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arduino">systemctl stop firewalld.service<br></code></pre></td></tr></table></figure>

<p>禁止firewall开机启动</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs routeros">systemctl <span class="hljs-builtin-name">disable</span> firewalld.service<br></code></pre></td></tr></table></figure>
</blockquote>
<h3 id="虚拟机关闭selinux"><a href="#虚拟机关闭selinux" class="headerlink" title="虚拟机关闭selinux"></a>虚拟机关闭selinux</h3><ul>
<li>什么是SELinux<ul>
<li>SELinux是Linux的一种安全子系统</li>
<li>Linux中的权限管理是针对于文件的， 而不是针对进程的， 也就是说， 如果root启动了某个进程， 则这个进程可以操作任何一个文件</li>
<li>SELinux在Linux的文件权限之外， 增加了对进程的限制， 进程只能在进程允许的范围内操作资源</li>
</ul>
</li>
<li>为什么要关闭SELinux<ul>
<li>如果开启了SELinux， 需要做非常复杂的配置， 才能正常使用系统， 在学习阶段， 在非生产环境， 一般不使用SELinux</li>
</ul>
</li>
<li>SELinux的工作模式<ul>
<li><code>enforcing</code> 强制模式</li>
<li><code>permissive</code> 宽容模式</li>
<li><code>disable</code> 关闭</li>
</ul>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 修改selinux的配置文件</span><br>vi /etc/selinux/config<br></code></pre></td></tr></table></figure>

<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/1.12.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="虚拟机免密码登录"><a href="#虚拟机免密码登录" class="headerlink" title="虚拟机免密码登录"></a>虚拟机免密码登录</h3><ul>
<li><strong>为什么要免密登录</strong><ul>
<li>Hadoop 节点众多， 所以一般在主节点启动从节点， 这个时候就需要程序自动在主节点登录到从节点中， 如果不能免密就每次都要输入密码， 非常麻烦</li>
</ul>
</li>
<li><strong>免密 SSH 登录的原理</strong><ol>
<li>需要先在 B节点 配置 A节点 的公钥</li>
<li>A节点 请求 B节点 要求登录</li>
<li>B节点 使用 A节点 的公钥， 加密一段随机文本</li>
<li>A节点 使用私钥解密， 并发回给 B节点</li>
<li>B节点 验证文本是否正确</li>
</ol>
</li>
</ul>
<p><strong>第一步：三台机器生成公钥与私钥</strong></p>
<p>在三台机器执行以下命令，生成公钥与私钥</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">ssh-keygen -t rsa<br></code></pre></td></tr></table></figure>

<p>执行该命令之后，按下三个回车即可</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/1.13.png" srcset="/img/loading.gif" lazyload></p>
<p><strong>第二步：拷贝公钥到同一台机器</strong></p>
<p>三台机器将拷贝公钥到第一台机器</p>
<p>三台机器执行命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">ssh-copy-id node01<br></code></pre></td></tr></table></figure>

<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/1.14.png" srcset="/img/loading.gif" lazyload></p>
<p> <strong>第三步:复制第一台机器的认证到其他机器</strong></p>
<p>将第一台机器的公钥拷贝到其他机器上</p>
<p>在第一台机器上面指向以下命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">scp /root/.ssh/authorized_keys node02:/root/.ssh<br><br>scp /root/.ssh/authorized_keys node03:/root/.ssh<br></code></pre></td></tr></table></figure>

<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/1.15.png" srcset="/img/loading.gif" lazyload></p>
<p>从node01进行远程登录，验证配置是否成功</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/1.16.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="虚拟机时钟同步"><a href="#虚拟机时钟同步" class="headerlink" title="虚拟机时钟同步"></a>虚拟机时钟同步</h3><p>为什么需要时间同步</p>
<ul>
<li><p>因为很多分布式系统是有状态的， 比如说存储一个数据， A节点 记录的时间是 1， B节点 记录的时间是 2， 就会出问题</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># 安装</span></span><br>yum install -y ntp<br><span class="hljs-meta"></span><br><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># 启动定时任务</span></span><br>crontab -e<br></code></pre></td></tr></table></figure>

<p>随后在输入界面键入</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">*/1 * * * * /usr/sbin/ntpdate ntp4.aliyun.com;<br></code></pre></td></tr></table></figure>



<h3 id="JDK安装"><a href="#JDK安装" class="headerlink" title="JDK安装"></a>JDK安装</h3><p> 查看自带的openjdk</p>
<p><code>rpm -qa | grep java</code></p>
<p>卸载系统自带的openjdk</p>
<p><code>rpm -e java-1.6.0-openjdk-1.6.0.41-1.13.13.1.el6_8.x86_64 tzdata-java-2016j-1.el6.noarch java-1.7.0-openjdk-1.7.0.131-2.6.9.0.el6_8.x86_64 --nodeps</code></p>
<p>上传jdk并解压然后配置环境变量</p>
<p>所有软件的安装路径</p>
<p><code>mkdir -p /export/servers</code></p>
<p>所有软件压缩包的存放路径</p>
<p><code>mkdir -p /export/softwares</code></p>
<p>上传jdk到/export/softwares路径下去，并解压</p>
<p><code>tar -zxvf jdk-8u141-linux-x64.tar.gz -C ../servers/</code></p>
<p>配置环境变量</p>
<p><code>vim /etc/profile</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">export JAVA_HOME=/export/servers/jdk1.8.0_141<br>export PATH=:$JAVA_HOME/bin:$PATH<br></code></pre></td></tr></table></figure>

<p>修改完成之后执行<code>source /etc/profile</code>生效</p>
<h1 id="二、Zookeeper"><a href="#二、Zookeeper" class="headerlink" title="二、Zookeeper"></a>二、Zookeeper</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><ul>
<li>Zookeeper 是一个开源的分布式协调服务框架 ，主要用来解决分布式集群中 应用系统的一致性问题</li>
<li>Zookeeper 是 Google Chubby 思想的一个开源实现</li>
<li>Zookeeper 本质上是一个分布式文件系统， 适合存放小文件， 通过文件系统来实现分布式协调</li>
</ul>
<p>它是一个分布式服务框架，是Apache Hadoop 的一个子项目，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，如：统一命名服务、状态同步服务、集群管理、分布式应用配置项的管理等。简单来说<strong>zookeeper=文件系统+监听通知机制</strong>。</p>
<h3 id="Zookeeper是分布式的"><a href="#Zookeeper是分布式的" class="headerlink" title="Zookeeper是分布式的"></a>Zookeeper是分布式的</h3><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/2.1.png" srcset="/img/loading.gif" lazyload></p>
<p>在上图左侧，Zookeeper 中存储的其实是一个又一个 Znode， Znode 是 Zookeeper 中的节点</p>
<ul>
<li>Znode是<strong>有路径</strong>的，例如 <code>/data/host1</code>，<code>/data/host2</code>，这个路径也可以理解为是 Znode 的 Name</li>
<li>Znode也<strong>可以携带数据</strong>， 例如说某个 Znode 的路径是 <code>/data/host1</code>，其值是一个字符串 <code>&quot;192.168.0.1&quot;</code></li>
</ul>
<p>正因为 Znode 的特性，所以 Zookeeper 可以对外提供出一个类似于文件系统的视图， 可以通过操作文件系统的方式操作 Zookeeper，如下图</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/2.1.1.png" srcset="/img/loading.gif" lazyload></p>
<p>Zookeeper 分为服务端和客户端的， 客户端有 Java 的客户端，有 Shell 命令行的客户端等，客户端通过一个类似于文件系统的 API 来访问 Zookeeper集群。但是事实上， 客户端最终是直接访问 Zookeeper 集群。 集群中有两大类角色， 一类是<strong>Leader</strong>，一类是<strong>Follower</strong>，其实就是主从的思想。<strong>Leader负责读和写</strong>，<strong>Follower只能读</strong>，遇到会产生修改的请求会转发给Leader 处理，这是因为Zookeeper 质上就是为了在分布式环境中对<strong>消息的一致性</strong>的支持， Zookeeper 所基于的ZAB协议是Paxos协议的一个变种，ZAB 协议中有一个全局的事务生成者，就是 Leader。因此修改设计在分布式环境下对事务达成一致， 必须由 Leader 发起</p>
<h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><ul>
<li>发布订阅</li>
<li>命名服务</li>
<li>分布式锁</li>
<li>分布式协调</li>
</ul>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><h3 id="集群规划-1"><a href="#集群规划-1" class="headerlink" title="集群规划"></a>集群规划</h3><table>
<thead>
<tr>
<th>服务器IP</th>
<th>主机名</th>
<th>myid的值</th>
</tr>
</thead>
<tbody><tr>
<td>192.168.127.110</td>
<td>node01</td>
<td>1</td>
</tr>
<tr>
<td>192.168.127.120</td>
<td>node02</td>
<td>2</td>
</tr>
<tr>
<td>192.168.127.130</td>
<td>node03</td>
<td>3</td>
</tr>
</tbody></table>
<h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h3><ul>
<li><p><strong>第一步：下载zookeeeper的压缩包</strong></p>
<ul>
<li><p><a target="_blank" rel="noopener" href="http://archive.apache.org/dist/zookeeper/">http://archive.apache.org/dist/zookeeper/</a>，使用的zk版本为3.4.9</p>
</li>
<li><p>下载完成之后，上传到的linux的/export/softwares路径下准备进行安装</p>
</li>
</ul>
</li>
<li><p><strong>第二步：解压</strong></p>
<p>解压zookeeper的压缩包到/export/servers路径下</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /export/softwares<br><br>tar -zxvf zookeeper-3.4.9.tar.gz -C ../servers/ <br></code></pre></td></tr></table></figure></li>
<li><p><strong>第三步：修改配置文件</strong></p>
<p><strong>node01</strong>修改配置文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /export/servers/zookeeper-3.4.9/conf/<br><br>cp zoo_sample.cfg zoo.cfg<br><br>mkdir -p /export/servers/zookeeper-3.4.9/zkdatas/<br></code></pre></td></tr></table></figure>

<p><code>vim  zoo.cfg</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs shell">dataDir=/export/servers/zookeeper-3.4.9/zkdatas<br><span class="hljs-meta">#</span><span class="bash"> 保留多少个快照</span><br>autopurge.snapRetainCount=3<br><span class="hljs-meta">#</span><span class="bash"> 日志多少小时清理一次</span><br>autopurge.purgeInterval=1<br><span class="hljs-meta">#</span><span class="bash"> 集群中服务器地址</span><br>server.1=node01:2888:3888<br>server.2=node02:2888:3888<br>server.3=node03:2888:3888<br></code></pre></td></tr></table></figure>

<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/2.2.png" srcset="/img/loading.gif" lazyload></p>
</li>
</ul>
<ul>
<li><strong>第四步：添加myid配置</strong></li>
</ul>
<p>在<strong>node01</strong>中</p>
<p>/export/servers/zookeeper-3.4.9/zkdatas /这个路径下创建一个文件，文件名为myid ，文件内容为1</p>
<p><code>echo 1 &gt; /export/servers/zookeeper-3.4.9/zkdatas/myid</code> </p>
<ul>
<li><p><strong>第五步：安装包分发并修改myid的值</strong></p>
<ul>
<li><p>安装包分发到其他机器</p>
<p>在node01上面执行以下两个命令</p>
<p><code>scp -r  /export/servers/zookeeper-3.4.9/ node02:/export/servers/</code></p>
<p><code>scp -r  /export/servers/zookeeper-3.4.9/ node03:/export/servers/</code></p>
</li>
<li><p>第二台机器上修改myid的值为2</p>
<p><code>echo 2 &gt; /export/servers/zookeeper-3.4.9/zkdatas/myid</code></p>
</li>
<li><p>第三台机器上修改myid的值为3<br><code>echo 3 &gt; /export/servers/zookeeper-3.4.9/zkdatas/myid</code></p>
</li>
</ul>
</li>
</ul>
<ul>
<li><p><strong>第六步：三台机器启动zookeeper服务</strong></p>
<ul>
<li><p>分别在三台设备上执行</p>
<p><code>/export/servers/zookeeper-3.4.9/bin/zkServer.sh start</code></p>
</li>
<li><p>执行如下命令检测，Zookeeper是否启动成功 </p>
<p><code>/export/servers/zookeeper-3.4.9/bin/zkServer.sh  status</code> </p>
</li>
</ul>
</li>
</ul>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/2.3.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/2.4.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="Znode"><a href="#Znode" class="headerlink" title="Znode"></a>Znode</h2><h3 id="Znode的特点"><a href="#Znode的特点" class="headerlink" title="Znode的特点"></a>Znode的特点</h3><ul>
<li>文件系统的核心是 <code>Znode</code></li>
<li>如果想要选取一个 <code>Znode</code>， 需要使用路径的形式， 例如 <code>/test1/test11</code></li>
<li><strong>Znode本身并不是文件， 也不是文件夹</strong>，Znode 因为具有一个类似于 Name 的路径， 所以可以从逻辑上实现一个树状文件系统</li>
<li>Zookeeper保证 Znode 访问的<strong>原子性</strong>， 不会出现部分 ZK 节点更新成功， 部分 ZK 节点更新失败的问题</li>
<li><code>Znode</code> 中数据是有<strong>大小限制</strong>的， 最大只能为<code>1M</code></li>
<li><code>Znode</code>是由三个部分构成<ul>
<li><code>stat</code>: 状态， Znode的权限信息， 版本等</li>
<li><code>data</code>: 数据， 每个Znode都是可以携带数据的， 无论是否有子节点</li>
<li><code>children</code>: 子节点列表</li>
</ul>
</li>
</ul>
<h3 id="Znode的类型"><a href="#Znode的类型" class="headerlink" title="Znode的类型"></a>Znode的类型</h3><ul>
<li><p>每个<code>Znode</code>有两大特性， 可以构成四种不同类型的<code>Znode</code></p>
<ul>
<li>持久性<ul>
<li><code>持久</code> 客户端断开时， 不会删除持有的Znode</li>
<li><code>临时</code> 客户端断开时， 删除所有持有的Znode， <strong>临时Znode不允许有子Znode</strong></li>
</ul>
</li>
<li>顺序性<ul>
<li><code>有序</code> 创建的Znode有先后顺序， 顺序就是在后面追加一个序列号， 序列号是由父节点管理的自增</li>
<li><code>无序</code> 创建的Znode没有先后顺序</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Znode的属性"><a href="#Znode的属性" class="headerlink" title="Znode的属性"></a>Znode的属性</h3><ul>
<li><code>dataVersion</code> 数据版本， 每次当<code>Znode</code>中的数据发生变化的时候， <code>dataVersion</code>都会自增一下</li>
<li><code>cversion</code> 节点版本， 每次当<code>Znode</code>的节点发生变化的时候， <code>cversion</code>都会自增</li>
<li><code>aclVersion</code> <code>ACL(Access Control List)</code>的版本号， 当<code>Znode</code>的权限信息发生变化的时候aclVersion会自增</li>
<li><code>zxid</code> 事务ID</li>
<li><code>ctime</code> 创建时间</li>
<li><code>mtime</code> 最近一次更新的时间</li>
<li><code>ephemeralOwner</code> 如果<code>Znode</code>为临时节点， <code>ephemeralOwner</code>表示与该节点关联的<code>SessionId</code></li>
</ul>
<h2 id="Shell-客户端操作"><a href="#Shell-客户端操作" class="headerlink" title="Shell 客户端操作"></a>Shell 客户端操作</h2><table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
<th>参数</th>
</tr>
</thead>
<tbody><tr>
<td><code>create [-s] [-e] path data acl</code></td>
<td>创建Znode</td>
<td>-s 指定是顺序节点<br>-e 指定是临时节点</td>
</tr>
<tr>
<td><code>ls path [watch]</code></td>
<td>列出Path下所有子Znode</td>
<td></td>
</tr>
<tr>
<td><code>get path [watch]</code></td>
<td>获取Path对应的Znode的数据和属性</td>
<td></td>
</tr>
<tr>
<td><code>ls2 path [watch]</code></td>
<td>查看Path下所有子Znode以及子Znode的属性</td>
<td></td>
</tr>
<tr>
<td><code>set path data [version]</code></td>
<td>更新节点</td>
<td>version 数据版本</td>
</tr>
<tr>
<td><code>delete path [version]</code></td>
<td>删除节点, 如果要删除的节点有子Znode则无法删除</td>
<td>version 数据版本</td>
</tr>
<tr>
<td><code>rmr path</code></td>
<td>删除节点, 如果有子Znode则递归删除</td>
<td></td>
</tr>
<tr>
<td>`setquota -n</td>
<td>-b val path`</td>
<td>修改Znode配额</td>
</tr>
<tr>
<td><code>history</code></td>
<td>列出历史记录</td>
<td></td>
</tr>
</tbody></table>
<ul>
<li><p>创建节点</p>
<ul>
<li><p>创建普通节点</p>
<p><code>create /app1 hello</code></p>
</li>
<li><p>创建顺序节点</p>
<p><code>create -s /app3 world</code></p>
</li>
<li><p>创建临时节点</p>
<p><code>create -e /tempnode world</code></p>
</li>
<li><p>创建顺序的临时节点<br><code>create -s -e /tempnode2 aaa</code></p>
</li>
</ul>
</li>
<li><p>获取节点数据</p>
<p><code>get /app1</code></p>
</li>
<li><p>修改节点数据</p>
<p><code>set /app1  xxx</code></p>
</li>
<li><p>删除节点</p>
<ul>
<li><p>delete /app1</p>
<p>注：删除的节点不能有子节点</p>
</li>
<li><p>rmr /app1</p>
<p>注：递归删除</p>
</li>
</ul>
</li>
</ul>
<h2 id="通知机制"><a href="#通知机制" class="headerlink" title="通知机制"></a>通知机制</h2><ul>
<li>通知类似于数据库中的触发器, 对某个Znode设置 <code>Watcher</code>, 当Znode发生变化的时候, <code>WatchManager</code>会调用对应的<code>Watcher</code></li>
<li>当Znode发生删除, 修改, 创建, 子节点修改的时候, 对应的<code>Watcher</code>会得到通知</li>
<li><code>Watcher</code>的特点<ul>
<li><strong>一次性触发</strong> 一个 <code>Watcher</code> 只会被触发一次, 如果需要继续监听, 则需要再次添加 <code>Watcher</code></li>
<li>事件封装: <code>Watcher</code> 得到的事件是被封装过的, 包括三个内容 <code>keeperState, eventType, path</code></li>
</ul>
</li>
</ul>
<table>
<thead>
<tr>
<th>KeeperState</th>
<th>EventType</th>
<th>触发条件</th>
<th>说明</th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td>None</td>
<td>连接成功</td>
<td></td>
</tr>
<tr>
<td>SyncConnected</td>
<td>NodeCreated</td>
<td>Znode被创建</td>
<td>此时处于连接状态</td>
</tr>
<tr>
<td>SyncConnected</td>
<td>NodeDeleted</td>
<td>Znode被删除</td>
<td>此时处于连接状态</td>
</tr>
<tr>
<td>SyncConnected</td>
<td>NodeDataChanged</td>
<td>Znode数据被改变</td>
<td>此时处于连接状态</td>
</tr>
<tr>
<td>SyncConnected</td>
<td>NodeChildChanged</td>
<td>Znode的子Znode数据被改变</td>
<td>此时处于连接状态</td>
</tr>
<tr>
<td>Disconnected</td>
<td>None</td>
<td>客户端和服务端断开连接</td>
<td>此时客户端和服务器处于断开连接状态</td>
</tr>
<tr>
<td>Expired</td>
<td>None</td>
<td>会话超时</td>
<td>会收到一个SessionExpiredException</td>
</tr>
<tr>
<td>AuthFailed</td>
<td>None</td>
<td>权限验证失败</td>
<td>会收到一个AuthFailedException</td>
</tr>
</tbody></table>
<p><strong>会话</strong></p>
<ul>
<li>在ZK中所有的客户端和服务器的交互都是在某一个<code>Session</code>中的, 客户端和服务器创建一个连接的时候同时也会创建一个<code>Session</code></li>
<li><code>Session</code>会在不同的状态之间进行切换: <code>CONNECTING</code>, <code>CONNECTED</code>, <code>RECONNECTING</code>, <code>RECONNECTED</code>, <code>CLOSED</code></li>
<li>ZK中的会话两端也需要进行心跳检测, 服务端会检测如果超过超时时间没收到客户端的心跳, 则会关闭连接, 释放资源, 关闭会话</li>
</ul>
<h1 id="三、Hadoop"><a href="#三、Hadoop" class="headerlink" title="三、Hadoop"></a>三、Hadoop</h1><h2 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h2><p>Hadoop是一个分布式系基础框架，它允许使用简单的编程模型跨大型计算机的大型数据集进行分布式处理.</p>
<p>它主要解决两个问题</p>
<ul>
<li>大数据<strong>存储</strong>问题： HDFS，分布式文件系统</li>
<li>大数据<strong>计算</strong>问题：MapReduce， 分布式计算系统</li>
</ul>
<p><strong>广义上来说，hadoop指代大数据的一个生态圈，包括很多其他的软件</strong></p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/3.1.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="Hadoop的组成"><a href="#Hadoop的组成" class="headerlink" title="Hadoop的组成"></a>Hadoop的组成</h2><ul>
<li><strong>Hadoop分布式文件系统(HDFS)</strong> 提供对应用程序数据的高吞吐量访问的分布式文件系统</li>
</ul>
<ul>
<li><strong>Hadoop Common</strong> 其他Hadoop模块所需的Java库和实用程序。这些库提供文件系统和操作系统级抽象，并包含启动Hadoop所需的必要Java文件和脚本</li>
<li><strong>Hadoop MapReduce</strong> 基于YARN的大型数据集并行处理系统</li>
<li><strong>Hadoop YARN</strong> 作业调度和集群资源管理的框架</li>
</ul>
<h2 id="架构模型"><a href="#架构模型" class="headerlink" title="架构模型"></a>架构模型</h2><h3 id="1-X版本架构模型"><a href="#1-X版本架构模型" class="headerlink" title="1.X版本架构模型"></a>1.X版本架构模型</h3><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/3.2.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li><p>文件系统核心模块：</p>
<ul>
<li>NameNode：集群当中的主节点，<strong>管理元数据</strong>(文件的大小，文件的位置，文件的权限)，主要用于管理集群当中的各种数据</li>
<li>secondaryNameNode：主要能用于hadoop当中元数据信息的辅助管理</li>
<li>DataNode：集群当中的从节点，主要用于<strong>存储</strong>集群当中的各种数据</li>
</ul>
</li>
<li><p>数据计算核心模块：</p>
<ul>
<li>JobTracker：接收用户的计算请求任务，并分配任务给从节点</li>
<li>TaskTracker：负责执行主节点JobTracker分配的任务</li>
</ul>
</li>
</ul>
<h3 id="2-X版本架构模型"><a href="#2-X版本架构模型" class="headerlink" title="2.X版本架构模型"></a>2.X版本架构模型</h3><h4 id="第一种：NameNode与ResourceManager单节点架构模型"><a href="#第一种：NameNode与ResourceManager单节点架构模型" class="headerlink" title="第一种：NameNode与ResourceManager单节点架构模型"></a>第一种：NameNode与ResourceManager单节点架构模型</h4><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/3.3.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li><p>文件系统核心模块：</p>
<ul>
<li>NameNode：集群当中的主节点，主要用于<strong>管理</strong>集群当中的各种数据</li>
<li>secondaryNameNode：主要能用于hadoop当中元数据信息的辅助管理</li>
<li>DataNode：集群当中的从节点，主要用于<strong>存储</strong>集群当中的各种数据</li>
</ul>
</li>
<li><p>数据计算核心模块：</p>
<ul>
<li>ResourceManager：接收用户的计算请求任务，并负责集群的资源分配</li>
<li>NodeManager：负责执行主节点APPmaster分配的任务</li>
</ul>
</li>
</ul>
<h4 id="第二种：NameNode单节点与ResourceManager高可用架构模型"><a href="#第二种：NameNode单节点与ResourceManager高可用架构模型" class="headerlink" title="第二种：NameNode单节点与ResourceManager高可用架构模型"></a>第二种：NameNode单节点与ResourceManager高可用架构模型</h4><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/3.4.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li><p>文件系统核心模块：</p>
<ul>
<li>NameNode：集群当中的主节点，主要用于管理集群当中的各种数据</li>
<li>secondaryNameNode：主要能用于hadoop当中元数据信息的辅助管理</li>
<li>DataNode：集群当中的从节点，主要用于存储集群当中的各种数据</li>
</ul>
</li>
<li><p>数据计算核心模块：</p>
<ul>
<li>ResourceManager：接收用户的计算请求任务，并负责集群的资源分配，以及计算任务的划分，<strong>通过zookeeper实现ResourceManager的高可用</strong></li>
<li>NodeManager：负责执行主节点ResourceManager分配的任务</li>
</ul>
</li>
</ul>
<h4 id="第三种：NameNode高可用与ResourceManager单节点架构模型"><a href="#第三种：NameNode高可用与ResourceManager单节点架构模型" class="headerlink" title="第三种：NameNode高可用与ResourceManager单节点架构模型"></a>第三种：NameNode高可用与ResourceManager单节点架构模型</h4><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/3.5.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li><p>文件系统核心模块：</p>
<ul>
<li>NameNode：集群当中的主节点，主要用于管理集群当中的各种数据，<strong>其中nameNode可以有两个，形成高可用状态</strong></li>
<li>DataNode：集群当中的从节点，主要用于存储集群当中的各种数据</li>
<li>JournalNode：文件系统元数据信息管理</li>
</ul>
</li>
<li><p>数据计算核心模块：</p>
<ul>
<li>ResourceManager：接收用户的计算请求任务，并负责集群的资源分配，以及计算任务的划分</li>
<li>NodeManager：负责执行主节点ResourceManager分配的任务</li>
</ul>
</li>
</ul>
<h4 id="第四种：NameNode与ResourceManager高可用架构模型"><a href="#第四种：NameNode与ResourceManager高可用架构模型" class="headerlink" title="第四种：NameNode与ResourceManager高可用架构模型"></a>第四种：NameNode与ResourceManager高可用架构模型</h4><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/3.6.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li><p>文件系统核心模块：</p>
<ul>
<li>NameNode：集群当中的主节点，主要用于管理集群当中的各种数据，一般都是<strong>使用两个，实现高可用</strong></li>
<li>JournalNode：元数据信息管理进程，一般都是奇数个</li>
<li>DataNode：从节点，用于数据的存储</li>
</ul>
</li>
<li><p>数据计算核心模块：</p>
<ul>
<li>ResourceManager：Yarn平台的主节点，主要用于接收各种任务，<strong>通过两个，构建成高可用</strong></li>
<li>NodeManager：Yarn平台的从节点，主要用于处理ResourceManager分配的任务</li>
</ul>
</li>
</ul>
<h2 id="安装-2"><a href="#安装-2" class="headerlink" title="安装"></a>安装</h2><h3 id="集群规划-2"><a href="#集群规划-2" class="headerlink" title="集群规划"></a>集群规划</h3><table>
<thead>
<tr>
<th>服务器IP</th>
<th>192.168.127.110</th>
<th>192.168.127.120</th>
<th>192.168.127.130</th>
</tr>
</thead>
<tbody><tr>
<td>主机名</td>
<td>node01</td>
<td>node02</td>
<td>node03</td>
</tr>
<tr>
<td>NameNode</td>
<td>是</td>
<td>否</td>
<td>否</td>
</tr>
<tr>
<td>SecondaryNameNode</td>
<td>是</td>
<td>否</td>
<td>否</td>
</tr>
<tr>
<td>dataNode</td>
<td>是</td>
<td>是</td>
<td>是</td>
</tr>
<tr>
<td>ResourceManager</td>
<td>是</td>
<td>否</td>
<td>否</td>
</tr>
<tr>
<td>NodeManager</td>
<td>是</td>
<td>是</td>
<td>是</td>
</tr>
</tbody></table>
<h3 id="安装-3"><a href="#安装-3" class="headerlink" title="安装"></a>安装</h3><h4 id="第一步：下载Hadoop的压缩包"><a href="#第一步：下载Hadoop的压缩包" class="headerlink" title="第一步：下载Hadoop的压缩包"></a>第一步：下载Hadoop的压缩包</h4><ul>
<li><p>使用的Hadoop版本为3.1.1</p>
</li>
<li><p>下载完成之后，上传到的linux的/export/softwares路径下准备进行安装</p>
</li>
</ul>
<h4 id="第二步：解压"><a href="#第二步：解压" class="headerlink" title="第二步：解压"></a>第二步：解压</h4><p>解压hadoop的压缩包到/export/servers路径下</p>
  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /export/softwares<br>tar xzvf hadoop-3.1.1.tar.gz  -C ../servers<br></code></pre></td></tr></table></figure>

<h4 id="第三步：修改配置文件"><a href="#第三步：修改配置文件" class="headerlink" title="第三步：修改配置文件"></a>第三步：修改配置文件</h4><p>  配置文件的位置在 <code>hadoop/etc/hadoop</code></p>
<h5 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h5>  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="hljs-meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="hljs-comment">&lt;!--</span><br><span class="hljs-comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="hljs-comment">  you may not use this file except in compliance with the License.</span><br><span class="hljs-comment">  You may obtain a copy of the License at</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">  Unless required by applicable law or agreed to in writing, software</span><br><span class="hljs-comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="hljs-comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="hljs-comment">  See the License for the specific language governing permissions and</span><br><span class="hljs-comment">  limitations under the License. See accompanying LICENSE file.</span><br><span class="hljs-comment">--&gt;</span><br><br><span class="hljs-comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span><br><br><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs://node01:8020<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-comment">&lt;!-- 临时文件存储目录 --&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/export/servers/hadoop-3.1.1/datas/tmp<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!--  缓冲区大小，实际工作中根据服务器性能动态调整 --&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>io.file.buffer.size<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>8192<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!--  开启hdfs的垃圾桶机制，删除掉的数据可以从垃圾桶中回收，单位分钟 --&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.trash.interval<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>10080<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br><br></code></pre></td></tr></table></figure>

<h5 id="hadoop-env-sh"><a href="#hadoop-env-sh" class="headerlink" title="hadoop-env.sh"></a>hadoop-env.sh</h5>  <figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">export JAVA_HOME=/export/servers/jdk1.8.0_141<br></code></pre></td></tr></table></figure>

<h5 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h5>  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;</span><br><span class="hljs-meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="hljs-comment">&lt;!--</span><br><span class="hljs-comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="hljs-comment">  you may not use this file except in compliance with the License.</span><br><span class="hljs-comment">  You may obtain a copy of the License at</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">  Unless required by applicable law or agreed to in writing, software</span><br><span class="hljs-comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="hljs-comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="hljs-comment">  See the License for the specific language governing permissions and</span><br><span class="hljs-comment">  limitations under the License. See accompanying LICENSE file.</span><br><span class="hljs-comment">--&gt;</span><br><br><span class="hljs-comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span><br><br><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- namenode元数据存放路径 --&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.name.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:///export/servers/hadoop-3.1.1/datas/namenode/namenodedatas<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 文件分块大小 --&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.blocksize<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>134217728<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.handler.count<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>10<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>     <span class="hljs-comment">&lt;!-- datanode元数据存放路径 --&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.datanode.data.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:///export/servers/hadoop-3.1.1/datas/datanode/datanodeDatas<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 浏览器访问hdfs端口 --&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.http-address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>node01:50070<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- 文件副本数 --&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>3<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- HDFS权限访问 --&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.permissions.enabled<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-comment">&lt;!-- HDFS日志存储路径 --&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.checkpoint.edits.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:///export/servers/hadoop-3.1.1/datas/dfs/nn/snn/edits<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>node01.hadoop.com:50090<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.edits.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:///export/servers/hadoop-3.1.1/datas/dfs/nn/edits<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.checkpoint.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:///export/servers/hadoop-3.1.1/datas/dfs/snn/name<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br><br></code></pre></td></tr></table></figure>

<h5 id="mapred-site-xml"><a href="#mapred-site-xml" class="headerlink" title="mapred-site.xml"></a>mapred-site.xml</h5>  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class="hljs-meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="hljs-comment">&lt;!--</span><br><span class="hljs-comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="hljs-comment">  you may not use this file except in compliance with the License.</span><br><span class="hljs-comment">  You may obtain a copy of the License at</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">  Unless required by applicable law or agreed to in writing, software</span><br><span class="hljs-comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="hljs-comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="hljs-comment">  See the License for the specific language governing permissions and</span><br><span class="hljs-comment">  limitations under the License. See accompanying LICENSE file.</span><br><span class="hljs-comment">--&gt;</span><br><br><span class="hljs-comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span><br><br><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.map.memory.mb<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>1024<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.map.java.opts<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>-Xmx512M<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.reduce.memory.mb<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>1024<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.reduce.java.opts<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>-Xmx512M<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.task.io.sort.mb<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>256<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.task.io.sort.factor<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>100<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.reduce.shuffle.parallelcopies<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>25<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>node01.hadoop.com:10020<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>node01.hadoop.com:19888<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.jobhistory.intermediate-done-dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/export/servers/hadoop-3.1.1/datas/jobhsitory/intermediateDoneDatas<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.jobhistory.done-dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/export/servers/hadoop-3.1.1/datas/jobhsitory/DoneDatas<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>	  <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.app.mapreduce.am.env<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>	  <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/export/servers/hadoop-3.1.1<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>	  <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.map.env<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>	  <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/export/servers/hadoop-3.1.1/<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>	  <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.reduce.env<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>	  <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/export/servers/hadoop-3.1.1<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure>

<h5 id="yarn-site-xml"><a href="#yarn-site-xml" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h5>  <figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=&quot;1.0&quot;?&gt;</span><br><span class="hljs-comment">&lt;!--</span><br><span class="hljs-comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="hljs-comment">  you may not use this file except in compliance with the License.</span><br><span class="hljs-comment">  You may obtain a copy of the License at</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">    http://www.apache.org/licenses/LICENSE-2.0</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">  Unless required by applicable law or agreed to in writing, software</span><br><span class="hljs-comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="hljs-comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="hljs-comment">  See the License for the specific language governing permissions and</span><br><span class="hljs-comment">  limitations under the License. See accompanying LICENSE file.</span><br><span class="hljs-comment">--&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.handler.count<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>100<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>node01:8032<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>node01:8030<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>node01:8031<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.admin.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>node01:8033<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.webapp.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>node01:8088<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>node01<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>1024<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>2048<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.vmem-pmem-ratio<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>2.1<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-comment">&lt;!-- 设置不检查虚拟内存的值，不然内存不够会报错 --&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>1024<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.resource.detect-hardware-capabilities<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.local-dirs<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:///export/servers/hadoop-3.1.1/datas/nodemanager/nodemanagerDatas<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.log-dirs<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>file:///export/servers/hadoop-3.1.1/datas/nodemanager/nodemanagerLogs<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.log.retain-seconds<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>10800<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.remote-app-log-dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/export/servers/hadoop-3.1.1/datas/remoteAppLog/remoteAppLogs<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.remote-app-log-dir-suffix<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>logs<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>18144000<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.log-aggregation.retain-check-interval-seconds<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>86400<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-comment">&lt;!-- yarn上面运行一个任务，最少需要1.5G内存，虚拟机没有这么大的内存就调小这个值，不然会报错 --&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.app.mapreduce.am.resource.mb<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>1024<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure>

<h5 id="worker"><a href="#worker" class="headerlink" title="worker"></a>worker</h5>  <figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs gcode"><span class="hljs-symbol">node01</span><br><span class="hljs-symbol">node02</span><br><span class="hljs-symbol">node03</span><br></code></pre></td></tr></table></figure>

<h4 id="第四步：创建数据和临时文件夹"><a href="#第四步：创建数据和临时文件夹" class="headerlink" title="第四步：创建数据和临时文件夹"></a>第四步：创建数据和临时文件夹</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs shell">mkdir -p /export/servers/hadoop-3.1.1/datas/tmp<br>mkdir -p /export/servers/hadoop-3.1.1/datas/dfs/nn/snn/edits<br>mkdir -p /export/servers/hadoop-3.1.1/datas/namenode/namenodedatas<br>mkdir -p /export/servers/hadoop-3.1.1/datas/datanode/datanodeDatas<br>mkdir -p /export/servers/hadoop-3.1.1/datas/dfs/nn/edits<br>mkdir -p /export/servers/hadoop-3.1.1/datas/dfs/snn/name<br>mkdir -p /export/servers/hadoop-3.1.1/datas/jobhsitory/intermediateDoneDatas<br>mkdir -p /export/servers/hadoop-3.1.1/datas/jobhsitory/DoneDatas<br>mkdir -p /export/servers/hadoop-3.1.1/datas/nodemanager/nodemanagerDatas<br>mkdir -p /export/servers/hadoop-3.1.1/datas/nodemanager/nodemanagerLogs<br>mkdir -p /export/servers/hadoop-3.1.1/datas/remoteAppLog/remoteAppLogs<br></code></pre></td></tr></table></figure>

<h4 id="第五步：分发安装包到其它机器"><a href="#第五步：分发安装包到其它机器" class="headerlink" title="第五步：分发安装包到其它机器"></a>第五步：分发安装包到其它机器</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /export/servers<br>scp -r hadoop-3.1.1/ node02:$PWD<br>scp -r hadoop-3.1.1/ node03:$PWD<br></code></pre></td></tr></table></figure>

<h4 id="第六步：在每个节点配置环境变量"><a href="#第六步：在每个节点配置环境变量" class="headerlink" title="第六步：在每个节点配置环境变量"></a>第六步：在每个节点配置环境变量</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">vi /etc/profile<br></code></pre></td></tr></table></figure>

<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">export HADOOP_HOME=/export/servers/hadoop-3.1.1/<br>export PATH=:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH<br></code></pre></td></tr></table></figure>

<p><strong>最后记得刷新配置</strong></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">source /etc/profile<br></code></pre></td></tr></table></figure>

<h4 id="第七步：格式化HDFS"><a href="#第七步：格式化HDFS" class="headerlink" title="第七步：格式化HDFS"></a>第七步：格式化HDFS</h4><p>为什么要格式化HDFS</p>
<ul>
<li>HDFS需要一个格式化的过程来创建存放元数据(image, editlog)的目录</li>
</ul>
<p>回到Hadoop主目录，执行下面命令</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">bin/hdfs namenode -format<br></code></pre></td></tr></table></figure>

<blockquote>
<p>仅在NameNode节点格式化HDFS即可</p>
</blockquote>
<h4 id="第八步：启动集群"><a href="#第八步：启动集群" class="headerlink" title="第八步：启动集群"></a>第八步：启动集群</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> 会登录进所有的worker启动相关进行, 也可以手动进行, 但是没必要</span><br>/export/servers/hadoop-3.1.1/sbin/start-dfs.sh<br>/export/servers/hadoop-3.1.1/sbin/start-yarn.sh<br>mapred --daemon start historyserver<br></code></pre></td></tr></table></figure>

<p>此时便可以通过如下三个URL访问Hadoop了</p>
<ul>
<li>HDFS: <code>http://192.168.127.110:50070/dfshealth.html#tab-overview</code></li>
<li>Yarn: <code>http://192.168.127.110:8088/cluster</code></li>
</ul>
<p>出现如下报错：对于<strong>所有节点</strong>，设置hadoop-env.sh</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/3.7.png" srcset="/img/loading.gif" lazyload></p>
<p><code>vim /export/servers/hadoop-3.1.1/etc/hadoop/hadoop-env.sh </code> </p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs shell">export HDFS_NAMENODE_USER=&quot;root&quot;<br>export HDFS_DATANODE_USER=&quot;root&quot;<br>export HDFS_SECONDARYNAMENODE_USER=&quot;root&quot;<br>export YARN_RESOURCEMANAGER_USER=&quot;root&quot;<br>export YARN_NODEMANAGER_USER=&quot;root&quot;<br></code></pre></td></tr></table></figure>



<h4 id="第九步：验证启动是否成功"><a href="#第九步：验证启动是否成功" class="headerlink" title="第九步：验证启动是否成功"></a>第九步：验证启动是否成功</h4><p><code>jps</code></p>
<ul>
<li><p>NameNode节点</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/3.8.png" srcset="/img/loading.gif" lazyload></p>
</li>
<li><p>DataNode节点</p>
</li>
</ul>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/3.9.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li><p>浏览器可以访问NameNode管理界面</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/3.10.png" srcset="/img/loading.gif" lazyload></p>
</li>
</ul>
<hr>
<h1 id="四、HDFS"><a href="#四、HDFS" class="headerlink" title="四、HDFS"></a>四、HDFS</h1><h2 id="概述-2"><a href="#概述-2" class="headerlink" title="概述"></a>概述</h2><p>HDFS（Hadoop  Distributed  File  System） 是一个 Apache Software Foundation 项目，是 Apache Hadoop 项目的一个子项目。Hadoop 非常适于存储大型数据 (比如 TB 和 PB)，其就是使用 HDFS 作为存储系统。HDFS 使用多台计算机存储文件， 并且提供统一的访问接口，像是访问一个普通文件系统一样使用分布式文件系统。HDFS 对数据文件的访问通过流的方式进行处理，这意味着通过命令和 MapReduce 程序的方式可以直接使用 HDFS。HDFS 是容错的，且提供对大数据集的高吞吐量访问。</p>
<p>HDFS 的一个非常重要的特点就是<strong>一次写入、多次读取</strong>， 该模型降低了对并发控制的要求，简化了数据聚合性，支持高吞吐量访问。而吞吐量是大数据系统的一个非常重要的指标，吞吐量高意味着能处理的数据量就大。</p>
<h3 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h3><ul>
<li>通过跨多个廉价计算机<strong>集群</strong>分布数据和处理来节约成本</li>
<li>通过自动维护多个<strong>数据副本</strong>和在故障发生时来实现可靠性</li>
<li>它们为存储和处理超大规模数据提供所需的<strong>扩展</strong>能力。</li>
</ul>
<h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/4.1.png" srcset="/img/loading.gif" lazyload></p>
<p><strong>HDFS具有主/从架构。HDFS集群由单个NameNode，和多个datanode构成。</strong></p>
<ul>
<li><p><strong>NameNode</strong>：管理文件系统命名空间的主服务器和管理客户端对文件的访问组成，如打开，关闭和重命名文件和目录。负责管理文件目录、文件和block的对应关系以及block和datanode的对应关系，维护目录树，接管用户的请求</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/4.2.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li><p>将文件的元数据保存在一个文件目录树中</p>
</li>
<li><p>在磁盘上保存为：fsimage 和 edits</p>
<ul>
<li><p><strong>fsimage</strong></p>
<ul>
<li>NameNode 中关于元数据的镜像, 一般称为检查点, <code>fsimage</code> 存放了一份比较完整的元数据信息</li>
<li>因为 <code>fsimage</code> 是 NameNode 的完整的镜像, 如果每次都加载到内存生成树状拓扑结构，这是非常耗内存和CPU, 所以一般开始时对 NameNode 的操作都放在 edits 中</li>
<li><code>fsimage</code> 内容包含了 NameNode 管理下的所有 DataNode 文件及文件 block 及 block 所在的 DataNode 的元数据信息.</li>
<li>随着 <code>edits</code> 内容增大, 就需要在一定时间点和 <code>fsimage</code> 合并</li>
</ul>
</li>
<li><p><strong>edits</strong></p>
<ul>
<li><code>edits</code> 存放了客户端最近一段时间的操作日志</li>
<li>客户端对 HDFS 进行写文件时会首先被记录在 <code>edits</code> 文件中</li>
<li><code>edits</code> 修改时元数据也会更新</li>
<li>每次 HDFS 更新时 <code>edits</code> 先更新后客户端才会看到最新信息</li>
</ul>
</li>
</ul>
</li>
<li><p>保存datanode的数据信息的文件，在系统启动的时候读入内存。</p>
</li>
</ul>
</li>
<li><p><strong>DataNode</strong>：（数据节点）管理连接到它们运行的节点的存储，负责处理来自文件系统客户端的读写请求。DataNodes还执行块创建，删除</p>
</li>
<li><p><strong>Client</strong>：(客户端)代表用户通过与nameNode和datanode交互来访问整个文件系统，HDFS对外开放文件命名空间并允许用户数据以文件形式存储。用户通过客户端（Client）与HDFS进行通讯交互。</p>
</li>
</ul>
<table>
<thead>
<tr>
<th align="left">类别</th>
<th align="left">NameNode</th>
<th align="left">DataNode</th>
</tr>
</thead>
<tbody><tr>
<td align="left">存储内容</td>
<td align="left">存储元数据</td>
<td align="left">存储文件内容</td>
</tr>
<tr>
<td align="left">存储位置</td>
<td align="left">元数据保存在<strong>内存</strong>中</td>
<td align="left">文件内容保存在磁盘</td>
</tr>
<tr>
<td align="left">作用</td>
<td align="left">保存文件, block, DataNode 之间的关系</td>
<td align="left">维护了 block id 到 DataNode 文件之间的关系</td>
</tr>
</tbody></table>
<blockquote>
<ul>
<li>副本存放在哪些 DataNode 上由 NameNode 来控制, 根据全局情况作出块放置决定, 读取文件时 NameNode 尽量让用户先读取最近的副本, 降低读取网络开销和读取延时</li>
<li>NameNode 全权管理数据库的复制, 它周期性的从集群中的每个 DataNode 接收心跳信合和状态报告, 接收到心跳信号意味着 DataNode 节点工作正常, 块状态报告包含了一个该 DataNode 上所有的数据列表</li>
</ul>
</blockquote>
<h2 id="HDFS文件副本和Block块存储"><a href="#HDFS文件副本和Block块存储" class="headerlink" title="HDFS文件副本和Block块存储"></a>HDFS文件副本和Block块存储</h2><p>所有的文件都是以<strong>block块</strong>的方式存放在 HDFS 文件系统当中, 在 Hadoop1 当中, 文件的 block 块默认大小是 64M, hadoop2 当中, 文件的 block 块大小默认是 128M, block 块的大小可以通过 hdfs-site.xml 当中的配置文件进行指定</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.block.size<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>块大小 以字节为单位<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br></code></pre></td></tr></table></figure>

<blockquote>
<p>为什么要以块的形式存储文件，而不是整个文件呢？<br>1、因为一个文件可以特别大，可以大于有个磁盘的容量，所以以块的形式存储，可以用来存储无论大小怎样的文件。<br>2、简化存储系统的设计。因为块是固定的大小，计算磁盘的存储能力就容易多了<br>3、以块的形式存储不需要全部存在一个磁盘上，可以分布在各个文件系统的磁盘上，有利于复制和容错，数据本地化计算</p>
</blockquote>
<p><strong>注意：假设一个文件 130M，一个block块128M，则文件会被切分成 2 个 block 块，实际占用磁盘 130M 空间, 而不是占用256M的磁盘空间</strong></p>
<h3 id="块缓存"><a href="#块缓存" class="headerlink" title="块缓存"></a>块缓存</h3><p>通常 DataNode 从磁盘中读取块， 但对于访问频繁的文件， 其对应的块可能被显式的缓存在 DataNode 的内存中，以堆外块缓存的形式存在。默认情况下，一个块仅缓存在一个 DataNode 的内存中，当然可以针对每个文件配置 DataNode 的数量。作业调度器通过在缓存块的 DataNode 上运行任务，可以利用块缓存的优势提高读操作的性能。</p>
<h3 id="HDFS的文件权限验证"><a href="#HDFS的文件权限验证" class="headerlink" title="HDFS的文件权限验证"></a>HDFS的文件权限验证</h3><p>HDFS 的文件权限机制与 Linux 系统的文件权限机制类似</p>
<figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs lua">r:<span class="hljs-built_in">read</span>  w:<span class="hljs-built_in">write</span>  x:<span class="hljs-built_in">execute</span><br></code></pre></td></tr></table></figure>

<p>权限 <code>x</code> 对于文件表示忽略，对于文件夹表示是否有权限访问其内容</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/4.3.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="容错机制"><a href="#容错机制" class="headerlink" title="容错机制"></a>容错机制</h2><p>既然namenode管理着文件系统的命名空间，维护着文件系统树以及整颗树内的所有文件和目录，这些信息以文件的形式永远的保存在本地磁盘上，分别问命名空间镜像文件<strong>fsimage</strong>和编辑日志文件<strong>Edits</strong>。datanode是文件的工作节点，根据需要存储和检索数据块，并且定期的向namenode发送它们所存储的块的列表。那么就知道namenode是多么的重要，一旦那么namenode挂了，那整个分布式文件系统就不可以使用了，所以对于namenode的容错就显得尤为重要了，hadoop为此提供了两种<strong>容错机制</strong></p>
<h3 id="容错机制一"><a href="#容错机制一" class="headerlink" title="容错机制一"></a>容错机制一</h3><p>通过对那些组成文件系统的元数据持久化，分别问命名空间镜像文件<strong>fsimage</strong>（文件系统的目录树）和编辑日志文件<strong>Edits</strong>（针对文件系统做的修改操作记录）。磁盘上的映像FsImage就是一个Checkpoint同步点，有了一个Checkpoint之后，NameNode在相当长的时间内只是对内存中的目录映像操作，同时也对磁盘上的Edits操作，而不用对FsImage再进行操作，直到关机。下次开机的时候，NameNode要从磁盘上装载目录映像FSImage，那其实就是老的Checkpoint，也许就是上次开机后所保存的映像，而自从上次开机后直到关机为止对于文件系统的所有改变都记录在Edits文件中。将记录在Edits中的操作重演于上一次的FsImage，就得到这一次的新的映像，将其写回磁盘就是新的Checkpoint（也就是fsImage）。</p>
<p>但是这样有很大一个缺点，如果Edits很大，开机后生成原始映像的过程也会很长，所以对其进行改进：每当 Edits长到一定程度，或者每隔一定的时间，就做一次Checkpoint，但是这样就会给namenode造成很大的负荷，会影响系统的性能。于是就有了<strong>SecondaryNameNode</strong>的需要，这相当于NameNode的助理，专替NameNode做Checkpoint。当然，SecondaryNameNode的负载相比之下是偏轻的。所以如果为NameNode配上了热备份，就可以让热备份兼职，而无须再有专职的SecondaryNameNode。工作流程如下图所示：</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/4.4.png" srcset="/img/loading.gif" lazyload></p>
<p>SecondaryNameNode主要负责将NameNode中的fsImage文件和Edits文件，并合并生成新的fsImage文件，并推送给NameNode，工作流程如下：</p>
<ol>
<li>SecondaryNameNode请求主NameNode停止使用edits文件，暂时将新的写操作记录到一个新的文件中；</li>
<li>SecondaryNameNode从主NameNode获取fsimage和edits文件（通过http get）</li>
<li>SecondaryNameNode将fsimage文件载入内存，逐一执行edits文件中的操作，创建新的fsimage文件。</li>
<li>SecondaryNameNode将新的fsimage文件发送回主NameNode（使用http post）.</li>
<li>NameNode用从SecondaryNameNode接收的fsimage文件替换旧的fsimage文件；用步骤1所产生的edits文件替换旧的edits文件。同时，还更新fstime文件来记录检查点执行时间。</li>
<li>最终，主namenode拥有最新的fsimage文件和一个更小的edits文件。当namenode处在安全模式时，管理员也可调用hadoop dfsadmin –saveNameSpace命令来创建检查点。</li>
</ol>
<p>​    从上面的过程中可以清晰的看到<strong>secondarynamenode和主namenode拥有相近内存需求</strong>的原因（因为secondarynamenode也把fsimage文件载入内存）。因此，在大型集群中，secondarynamenode需要运行在一台专用机器上。</p>
<p><strong>SecondaryNameNode配置</strong></p>
<ul>
<li><p>SecondaryNameNode 在 <code>conf/masters</code> 中指定</p>
</li>
<li><p>在 masters 指定的机器上, 修改 <code>hdfs-site.xml</code></p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.http.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>host:50070<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br></code></pre></td></tr></table></figure></li>
<li><p>修改 <code>core-site.xml</code>, 这一步不做配置保持默认也可以</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-comment">&lt;!-- 多久记录一次 HDFS 镜像, 默认 1小时 --&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.checkpoint.period<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>3600<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-comment">&lt;!-- 一次记录多大, 默认 64M --&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.checkpoint.size<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>67108864<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br></code></pre></td></tr></table></figure></li>
</ul>
<h3 id="容错机制二"><a href="#容错机制二" class="headerlink" title="容错机制二"></a>容错机制二</h3><p>高可用方案</p>
<h2 id="文件存取原理"><a href="#文件存取原理" class="headerlink" title="文件存取原理"></a>文件存取原理</h2><h3 id="HDFS文件读取过程"><a href="#HDFS文件读取过程" class="headerlink" title="HDFS文件读取过程"></a>HDFS文件读取过程</h3><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/4.5.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/4.6.png" srcset="/img/loading.gif" lazyload></p>
<ol>
<li><p>Client通过FileSystem对象（DistributedFileSystem）的open()方法，通过 RPC 与 NameNode 建立通讯，来确定请求文件block所在的位置；</p>
</li>
<li><p>NameNode会判断文件是否存在，是否有权限下载</p>
</li>
<li><p>NameNode返回文件的部分或者全部block列表，对于每个block，NameNode 都会返回含有该 block 副本的 DataNode 地址；  这些返回的 DN 地址，会按照集群拓扑结构得出 DataNode 与客户端的距离，然后进行排序，排序两个规则：网络拓扑结构中距离 Client 近的排靠前；心跳机制中超时汇报的 DN 状态为 STALE，这样的排靠后；</p>
</li>
<li><p>Client 选取排序靠前的 DataNode 来读取 block，如果客户端本身就是DataNode,那么将从本地直接获取数据(短路读取特性)；</p>
<ul>
<li>底层上本质是建立 Socket Stream（FSDataInputStream），重复的调用父类 DataInputStream 的 read 方法，直到这个块上的数据读取完毕；</li>
</ul>
</li>
<li><p>当读完列表的 block 后，若文件读取还没有结束，客户端会继续向NameNode 获取下一批的 block 列表；</p>
<ul>
<li><p>读取完一个 block 都会进行 checksum 验证，如果读取 DataNode 时出现错误，客户端会通知 NameNode，然后再从下一个拥有该 block 副本的DataNode 继续读。</p>
</li>
<li><p>read 方法是并行的读取 block 信息，不是一块一块的读取；NameNode 只是返回Client请求包含块的DataNode地址，并不是返回请求块的数据；</p>
</li>
<li><p>最终读取来所有的 block 会合并成一个完整的最终文件。</p>
</li>
</ul>
</li>
</ol>
<blockquote>
<p>在读取数据的时候，如果DFSInputStream在与datanode通讯时遇到错误，它便会尝试从这个块的另外一个临近datanode读取数据。他也会记住那个故障datanode，以保证以后不会反复读取该节点上后续的块。DFSInputStream也会通过校验和确认从datanode发送来的数据是否完整。如果发现一个损坏的块， DFSInputStream就会在试图从其他datanode读取一个块的复本之前通知namenode。</p>
</blockquote>
<blockquote>
<p>在这个设计中，namenode会告知客户端每个块中最佳的datanode，并让客户端直接联系该datanode且检索数据。由于数据流分散在该集群中的所有datanode，所以这种设计会使HDFS可扩展到大量的并发客户端。同时，namenode仅需要响应位置的请求（这些信息存储在内存中，非常高效），而无需响应数据请求，</p>
</blockquote>
<h3 id="HDFS文件写入过程"><a href="#HDFS文件写入过程" class="headerlink" title="HDFS文件写入过程"></a>HDFS文件写入过程</h3><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/4.7.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/4.8.png" srcset="/img/loading.gif" lazyload></p>
<ol>
<li><p>Client 通过DistributedFileSystem上的create()方法发起文件上传请求，通过 RPC 与 NameNode 建立通讯，指明预创建文件名</p>
</li>
<li><p>NameNode 检查目标文件是否已存在，父目录是否存在，是否有创建权限</p>
</li>
<li><p>返回是否可以上传</p>
</li>
<li><p>Client 请求第一个block该传输到哪些 DataNode 服务器上</p>
</li>
<li><p>NameNode根据dataNode信息池检测可以上传的dateNode列表</p>
<ul>
<li>NameNode 根据配置文件中指定的备份数量及机架感知原理进行文件分配，返回可用的 DataNode 的地址如: A，B，C</li>
<li>Hadoop 在设计时考虑到数据的安全与高效，数据文件默认在 HDFS 上存放三份，存储策略为本地一份，同机架内其它某一节点上一份，不同机架的某一节点上一份。</li>
</ul>
</li>
<li><p>将dateNode列表返回给client</p>
</li>
<li><p>Client 请求 3 台 DataNode 中的一台 A 上传数据（本质上是一个 RPC 调用，建立 pipeline ）, A 收到请求会继续调用 B，然后 B 调用 C，将整个 pipeline 建立完成，后逐级返回 client</p>
</li>
<li><p>Client 开始往 A 上传第一个 block（先从磁盘读取数据放到一个本地内存缓存），数据被分割成一个个 packet（默认64K） 数据包在 pipeline 上依次传输，A 收到一个 packet 就会传给 B，B 传给 C。 A 每传一个 packet 会放入一个应答队列等待应答</p>
</li>
<li><p>各个dataNode将数据保存到某一个目录下</p>
</li>
<li><p>在 pipeline 反方向上，dataNode逐个发送 ack（命令正确应答），最终由 pipeline 中第一个 DataNode 节点 A 将 pipeline ack 发送给 Client</p>
</li>
<li><p>当一个 block 传输完成之后，Client 再次请求 NameNode 上传第二个 block 到服务 1</p>
</li>
</ol>
<blockquote>
<p>如果某个datanode在写数据的时候当掉了，下面这些对用户透明的步骤会被执行：</p>
<ul>
<li><p>管道线关闭，所有确认队列上的数据会被挪到数据队列的首部重新发送，这样可以确保管道线中当掉的datanode下流的datanode不会因为当掉的datanode而丢失数据包。</p>
</li>
<li><p>在还在正常运行的datanode上的当前block上做一个标志，这样当当掉的datanode重新启动以后namenode就会知道该datanode上哪个block是刚才当机时残留下的局部损坏block，从而可以把它删掉。</p>
</li>
<li><p>已经当掉的datanode从管道线中被移除，未写完的block的其他数据继续被写入到其他两个还在正常运行的datanode中去，namenode知道这个block还处在under-replicated状态（也即备份数不足的状态）下，然后他会安排一个新的replica从而达到要求的备份数，后续的block写入方法同前面正常时候一样。有可能管道线中的多个datanode当掉（虽然不太经常发生），但只要dfs.replication.min（默认为1）个replica被创建，我们就认为该创建成功了。剩余的replica会在以后异步创建以达到指定的replica数。</p>
</li>
</ul>
</blockquote>
<blockquote>
<p>hdfs写入过程中，datanode管线的确认应答包并不是每写完一个datanode，就返回一个确认应答，而是<strong>一直写入，直到最后一个datanode写入完毕后，统一返回应答包</strong>。如果中间的一个datanode出现故障，那么返回的应答就是前面完好的datanode确认应答，和故障datanode的故障异常。</p>
<p>这样我们也就可以理解，在写入数据的过程中，为什么数据包的校验是在最后一个datanode完成。</p>
</blockquote>
<h2 id="HDFS命令行"><a href="#HDFS命令行" class="headerlink" title="HDFS命令行"></a>HDFS命令行</h2><p>语法：<code>hdfs dfs 参数</code></p>
<p>或替换为<code>hadoop fs 参数</code></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs shell">hdfs dfs -help 		#帮助<br>hdfs dfs -ls / 		#显示根目录信息<br>hdfs dfs -mkdir -p /xx/xxx	#在hdfs上递归创建目录<br>hdfs dfs -moveFromLocal test.txt /user/data	 	#从本地剪切粘贴到hdfs<br>hdfs dfs -appendTofile test.txt /user/test.txt 	#追加一个文件到已经存在的文件末尾<br>hdfs dfs -cat xx	#显示文件内容<br>hdfs dfs -tail xx	#显示一个文件的末尾<br>hdfs dfs -cp /user/x.txt /user/test		 #从hdfs的一个路径拷贝到hdfs的另一个路径<br>hdfs dfs -mv /user/x.txt /user/test		 #在hdfs目录中移动文件<br>hdfs dfs -get /user/x.txt ./				 #等同于copyToLocal,就是从hdfs下载文件到本地<br>hdfs dfs -getmerge /user//test/* ./test.txt #合并下载多个文件<br>hdfs dfs -put 		#等同于copyFromLocal上传<br>hdfs dfs -rm [-r] 	#递归删除文件或文件夹<br>hdfs dfs -rmdir 	#删除空目录<br>hdfs dfs -df 		#统计文件系统的可用空间<br>hdfs dfs -du #		统计文件的大小信息<br>hdfs dfs -setrep 	#设置hdfs中文件的副本量数<br><span class="hljs-meta"></span><br><span class="hljs-meta">#</span><span class="bash">权限管理命令</span><br>hdfs dfs -chmod -R 777 /xxx #修改权限<br>hdfs dfs -chown -R hadoop:hadoop /xxx	#修改用户组<br><br></code></pre></td></tr></table></figure>



<h2 id="在windows配置Hadoop运行环境"><a href="#在windows配置Hadoop运行环境" class="headerlink" title="在windows配置Hadoop运行环境"></a>在windows配置Hadoop运行环境</h2><ol>
<li>将apache-hadoop-3.1.1文件夹拷贝到一个没有中文没有空格的路径下</li>
<li>在windows配置hadoop环境变量：<code>HADOOP_HOME</code></li>
<li>在path下，新增<code>%HADOOP_HOME%\bin</code></li>
<li>将bin目录下hadoop.dll文件拷贝到<code>C:\Windows\System32</code></li>
<li>重启电脑</li>
</ol>
<h2 id="HDFS-的-API-操作"><a href="#HDFS-的-API-操作" class="headerlink" title="HDFS 的 API 操作"></a>HDFS 的 API 操作</h2><h3 id="概述-3"><a href="#概述-3" class="headerlink" title="概述"></a>概述</h3><p>在 Java 中操作 HDFS, 主要涉及以下 Class:</p>
<ul>
<li><p><code>Configuration</code></p>
<ul>
<li>该类的对象封转了客户端或者服务器的配置</li>
</ul>
</li>
<li><p><code>FileSystem</code></p>
<ul>
<li><p>该类的对象是一个文件系统对象, 可以用该对象的一些方法来对文件进行操作, 通过 FileSystem 的静态方法 get 获得该对象</p>
<figure class="highlight arduino"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs arduino"><span class="hljs-built_in">FileSystem</span> fs = <span class="hljs-built_in">FileSystem</span>.<span class="hljs-built_in">get</span>(conf)<br></code></pre></td></tr></table></figure>

<ul>
<li><code>get</code> 方法从 <code>conf</code> 中的一个参数 <code>fs.defaultFS</code> 的配置值判断具体是什么类型的文件系统</li>
<li>如果我们的代码中没有指定 <code>fs.defaultFS</code>, 并且工程 ClassPath 下也没有给定相应的配置, <code>conf</code> 中的默认值就来自于 Hadoop 的 Jar 包中的 <code>core-default.xml</code></li>
<li>默认值为 <code>file:///</code>, 则获取的不是一个 DistributedFileSystem 的实例, 而是一个本地文件系统的客户端对象</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="依赖配置"><a href="#依赖配置" class="headerlink" title="依赖配置"></a>依赖配置</h3><p>新建工程后导入maven依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">repositories</span>&gt;</span><br>      <span class="hljs-comment">&lt;!--指定下载地址--&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">repository</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">id</span>&gt;</span>cloudera<span class="hljs-tag">&lt;/<span class="hljs-name">id</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">url</span>&gt;</span>https://repository.cloudera.com/artifactory/cloudera-repos/<span class="hljs-tag">&lt;/<span class="hljs-name">url</span>&gt;</span><br>      <span class="hljs-tag">&lt;/<span class="hljs-name">repository</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">repositories</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">dependencies</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hadoop-common<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.1.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>      <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hadoop-hdfs<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.1.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>      <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hadoop-hdfs-client<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.1.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>      <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hadoop-client<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.1.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>      <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.junit.jupiter<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>junit-jupiter<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>RELEASE<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>compile<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>      <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">dependencies</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">properties</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="hljs-tag">&lt;/<span class="hljs-name">project.build.sourceEncoding</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">properties</span>&gt;</span><br>  <span class="hljs-tag">&lt;<span class="hljs-name">build</span>&gt;</span><br>      <span class="hljs-tag">&lt;<span class="hljs-name">plugins</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">plugin</span>&gt;</span><br>              <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>              <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>              <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>              <span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>                  <span class="hljs-tag">&lt;<span class="hljs-name">source</span>&gt;</span>1.8<span class="hljs-tag">&lt;/<span class="hljs-name">source</span>&gt;</span><br>                  <span class="hljs-tag">&lt;<span class="hljs-name">target</span>&gt;</span>1.8<span class="hljs-tag">&lt;/<span class="hljs-name">target</span>&gt;</span><br>                  <span class="hljs-tag">&lt;<span class="hljs-name">encoding</span>&gt;</span>UTF-8<span class="hljs-tag">&lt;/<span class="hljs-name">encoding</span>&gt;</span><br>              <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br>          <span class="hljs-tag">&lt;/<span class="hljs-name">plugin</span>&gt;</span><br>          <span class="hljs-tag">&lt;<span class="hljs-name">plugin</span>&gt;</span><br>              <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>              <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>maven-shade-plugin<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>              <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.4.3<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>              <span class="hljs-tag">&lt;<span class="hljs-name">executions</span>&gt;</span><br>                  <span class="hljs-tag">&lt;<span class="hljs-name">execution</span>&gt;</span><br>                      <span class="hljs-tag">&lt;<span class="hljs-name">phase</span>&gt;</span>package<span class="hljs-tag">&lt;/<span class="hljs-name">phase</span>&gt;</span><br>                      <span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>                          <span class="hljs-tag">&lt;<span class="hljs-name">minimizeJar</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">minimizeJar</span>&gt;</span><br>                      <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br>                  <span class="hljs-tag">&lt;/<span class="hljs-name">execution</span>&gt;</span><br>              <span class="hljs-tag">&lt;/<span class="hljs-name">executions</span>&gt;</span><br>          <span class="hljs-tag">&lt;/<span class="hljs-name">plugin</span>&gt;</span><br>      <span class="hljs-tag">&lt;/<span class="hljs-name">plugins</span>&gt;</span><br>  <span class="hljs-tag">&lt;/<span class="hljs-name">build</span>&gt;</span><br></code></pre></td></tr></table></figure>



<h3 id="获取-FileSystem的方式"><a href="#获取-FileSystem的方式" class="headerlink" title="获取 FileSystem的方式"></a>获取 FileSystem的方式</h3><h4 id="第一种"><a href="#第一种" class="headerlink" title="第一种"></a>第一种</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//获取文件系统的第一种方式</span><br><span class="hljs-meta">@Test</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">getFileSystem</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> URISyntaxException, IOException </span>&#123;<br>    <span class="hljs-comment">//1.获取Configuration对象</span><br>    Configuration configuration = <span class="hljs-keyword">new</span> Configuration();<br>    <span class="hljs-comment">//2.设置Configuration对象，指定要操作的文件系统</span><br>    configuration.set(<span class="hljs-string">&quot;fs.defaultFS&quot;</span>,<span class="hljs-string">&quot;hdfs://192.168.127.110:8020&quot;</span>);<br>    <span class="hljs-comment">//3.获取指定文件系统，获取了fileSystem就相当于获取了主节点中所有元数据信息</span><br>    FileSystem fileSystem = FileSystem.get(configuration);<br>    System.out.println(fileSystem.toString());<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="第二种"><a href="#第二种" class="headerlink" title="第二种"></a>第二种</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//获取文件系统的第二种方式</span><br><span class="hljs-meta">@Test</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">getFileSystem2</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> URISyntaxException, IOException </span>&#123;<br>    FileSystem fileSystem = FileSystem.get(<span class="hljs-keyword">new</span> URI(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020&quot;</span>), <span class="hljs-keyword">new</span> Configuration());<br>    System.out.println(fileSystem.toString());<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="第三种"><a href="#第三种" class="headerlink" title="第三种"></a>第三种</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//获取文件系统的第三种方式</span><br><span class="hljs-meta">@Test</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">getFileSystem3</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> URISyntaxException, IOException </span>&#123;<br>    FileSystem fileSystem = FileSystem.newInstance(<span class="hljs-keyword">new</span> URI(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020&quot;</span>), <span class="hljs-keyword">new</span> Configuration());<br>    System.out.println(fileSystem.toString());<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="第四种"><a href="#第四种" class="headerlink" title="第四种"></a>第四种</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//获取文件系统的第四种方式</span><br><span class="hljs-meta">@Test</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">getFileSystem4</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span>  Exception</span>&#123;<br>    Configuration configuration = <span class="hljs-keyword">new</span> Configuration();<br>    configuration.set(<span class="hljs-string">&quot;fs.defaultFS&quot;</span>,<span class="hljs-string">&quot;hdfs://192.168.127.110:8020&quot;</span>);<br>    FileSystem fileSystem = FileSystem.newInstance(configuration);<br>    System.out.println(fileSystem.toString());<br>&#125;<br></code></pre></td></tr></table></figure>

<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/4.9.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="获取文件元信息"><a href="#获取文件元信息" class="headerlink" title="获取文件元信息"></a>获取文件元信息</h3><p><strong>获取目录及其子目录下所有文件</strong>有如下两种方法</p>
<h4 id="递归法"><a href="#递归法" class="headerlink" title="递归法"></a>递归法</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//递归调用</span><br><span class="hljs-meta">@Test</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listFile</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span> Exception</span>&#123;<br>    FileSystem fileSystem = FileSystem.get(<span class="hljs-keyword">new</span> URI(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020&quot;</span>), <span class="hljs-keyword">new</span> Configuration());<br>    FileStatus[] fileStatuses = fileSystem.listStatus(<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;/&quot;</span>));<br>    <span class="hljs-keyword">for</span> (FileStatus fileStatus : fileStatuses) &#123;<br>        <span class="hljs-keyword">if</span>(fileStatus.isDirectory())&#123;<br>            Path path = fileStatus.getPath();<br>            listAllFiles(fileSystem,path);<br>        &#125;<span class="hljs-keyword">else</span>&#123;<br>            System.out.println(<span class="hljs-string">&quot;文件路径为&quot;</span>+fileStatus.getPath().toString());<br>        &#125;<br>    &#125;<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listAllFiles</span><span class="hljs-params">(FileSystem fileSystem,Path path)</span> <span class="hljs-keyword">throws</span>  Exception</span>&#123;<br>    FileStatus[] fileStatuses = fileSystem.listStatus(path);<br>    <span class="hljs-keyword">for</span> (FileStatus fileStatus : fileStatuses) &#123;<br>        <span class="hljs-keyword">if</span>(fileStatus.isDirectory())&#123;<br>            listAllFiles(fileSystem,fileStatus.getPath());<br>        &#125;<span class="hljs-keyword">else</span>&#123;<br>            Path path1 = fileStatus.getPath();<br>            System.out.println(<span class="hljs-string">&quot;文件路径为&quot;</span>+path1);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="直接使用API"><a href="#直接使用API" class="headerlink" title="直接使用API"></a>直接使用API</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-meta">@Test</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">listMyFiles</span><span class="hljs-params">()</span><span class="hljs-keyword">throws</span> Exception</span>&#123;<br>    <span class="hljs-comment">//获取fileSystem类</span><br>    FileSystem fileSystem = FileSystem.get(<span class="hljs-keyword">new</span> URI(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020&quot;</span>), <span class="hljs-keyword">new</span> Configuration());<br>    <span class="hljs-comment">//获取RemoteIterator 得到所有的文件或者文件夹，第一个参数指定遍历的路径，第二个参数表示是否要递归遍历</span><br>    RemoteIterator&lt;LocatedFileStatus&gt; locatedFileStatusRemoteIterator = fileSystem.listFiles(<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;/&quot;</span>), <span class="hljs-keyword">true</span>);<br>    <span class="hljs-keyword">while</span> (locatedFileStatusRemoteIterator.hasNext())&#123;<br>        <span class="hljs-comment">//获取每个文件详细信息</span><br>        LocatedFileStatus fileStatus = locatedFileStatusRemoteIterator.next();<br>        <span class="hljs-comment">//打印文件路径</span><br>        System.out.println(fileStatus.getPath().toString());<br>        <span class="hljs-comment">//获取文件Block信息</span><br>        BlockLocation[] blockLocations = fileStatus.getBlockLocations();<br>        <span class="hljs-comment">//打印每个文件副本存储位置</span><br>        <span class="hljs-keyword">for</span> (BlockLocation blockLocation : blockLocations) &#123;<br>            String[] hosts = blockLocation.getHosts();<br>            <span class="hljs-keyword">for</span> (String host : hosts) &#123;<br>                System.out.println(host);<br>            &#125;<br>        &#125;<br>    &#125;<br>    fileSystem.close();<br>&#125;<br><br></code></pre></td></tr></table></figure>

<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/4.10.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="创建文件夹"><a href="#创建文件夹" class="headerlink" title="创建文件夹"></a>创建文件夹</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//创建文件、文件夹(支持创建多级目录)</span><br><span class="hljs-meta">@Test</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">mkdirs</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span>  Exception</span>&#123;<br>    FileSystem fileSystem = FileSystem.get(<span class="hljs-keyword">new</span> URI(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020&quot;</span>), <span class="hljs-keyword">new</span> Configuration());<br>    <span class="hljs-keyword">boolean</span> isMkdirs01 = fileSystem.mkdirs(<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;/test03&quot;</span>));<br>    System.out.println(<span class="hljs-string">&quot;文件夹创建是否成功：&quot;</span>+isMkdirs01);<br>    <span class="hljs-keyword">boolean</span> isMkdirs02 = fileSystem.mkdirs(<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;/test01/a.txt&quot;</span>));<br>    System.out.println(<span class="hljs-string">&quot;文件创建是否成功：&quot;</span>+isMkdirs02);<br>    fileSystem.close();<br>&#125;<br></code></pre></td></tr></table></figure>

<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/4.11.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="下载文件"><a href="#下载文件" class="headerlink" title="下载文件"></a>下载文件</h3><h4 id="方法一"><a href="#方法一" class="headerlink" title="方法一"></a>方法一</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//文件下载方法一</span><br><span class="hljs-meta">@Test</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">getFileToLocal01</span><span class="hljs-params">()</span><span class="hljs-keyword">throws</span>  Exception</span>&#123;<br>    <span class="hljs-comment">//1.获取FileSystem对象</span><br>    FileSystem fileSystem = FileSystem.get(<span class="hljs-keyword">new</span> URI(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020&quot;</span>), <span class="hljs-keyword">new</span> Configuration());<br>    <span class="hljs-comment">//2.获取HDFS文件输入流</span><br>    FSDataInputStream open = fileSystem.open(<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;/test01/hello.sh&quot;</span>));<br>    <span class="hljs-comment">//3.获取本地文件输出流</span><br>    FileOutputStream fileOutputStream = <span class="hljs-keyword">new</span> FileOutputStream(<span class="hljs-keyword">new</span> File(<span class="hljs-string">&quot;..\\hello01.sh&quot;</span>));<br>    <span class="hljs-comment">//4.实现文件复制</span><br>    IOUtils.copy(open,fileOutputStream);<br>    IOUtils.closeQuietly(open);<br>    IOUtils.closeQuietly(fileOutputStream);<br>    <span class="hljs-comment">//5.关闭fileSystem</span><br>    fileSystem.close();<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="方法二"><a href="#方法二" class="headerlink" title="方法二"></a>方法二</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//文件下载方法二</span><br><span class="hljs-meta">@Test</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">getFileToLocal02</span><span class="hljs-params">()</span><span class="hljs-keyword">throws</span>  Exception</span>&#123;<br>    <span class="hljs-comment">//1.获取FileSystem对象</span><br>    FileSystem fileSystem = FileSystem.get(<span class="hljs-keyword">new</span> URI(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020&quot;</span>), <span class="hljs-keyword">new</span> Configuration());<br>    <span class="hljs-comment">//2.调用方法直接实现文件下载</span><br>    fileSystem.copyToLocalFile(<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;/test01/hello.sh&quot;</span>),<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;..\\hello02.sh&quot;</span>));<br>    <span class="hljs-comment">//3.关闭fileSystem</span><br>    fileSystem.close();<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="上传文件"><a href="#上传文件" class="headerlink" title="上传文件"></a>上传文件</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//文件上传方法</span><br><span class="hljs-meta">@Test</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">putFileTOHDFS</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span>  Exception</span>&#123;<br>    <span class="hljs-comment">//1.获取FileSystem对象</span><br>    FileSystem fileSystem = FileSystem.get(<span class="hljs-keyword">new</span> URI(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020&quot;</span>), <span class="hljs-keyword">new</span> Configuration());<br>    <span class="hljs-comment">//2.调用方法直接实现文件下载</span><br>    fileSystem.copyFromLocalFile(<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;..\\hello02.sh&quot;</span>),<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;/test03/hello02.sh&quot;</span>));<br>    <span class="hljs-comment">//3.关闭fileSystem</span><br>    fileSystem.close();<br>&#125;<br></code></pre></td></tr></table></figure>



<h3 id="伪造用户"><a href="#伪造用户" class="headerlink" title="伪造用户"></a>伪造用户</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//以指定用户名的用户去操作文件</span><br><span class="hljs-meta">@Test</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">getConfig</span><span class="hljs-params">()</span><span class="hljs-keyword">throws</span>  Exception</span>&#123;<br>  		FileSystem fileSystem = FileSystem.get(<span class="hljs-keyword">new</span> URI(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020&quot;</span>), <span class="hljs-keyword">new</span> Configuration(),<span class="hljs-string">&quot;root&quot;</span>);<br> 	    fileSystem.copyToLocalFile(<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;/test03/hello02.sh&quot;</span>),<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;..\\temp.sh&quot;</span>));<br>	fileSystem.close();<br>&#125;<br></code></pre></td></tr></table></figure>



<h3 id="小文件合并"><a href="#小文件合并" class="headerlink" title="小文件合并"></a>小文件合并</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">//小文件合并</span><br><span class="hljs-meta">@Test</span><br><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">mergeFile</span><span class="hljs-params">()</span> <span class="hljs-keyword">throws</span>  Exception</span>&#123;<br>    <span class="hljs-comment">//1.获取FileSystem文件系统</span><br>    FileSystem fileSystem = FileSystem.get(<span class="hljs-keyword">new</span> URI(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020&quot;</span>), <span class="hljs-keyword">new</span> Configuration(),<span class="hljs-string">&quot;hadoop&quot;</span>);<br>    <span class="hljs-comment">//2.在HDFS获取要输出的文件流</span><br>    FSDataOutputStream outputStream = fileSystem.create(<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;/bigfile.txt&quot;</span>));<br>    <span class="hljs-comment">//3.获取LocalFileSystem本地文件系统</span><br>    LocalFileSystem local = FileSystem.getLocal(<span class="hljs-keyword">new</span> Configuration());<br>    <span class="hljs-comment">//4.获取通过本地文件集合</span><br>    FileStatus[] fileStatuses = local.listStatus(<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;..\\hdfs_api\\temp&quot;</span>));<br>    <span class="hljs-comment">//5.遍历集合进行合并后上传</span><br>    <span class="hljs-keyword">for</span> (FileStatus fileStatus : fileStatuses) &#123;<br>        FSDataInputStream inputStream = local.open(fileStatus.getPath());<br>        IOUtils.copy(inputStream,outputStream);<br>        IOUtils.closeQuietly(inputStream);<br>    &#125;<br>    <span class="hljs-comment">//6.关闭资源</span><br>    IOUtils.closeQuietly(outputStream);<br>    local.close();<br>    fileSystem.close();<br>&#125;<br></code></pre></td></tr></table></figure>

<hr>
<h1 id="五、MapReduce"><a href="#五、MapReduce" class="headerlink" title="五、MapReduce"></a>五、MapReduce</h1><h2 id="概述-4"><a href="#概述-4" class="headerlink" title="概述"></a>概述</h2><p>MapReduce是一个分布式运算程序的编程框架，核心功能是将用户编写的业务逻辑代码和自带默认组件整合成一个完整的<strong>分布式运算程序</strong>，并发运行在Hadoop集群上。</p>
<h3 id="构思"><a href="#构思" class="headerlink" title="构思"></a>构思</h3><p>MapReduce的思想核心是“<strong>分而治之</strong>”，适用于大量复杂的任务处理场景（大规模数据处理场景）。</p>
<ul>
<li>分而治之<ul>
<li>对相互间<strong>不具有计算依赖关系</strong>的大数据，实现并行最自然的办法就是采取分而治之的策略。并行计算的第一个重要问题是如何划分计算任务或者计算数据以便对划分的子任务或数据块同时进行计算。不可分拆的计算任务或相互间有依赖关系的数据无法进行并行计算</li>
<li>统一构架，隐藏系统层细节<ul>
<li>MapReduce设计并提供了统一的计算框架，隐藏了绝大多数系统层面的处理细节。</li>
<li>MapReduce最大的亮点在于通过<strong>抽象模型</strong>和<strong>计算框架</strong>把需要做什么(whatneed to do)与具体怎么做(how to do)分开了，提供一个抽象和高层的编程接口和框架。使用者仅需要关心其应用层的具体计算问题，仅需编写少量的处理应用本身计算问题的程序代码。如何具体完成这个并行计算任务所相关的诸多系统层细节被隐藏起来，交给计算框架去处理：从分布代码的执行，到大到数千小到单个节点集群的自动调度使用。</li>
</ul>
</li>
</ul>
</li>
<li>构建抽象模型：Map和Reduce<ul>
<li>MapReduce借鉴了函数式语言中的思想，用Map和Reduce两个函数提供了高层的并行编程抽象模型，MapReduce处理的数据类型是键值对。<ul>
<li>Map: 对一组数据元素进行某种<strong>重复式</strong>的处理。</li>
<li>Reduce: 对Map的中间结果进行某种<strong>进一步</strong>的结果整理。</li>
</ul>
</li>
<li><strong>Map负责“分”</strong>，即把复杂的任务分解为若干个“简单的任务”来并行处理。可以进行拆分的前提是这些小任务可以并行计算，彼此间几乎没有依赖关系。</li>
<li><strong>Reduce负责“合”</strong>，即对map阶段的结果进行全局汇总。</li>
</ul>
</li>
</ul>
<p>MapReduce运行在yarn集群，<strong>ResourceManager</strong>，<strong>NodeManager</strong>这两个阶段合起来正是MapReduce思想的体现。</p>
<h3 id="运行流程"><a href="#运行流程" class="headerlink" title="运行流程"></a>运行流程</h3><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.1.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="框架结构"><a href="#框架结构" class="headerlink" title="框架结构"></a>框架结构</h3><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.2.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="编程规范"><a href="#编程规范" class="headerlink" title="编程规范"></a>编程规范</h2><h3 id="Map阶段"><a href="#Map阶段" class="headerlink" title="Map阶段"></a>Map阶段</h3><ol>
<li>设置 InputFormat 类, 将数据切分为 Key-Value(<strong>K1和V1</strong>) 对, 输入到第二步</li>
<li>自定义 Map 逻辑, 将第一步的结果转换成另外的 Key-Value（<strong>K2和V2</strong>） 对, 输出结果</li>
</ol>
<h3 id="Shuffle阶段"><a href="#Shuffle阶段" class="headerlink" title="Shuffle阶段"></a>Shuffle阶段</h3><ol start="3">
<li>对输出的 Key-Value 对进行<strong>分区</strong></li>
<li>对不同分区的数据按照相同的 Key <strong>排序</strong></li>
<li>(可选) 对分组过的数据初步<strong>规约</strong>，降低数据的网络拷贝</li>
<li>对数据进行**分组,**，相同 Key 的 Value 放入一个集合中</li>
</ol>
<h3 id="Reduce阶段"><a href="#Reduce阶段" class="headerlink" title="Reduce阶段"></a>Reduce阶段</h3><ol start="7">
<li>对多个 Map 任务的结果进行排序以及合并, 编写 Reduce 函数实现自己的逻辑, 对输入的 Key-Value 进行处理, 转为新的 Key-Value（<strong>K3和V3</strong>）输出</li>
<li>设置 OutputFormat 处理并保存 Reduce 输出的 Key-Value 数据</li>
</ol>
<h2 id="WordCount案例"><a href="#WordCount案例" class="headerlink" title="WordCount案例"></a>WordCount案例</h2><h3 id="步骤分析"><a href="#步骤分析" class="headerlink" title="步骤分析"></a>步骤分析</h3><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.2.1.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="第一步：数据准备"><a href="#第一步：数据准备" class="headerlink" title="第一步：数据准备"></a>第一步：数据准备</h3><ul>
<li><p>创建一个新的文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /export/servers<br>vim wordcount.txt<br></code></pre></td></tr></table></figure></li>
<li><p>向其中放入以下内容并保存</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs txt">hello,world,hadoop<br>hive,sqoop,flume,hello<br>kitty,tom,jerry,world<br>hadoop<br></code></pre></td></tr></table></figure></li>
<li><p>上传到 HDFS</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">hdfs dfs -mkdir /wordcount/<br>hdfs dfs -put wordcount.txt /wordcount/<br></code></pre></td></tr></table></figure></li>
</ul>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.3.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>新建Maven项目，导入如下依赖</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">packaging</span>&gt;</span>jar<span class="hljs-tag">&lt;/<span class="hljs-name">packaging</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">repositories</span>&gt;</span><br>    <span class="hljs-comment">&lt;!--指定下载地址--&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">repository</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">id</span>&gt;</span>cloudera<span class="hljs-tag">&lt;/<span class="hljs-name">id</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">url</span>&gt;</span>https://repository.cloudera.com/artifactory/cloudera-repos/<span class="hljs-tag">&lt;/<span class="hljs-name">url</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">repository</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">repositories</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">dependencies</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hadoop-common<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.1.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hadoop-hdfs<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.1.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hadoop-hdfs-client<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.1.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>provided<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hadoop-client<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.1.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.junit.jupiter<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>junit-jupiter<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>RELEASE<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">scope</span>&gt;</span>compile<span class="hljs-tag">&lt;/<span class="hljs-name">scope</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependencies</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">properties</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">project.build.sourceEncoding</span>&gt;</span>UTF-8<span class="hljs-tag">&lt;/<span class="hljs-name">project.build.sourceEncoding</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">properties</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">build</span>&gt;</span><br>    <span class="hljs-tag">&lt;<span class="hljs-name">plugins</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">plugin</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">source</span>&gt;</span>1.8<span class="hljs-tag">&lt;/<span class="hljs-name">source</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">target</span>&gt;</span>1.8<span class="hljs-tag">&lt;/<span class="hljs-name">target</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">encoding</span>&gt;</span>UTF-8<span class="hljs-tag">&lt;/<span class="hljs-name">encoding</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">plugin</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">plugin</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>maven-shade-plugin<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>2.4.3<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>            <span class="hljs-tag">&lt;<span class="hljs-name">executions</span>&gt;</span><br>                <span class="hljs-tag">&lt;<span class="hljs-name">execution</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">phase</span>&gt;</span>package<span class="hljs-tag">&lt;/<span class="hljs-name">phase</span>&gt;</span><br>                    <span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>                        <span class="hljs-tag">&lt;<span class="hljs-name">minimizeJar</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">minimizeJar</span>&gt;</span><br>                    <span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br>                <span class="hljs-tag">&lt;/<span class="hljs-name">execution</span>&gt;</span><br>            <span class="hljs-tag">&lt;/<span class="hljs-name">executions</span>&gt;</span><br>        <span class="hljs-tag">&lt;/<span class="hljs-name">plugin</span>&gt;</span><br>    <span class="hljs-tag">&lt;/<span class="hljs-name">plugins</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">build</span>&gt;</span><br></code></pre></td></tr></table></figure>

<h3 id="第二步：Mapper编写"><a href="#第二步：Mapper编写" class="headerlink" title="第二步：Mapper编写"></a>第二步：Mapper编写</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@time</span> 2021/1/10</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@auth</span> Gotcha</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@describe</span></span><br><span class="hljs-comment"> * Mapper的泛型</span><br><span class="hljs-comment"> *  KEYIN:k1的类型     行偏移量        LongWritable</span><br><span class="hljs-comment"> *  VALUEIN:v1的类型   一行的文本数据   Text</span><br><span class="hljs-comment"> *  KEYOUT:k2的类型    每个单词        Text</span><br><span class="hljs-comment"> *  VALUEOUT:v2的类型  固定值，1       LongWritable</span><br><span class="hljs-comment"> */</span><br><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">WordCountMapper</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Mapper</span>&lt;<span class="hljs-title">LongWritable</span>,<span class="hljs-title">Text</span>, <span class="hljs-title">Text</span>,<span class="hljs-title">LongWritable</span>&gt; </span>&#123;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@describe</span> 是将k1,v1转换为k2,v2</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> key 表示k1</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> value 表示v1</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> context 表示MapReduce上下文对象</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title">map</span><span class="hljs-params">(LongWritable key, Text value, Context context)</span> <span class="hljs-keyword">throws</span> IOException, InterruptedException </span>&#123;<br>        <span class="hljs-comment">//第二步要使用的对象</span><br>        Text text = <span class="hljs-keyword">new</span> Text();<br>        LongWritable longWritable = <span class="hljs-keyword">new</span> LongWritable(<span class="hljs-number">1</span>);<br>        <span class="hljs-comment">//1.对每行数据进行字符串拆分</span><br>        String line = value.toString();<br>        String[] split = line.split(<span class="hljs-string">&quot;,&quot;</span>);<br>        <span class="hljs-comment">//2.遍历数组获取每个单词</span><br>        <span class="hljs-keyword">for</span> (String word : split) &#123;<br>            text.set(word);<br>            <span class="hljs-comment">//3.将k2,v2写入上下文</span><br>            context.write(text,longWritable);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>



<h3 id="第三步：Reducer编写"><a href="#第三步：Reducer编写" class="headerlink" title="第三步：Reducer编写"></a>第三步：Reducer编写</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@time</span> 2021/1/10</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@auth</span> Gotcha</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@describe</span></span><br><span class="hljs-comment"> *  Reducer的泛型</span><br><span class="hljs-comment"> *  KEYIN:k2的类型     每个单词        Text</span><br><span class="hljs-comment"> *  VALUEIN:v2的类型   集合中泛型的类型   LongWritable</span><br><span class="hljs-comment"> *  KEYOUT:k3的类型    每个单词        Text</span><br><span class="hljs-comment"> *  VALUEOUT:v3的类型  出现的次数       LongWritable</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">WordCountReducer</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Reducer</span>&lt;<span class="hljs-title">Text</span>, <span class="hljs-title">LongWritable</span>,<span class="hljs-title">Text</span>, <span class="hljs-title">LongWritable</span>&gt; </span>&#123;<br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@describe</span> 是将k2,v2转换为k3,v3</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> key 表示k2</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> values 表示集合</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> context 表示MapReduce上下文对象</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title">reduce</span><span class="hljs-params">(Text key, Iterable&lt;LongWritable&gt; values, Context context)</span> <span class="hljs-keyword">throws</span> IOException, InterruptedException </span>&#123;<br>        <span class="hljs-keyword">long</span> count = <span class="hljs-number">0</span>;<br>        <span class="hljs-comment">//1.遍历values集合</span><br>        <span class="hljs-keyword">for</span> (LongWritable value : values) &#123;<br>            <span class="hljs-comment">//2.将集合中值相加</span><br>            count+=value.get();<br>        &#125;<br>        <span class="hljs-comment">//3.将k3,v3写入上下文</span><br>        context.write(key,<span class="hljs-keyword">new</span> LongWritable(count));<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>



<h3 id="第四步：定义主类-描述-Job-并提交-Job"><a href="#第四步：定义主类-描述-Job-并提交-Job" class="headerlink" title="第四步：定义主类, 描述 Job 并提交 Job"></a>第四步：定义主类, 描述 Job 并提交 Job</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">JobMain</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Configured</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Tool</span> </span>&#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">run</span><span class="hljs-params">(String[] strings)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        <span class="hljs-comment">//创建一个任务对象</span><br>        Job job = Job.getInstance(<span class="hljs-keyword">super</span>.getConf(), <span class="hljs-string">&quot;计算单词出现次数&quot;</span>);<br>        <span class="hljs-comment">//打包到集群上面运行时候，必须要添加以下配置，指定程序的main函数</span><br>        job.setJarByClass(JobMain.class);<br><br>        <span class="hljs-comment">//第一步：设置读取文件的类，将文件解析成key，value对</span><br>        job.setInputFormatClass(TextInputFormat.class);<br>        TextInputFormat.addInputPath(job,<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020/wordcount&quot;</span>));<br>        <span class="hljs-comment">//第二步：设置mapper类</span><br>        job.setMapperClass(WordCountMapper.class);<br>            <span class="hljs-comment">//设置map阶段完成之后的输出类型</span><br>        job.setMapOutputKeyClass(Text.class);<br>        job.setMapOutputValueClass(LongWritable.class);<br>        <span class="hljs-comment">//第三步，第四步，第五步，第六步采用默认方式（分区、排序、规约、分组）</span><br>        <span class="hljs-comment">//第七步：设置reduce类</span><br>        job.setReducerClass(WordCountReducer.class);<br>            <span class="hljs-comment">//设置reduce阶段完成之后的输出类型</span><br>        job.setOutputKeyClass(Text.class);<br>        job.setOutputValueClass(LongWritable.class);<br>        <span class="hljs-comment">//第八步：设置输出类以及输出路径</span><br>        job.setOutputFormatClass(TextOutputFormat.class);<br>        TextOutputFormat.setOutputPath(job,<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020/wordcount_out&quot;</span>));<br>        <span class="hljs-comment">//任务是否执行成功</span><br>        <span class="hljs-keyword">boolean</span> b = job.waitForCompletion(<span class="hljs-keyword">true</span>);<br>        <span class="hljs-keyword">return</span> b?<span class="hljs-number">0</span>:<span class="hljs-number">1</span>;<br><br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        Configuration configuration = <span class="hljs-keyword">new</span> Configuration();<br>        <span class="hljs-comment">//启动一个任务</span><br>        <span class="hljs-keyword">int</span> run = ToolRunner.run(configuration, <span class="hljs-keyword">new</span> JobMain(), args);<br>        System.exit(run);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>



<h3 id="第五步：打成jar包上传至服务器，并在服务器运行"><a href="#第五步：打成jar包上传至服务器，并在服务器运行" class="headerlink" title="第五步：打成jar包上传至服务器，并在服务器运行"></a>第五步：打成jar包上传至服务器，并在服务器运行</h3><p><code>hadoop jar /export/softwares/mapReduce-1.0-SNAPSHOT.jar top.igotcha.mapreduce.wordcount.JobMain</code></p>
<p>执行结果如下</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.4.png" srcset="/img/loading.gif" lazyload></p>
<p>生成的结果文件如下</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.5.png" srcset="/img/loading.gif" lazyload></p>
<hr>
<h2 id="分区案例"><a href="#分区案例" class="headerlink" title="分区案例"></a>分区案例</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>在MapReduce 中，通过指定分区，会将同一个分区的数据发送到同一个Reduce当中进行处理</p>
<h3 id="步骤分析-1"><a href="#步骤分析-1" class="headerlink" title="步骤分析"></a>步骤分析</h3><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.6.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="自定义Partitioner"><a href="#自定义Partitioner" class="headerlink" title="自定义Partitioner"></a>自定义Partitioner</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@time</span> 2021/1/11</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@auth</span> Gotcha</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@describe</span></span><br><span class="hljs-comment"> * Partitioner</span><br><span class="hljs-comment"> *  KEY:k2的类型     每个单词        Text</span><br><span class="hljs-comment"> *  VALUE:v2的类型   固定值，1   LongWritable</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">PartitionerOwn</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Partitioner</span>&lt;<span class="hljs-title">Text</span>,<span class="hljs-title">LongWritable</span>&gt; </span>&#123;<br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> text 表示k2</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> longWritable 表示v2</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> i 表示分区个数（reduce个数）</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@return</span></span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">getPartition</span><span class="hljs-params">(Text text, LongWritable longWritable, <span class="hljs-keyword">int</span> i)</span> </span>&#123;<br>        <span class="hljs-comment">//如果单词长度大于等于5，进入第一个分区，第一个ReduceTask，即reduce编号为0</span><br>        <span class="hljs-keyword">if</span> (text.getLength()&gt;=<span class="hljs-number">5</span>)&#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        &#125; <span class="hljs-keyword">else</span>  &#123;<br>        <span class="hljs-comment">//如果单词长度小于5，进入第二个分区，第二个ReduceTask，即reduce编号为1</span><br>            <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>



<h3 id="定义主类job"><a href="#定义主类job" class="headerlink" title="定义主类job"></a>定义主类job</h3><p>主要变化在于多了<strong>第三步，设置分区类</strong>，在<strong>第七步：设置reduce类</strong>中<strong>设置reduce个数</strong>，其他不变</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">JobMain02</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Configured</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Tool</span> </span>&#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">run</span><span class="hljs-params">(String[] strings)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        <span class="hljs-comment">//创建一个任务对象</span><br>        Job job = Job.getInstance(<span class="hljs-keyword">super</span>.getConf(), <span class="hljs-string">&quot;计算单词出现次数&quot;</span>);<br>        <span class="hljs-comment">//打包到集群上面运行时候，必须要添加以下配置，指定程序的main函数</span><br>        job.setJarByClass(JobMain02.class);<br>        <span class="hljs-comment">//第一步：设置读取文件的类，将文件解析成key，value对</span><br>        job.setInputFormatClass(TextInputFormat.class);<br>        TextInputFormat.addInputPath(job,<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020/wordcount&quot;</span>));<br>        <span class="hljs-comment">//第二步：设置mapper类</span><br>        job.setMapperClass(WordCountMapper.class);<br>            <span class="hljs-comment">//设置map阶段完成之后的输出类型</span><br>        job.setMapOutputKeyClass(Text.class);<br>        job.setMapOutputValueClass(LongWritable.class);<br>        <span class="hljs-comment">//第三步，第四步，第五步，第六步采用默认方式（分区、排序、规约、分组）</span><br>        <span class="hljs-comment">//第三步，设置分区类</span><br>        job.setPartitionerClass(PartitionerOwn.class);<br>        <span class="hljs-comment">//第七步：设置reduce类</span><br>        job.setReducerClass(WordCountReducer.class);<br>            <span class="hljs-comment">//设置reduce阶段完成之后的输出类型</span><br>        job.setOutputKeyClass(Text.class);<br>        job.setOutputValueClass(LongWritable.class);<br>            <span class="hljs-comment">//设置reduce个数</span><br>        job.setNumReduceTasks(<span class="hljs-number">2</span>);<br>        <span class="hljs-comment">//第八步：设置输出类以及输出路径</span><br>        job.setOutputFormatClass(TextOutputFormat.class);<br>        TextOutputFormat.setOutputPath(job,<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020/wordcount_out&quot;</span>));<br>        <span class="hljs-comment">//任务是否执行成功</span><br>        <span class="hljs-keyword">boolean</span> b = job.waitForCompletion(<span class="hljs-keyword">true</span>);<br>        <span class="hljs-keyword">return</span> b?<span class="hljs-number">0</span>:<span class="hljs-number">1</span>;<br><br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        Configuration configuration = <span class="hljs-keyword">new</span> Configuration();<br>        <span class="hljs-comment">//启动一个任务</span><br>        <span class="hljs-keyword">int</span> run = ToolRunner.run(configuration, <span class="hljs-keyword">new</span> JobMain02(), args);<br>        System.exit(run);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>



<h3 id="打成jar包上传至服务器，并在服务器运行"><a href="#打成jar包上传至服务器，并在服务器运行" class="headerlink" title="打成jar包上传至服务器，并在服务器运行"></a>打成jar包上传至服务器，并在服务器运行</h3><p><strong>保持Mapper类和Reducer类不变，上传至服务器并运行</strong>，产生了两个结果文件</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.7.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.8.png" srcset="/img/loading.gif" lazyload></p>
<hr>
<h2 id="序列化、反序列化和排序案例"><a href="#序列化、反序列化和排序案例" class="headerlink" title="序列化、反序列化和排序案例"></a>序列化、反序列化和排序案例</h2><h3 id="概念-1"><a href="#概念-1" class="headerlink" title="概念"></a>概念</h3><p><strong>当要在进程间传递对象或持久化对象的时候，就需要序列化对象成字节流，反之当要将接收到或从磁盘读取的字节流转换为对象，就要进行反序列化。</strong></p>
<ul>
<li><strong>序列化</strong> (Serialization) 是指把结构化对象转化为字节流</li>
<li><strong>反序列化</strong> (Deserialization) 是序列化的逆过程。 把字节流转为结构化对象。</li>
</ul>
<ul>
<li>Java 的序列化 (Serializable) 是一个重量级序列化框架, 一个对象被序列化后， 会附带很多额外的信息 (各种校验信息, header, 继承体系等），不便于在网络中高效传输。所以，Hadoop 自己开发了一套序列化机制(Writable)，精简高效。不用像 Java 对象类一样传输多层的父子关系， 需要哪个属性就传输哪个属性值, 大大的减少网络传输的开销</li>
<li>Writable 是 Hadoop 的序列化格式，Hadoop 定义了这样一个 Writable 接口。一个类要支持可序列化只需实现这个接口即可</li>
<li>另外 Writable 有一个子接口是 <strong>WritableComparable</strong>, WritableComparable 是既可实现序列化， 也可以对key进行比较，可以通过自定义类实现<br>WritableComparable来实现排序功能</li>
</ul>
<h3 id="步骤分析-2"><a href="#步骤分析-2" class="headerlink" title="步骤分析"></a>步骤分析</h3><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.9.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="第一步：数据准备-1"><a href="#第一步：数据准备-1" class="headerlink" title="第一步：数据准备"></a>第一步：数据准备</h3><ul>
<li><p>创建一个新的文件</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /export/servers<br>vim sort.txt<br></code></pre></td></tr></table></figure></li>
<li><p>向其中放入以下内容并保存</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs txt">a	1<br>a	9<br>b	3<br>a	7<br>b	8<br>c	1<br>b	10<br>a	5<br></code></pre></td></tr></table></figure></li>
<li><p>上传到 HDFS</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">hdfs dfs -mkdir -p /input/sort<br>hdfs dfs -put sort.txt /input/sort<br></code></pre></td></tr></table></figure></li>
<li><p>新建Maven项目，导入依赖（和WordCount案例相同）</p>
</li>
</ul>
<h3 id="第二步：自定义类型和比较器WritableComparable"><a href="#第二步：自定义类型和比较器WritableComparable" class="headerlink" title="第二步：自定义类型和比较器WritableComparable"></a>第二步：自定义类型和比较器WritableComparable</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SortWritable</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">WritableComparable</span>&lt;<span class="hljs-title">SortWritable</span>&gt; </span>&#123;<br>    <span class="hljs-keyword">private</span> String first;<br>    <span class="hljs-keyword">private</span> <span class="hljs-keyword">int</span> second;<br><br>    <span class="hljs-comment">//实现排序规则</span><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">compareTo</span><span class="hljs-params">(SortWritable other)</span> </span>&#123;<br>        <span class="hljs-comment">//先比较first,相同则比较second</span><br>        <span class="hljs-keyword">int</span> res = <span class="hljs-keyword">this</span>.first.compareTo(other.getFirst());<br>        <span class="hljs-keyword">if</span> (res!=<span class="hljs-number">0</span>)&#123;<br>            <span class="hljs-keyword">return</span> res;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-keyword">this</span>.second - other.getSecond();<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-comment">//实现序列化</span><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">write</span><span class="hljs-params">(DataOutput dataOutput)</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>        dataOutput.writeUTF(first);<br>        dataOutput.writeInt(second);<br>    &#125;<br><br>    <span class="hljs-comment">//实现反序列化</span><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">readFields</span><span class="hljs-params">(DataInput dataInput)</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>        <span class="hljs-keyword">this</span>.first = dataInput.readUTF();<br>        <span class="hljs-keyword">this</span>.second = dataInput.readInt();<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">getFirst</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> first;<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setFirst</span><span class="hljs-params">(String first)</span> </span>&#123;<br>        <span class="hljs-keyword">this</span>.first = first;<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">getSecond</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> second;<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setSecond</span><span class="hljs-params">(<span class="hljs-keyword">int</span> second)</span> </span>&#123;<br>        <span class="hljs-keyword">this</span>.second = second;<br>    &#125;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">toString</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> first + <span class="hljs-string">&#x27;\t&#x27;</span> + second ;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="第三步：Mapper编写"><a href="#第三步：Mapper编写" class="headerlink" title="第三步：Mapper编写"></a>第三步：Mapper编写</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@time</span> 2021/1/10</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@auth</span> Gotcha</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@describe</span></span><br><span class="hljs-comment"> * Mapper的泛型</span><br><span class="hljs-comment"> *  KEYIN:k1的类型     行偏移量                    LongWritable</span><br><span class="hljs-comment"> *  VALUEIN:v1的类型   一行的文本数据               Text</span><br><span class="hljs-comment"> *  KEYOUT:k2的类型    可以进行比较及排序的Bean对象   SortWritable</span><br><span class="hljs-comment"> *  VALUEOUT:v2的类型  一行的文本数据               Text</span><br><span class="hljs-comment"> */</span><br><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SortMapper</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Mapper</span>&lt;<span class="hljs-title">LongWritable</span>,<span class="hljs-title">Text</span>,<span class="hljs-title">SortWritable</span>,<span class="hljs-title">Text</span>&gt; </span>&#123;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@describe</span> 是将k1,v1转换为k2,v2</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> key 表示k1</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> value 表示v1</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> context 表示MapReduce上下文对象</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title">map</span><span class="hljs-params">(LongWritable key, Text value, Context context)</span> <span class="hljs-keyword">throws</span> IOException, InterruptedException </span>&#123;<br>        <span class="hljs-comment">//1.对每行数据进行拆分</span><br>        String[] split = value.toString().split(<span class="hljs-string">&quot;\t&quot;</span>);<br>        <span class="hljs-comment">//2.封装到SortWritable对象中，作为k2</span><br>        SortWritable sortWritable = <span class="hljs-keyword">new</span> SortWritable();<br>        sortWritable.setFirst(split[<span class="hljs-number">0</span>]);<br>        sortWritable.setSecond(Integer.parseInt(split[<span class="hljs-number">1</span>]));<br>        <span class="hljs-comment">//3.将k2,v2写入上下文</span><br>        context.write(sortWritable,value);<br><br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="第四步：Reducer编写"><a href="#第四步：Reducer编写" class="headerlink" title="第四步：Reducer编写"></a>第四步：Reducer编写</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@time</span> 2021/1/10</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@auth</span> Gotcha</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@describe</span></span><br><span class="hljs-comment"> * Reducer的泛型</span><br><span class="hljs-comment"> *  KEYIN:k2的类型     可以进行比较及排序的Bean对象    SortWritable</span><br><span class="hljs-comment"> *  VALUEIN:v2的类型   一行的文本数据                Text</span><br><span class="hljs-comment"> *  KEYOUT:k3的类型    可以进行比较及排序的Bean对象    SortWritable</span><br><span class="hljs-comment"> *  VALUEOUT:v3的类型  空类型，占位符                NullWritable</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SortReducer</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Reducer</span>&lt;<span class="hljs-title">SortWritable</span>,<span class="hljs-title">Text</span>,<span class="hljs-title">SortWritable</span>, <span class="hljs-title">NullWritable</span>&gt; </span>&#123;<br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@describe</span> 是将k2,v2转换为k3,v3</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> key 表示k2</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> values 表示集合</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> context 表示MapReduce上下文对象</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title">reduce</span><span class="hljs-params">(SortWritable key, Iterable&lt;Text&gt; values, Context context)</span> <span class="hljs-keyword">throws</span> IOException, InterruptedException </span>&#123;<br>        <span class="hljs-keyword">for</span> (Text value : values) &#123;<br>            context.write(key,NullWritable.get());<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="第五步：打成jar包上传至服务器，并在服务器运行-1"><a href="#第五步：打成jar包上传至服务器，并在服务器运行-1" class="headerlink" title="第五步：打成jar包上传至服务器，并在服务器运行"></a>第五步：打成jar包上传至服务器，并在服务器运行</h3><p><code>hadoop jar /export/softwares/mapReduce-1.0-SNAPSHOT.jar top.igotcha.mapreduce.sort.JobMain</code></p>
<p>生成的结果文件如下</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.10.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="常用数据序列化类型"><a href="#常用数据序列化类型" class="headerlink" title="常用数据序列化类型"></a>常用数据序列化类型</h3><table>
<thead>
<tr>
<th>Java 类型</th>
<th>Hadoop Write 类型</th>
</tr>
</thead>
<tbody><tr>
<td>boolean</td>
<td>BooleanWritable</td>
</tr>
<tr>
<td>byte</td>
<td>ByteWritable</td>
</tr>
<tr>
<td>int</td>
<td>IntWritable</td>
</tr>
<tr>
<td>float</td>
<td>FloatWritable</td>
</tr>
<tr>
<td>long</td>
<td>LongWritable</td>
</tr>
<tr>
<td>double</td>
<td>DoubleWritable</td>
</tr>
<tr>
<td>String</td>
<td>Text</td>
</tr>
<tr>
<td>map</td>
<td>MapWritable</td>
</tr>
<tr>
<td>array</td>
<td>ArrayWritable</td>
</tr>
</tbody></table>
<hr>
<h2 id="计数器Counter"><a href="#计数器Counter" class="headerlink" title="计数器Counter"></a>计数器Counter</h2><h3 id="概念-2"><a href="#概念-2" class="headerlink" title="概念"></a>概念</h3><p>计数器是收集作业统计信息的有效手段之一，用于质量控制或应用级统计。计数器还可辅助诊断系统故障。如果需要将日志信息传输到map或reduce 任务，更好的方法通常是看能否用一个计数器值来记录某一特定事件的发生。对于大型分布式作业而言，使用计数器更为方便。除了因为获取计数器值比输出日志更方便，还有根据计数器值统计特定事件的发生次数要比分析一堆日志文件容易得多。</p>
<h3 id="hadoop内置计数器"><a href="#hadoop内置计数器" class="headerlink" title="hadoop内置计数器"></a>hadoop内置计数器</h3><table>
<thead>
<tr>
<th>MapReduce任务计数器</th>
<th>org.apache.hadoop.mapreduce.TaskCounter</th>
</tr>
</thead>
<tbody><tr>
<td>文件系统计数器</td>
<td>org.apache.hadoop.mapreduce.FileSystemCounter</td>
</tr>
<tr>
<td>FileInputFormat计数器</td>
<td>org.apache.hadoop.mapreduce.lib.input.FileInputFormatCounter</td>
</tr>
<tr>
<td>FileOutputFormat计数器</td>
<td>org.apache.hadoop.mapreduce.lib.output.FileOutputFormatCounter</td>
</tr>
<tr>
<td>作业计数器</td>
<td>org.apache.hadoop.mapreduce.JobCounter</td>
</tr>
</tbody></table>
<p>示例</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.11.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="获取计数器"><a href="#获取计数器" class="headerlink" title="获取计数器"></a>获取计数器</h3><p>以排序案例为例</p>
<h4 id="方法一-1"><a href="#方法一-1" class="headerlink" title="方法一"></a>方法一</h4><ul>
<li>通过<strong>context</strong>上下文对象可以获取计数器，使用计数器进行统计</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SortMapper</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Mapper</span>&lt;<span class="hljs-title">LongWritable</span>,<span class="hljs-title">Text</span>,<span class="hljs-title">SortWritable</span>,<span class="hljs-title">Text</span>&gt; </span>&#123;<br><br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@describe</span> 是将k1,v1转换为k2,v2</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> key 表示k1</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> value 表示v1</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> context 表示MapReduce上下文对象</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title">map</span><span class="hljs-params">(LongWritable key, Text value, Context context)</span> <span class="hljs-keyword">throws</span> IOException, InterruptedException </span>&#123;<br>        <span class="hljs-comment">//自定义计数器</span><br>        Counter counter = context.getCounter(<span class="hljs-string">&quot;MR_COUNT&quot;</span>, <span class="hljs-string">&quot;MapReduceCounter&quot;</span>);<br>        counter.increment(<span class="hljs-number">1L</span>);<br><br>        <span class="hljs-comment">//1.对每行数据进行拆分</span><br>        String[] split = value.toString().split(<span class="hljs-string">&quot;\t&quot;</span>);<br>        <span class="hljs-comment">//2.封装到SortWritable对象中，作为k2</span><br>        SortWritable sortWritable = <span class="hljs-keyword">new</span> SortWritable();<br>        sortWritable.setFirst(split[<span class="hljs-number">0</span>]);<br>        sortWritable.setSecond(Integer.parseInt(split[<span class="hljs-number">1</span>]));<br>        <span class="hljs-comment">//3.将k2,v2写入上下文</span><br>        context.write(sortWritable,value);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="方法二-1"><a href="#方法二-1" class="headerlink" title="方法二"></a>方法二</h4><ul>
<li>通过enum<strong>枚举类型来定义计数器</strong>，统计reduce端数据的输入的key有多少个，对应的value有多少个</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">SortReducer</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Reducer</span>&lt;<span class="hljs-title">SortWritable</span>,<span class="hljs-title">Text</span>,<span class="hljs-title">SortWritable</span>, <span class="hljs-title">NullWritable</span>&gt; </span>&#123;<br>    <span class="hljs-comment">//自定义计数器，使用枚举类</span><br>    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-class"><span class="hljs-keyword">enum</span> <span class="hljs-title">Counter</span></span>&#123;<br>        REDUCE_INPUT_KEY_RECORDS, REDUCE_INPUT_VAL_NUMS,<br>    &#125;<br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@describe</span> 是将k2,v2转换为k3,v3</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> key 表示k2</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> values 表示集合</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> context 表示MapReduce上下文对象</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title">reduce</span><span class="hljs-params">(SortWritable key, Iterable&lt;Text&gt; values, Context context)</span> <span class="hljs-keyword">throws</span> IOException, InterruptedException </span>&#123;<br>        <span class="hljs-comment">//统计Reduce阶段key个数</span><br>        context.getCounter(Counter.REDUCE_INPUT_KEY_RECORDS).increment(<span class="hljs-number">1L</span>);<br>        <span class="hljs-keyword">for</span> (Text value : values) &#123;<br>            <span class="hljs-comment">//统计Reduce阶段value个数</span><br>            context.getCounter(Counter.REDUCE_INPUT_VAL_NUMS).increment(<span class="hljs-number">1L</span>);<br>            context.write(key,NullWritable.get());<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<p><strong>运行后输入如下信息</strong></p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.12.png" srcset="/img/loading.gif" lazyload></p>
<hr>
<h2 id="规约Combiner"><a href="#规约Combiner" class="headerlink" title="规约Combiner"></a>规约Combiner</h2><h3 id="概念-3"><a href="#概念-3" class="headerlink" title="概念"></a>概念</h3><p>每一个 map 都可能会产生大量的本地输出，Combiner 的作用就是<strong>对map端的输出先做一次合并</strong>，以<strong>减少在map和reduce节点之间的数据传输量</strong>，以提高网络IO 性能，是MapReduce 的一种优化手段之一</p>
<ul>
<li><p>combiner是 MR 程序中 Mapper 和 Reducer 之外的一种组件</p>
</li>
<li><p><strong>combiner 组件的父类就是 Reducer</strong></p>
</li>
<li><p>combiner 和 reducer 的区别在于运行的位置</p>
<ul>
<li><p>combiner 是在每一个 map task 所在的节点运行</p>
</li>
<li><p>reducer 是接收全局所有 Mapper 的输出结果</p>
</li>
</ul>
</li>
<li><p>combiner 的意义就是对每一个 map task 的输出进行<strong>局部汇总</strong>，以减小网络传输量</p>
</li>
</ul>
<h3 id="步骤分析-3"><a href="#步骤分析-3" class="headerlink" title="步骤分析"></a>步骤分析</h3><ul>
<li>以wordcount为例</li>
</ul>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.13.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="第一步：自定义combiner继承-Reducer，继承Reducer类，重写reduce方法"><a href="#第一步：自定义combiner继承-Reducer，继承Reducer类，重写reduce方法" class="headerlink" title="第一步：自定义combiner继承 Reducer，继承Reducer类，重写reduce方法"></a>第一步：自定义combiner继承 Reducer，继承Reducer类，重写reduce方法</h3><ul>
<li><strong>这里直接复制了Reducer类中的代码，因为规约的本质是，在map端执行了reducer的代码，提前整合</strong></li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@time</span> 2021/1/10</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@auth</span> Gotcha</span><br><span class="hljs-comment"> * <span class="hljs-doctag">@describe</span></span><br><span class="hljs-comment"> * Reducer的泛型</span><br><span class="hljs-comment"> *  KEYIN:k2的类型     每个单词        Text</span><br><span class="hljs-comment"> *  VALUEIN:v2的类型   集合中泛型的类型  LongWritable</span><br><span class="hljs-comment"> *  KEYOUT:k3的类型    每个单词        Text</span><br><span class="hljs-comment"> *  VALUEOUT:v3的类型  出现的次数       LongWritable</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">CombinerReducer</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Reducer</span>&lt;<span class="hljs-title">Text</span>, <span class="hljs-title">LongWritable</span>,<span class="hljs-title">Text</span>, <span class="hljs-title">LongWritable</span>&gt; </span>&#123;<br>    <span class="hljs-comment">/**</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@describe</span> 是将k2,v2转换为k3,v3</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> key 表示k2</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> values 表示集合</span><br><span class="hljs-comment">     * <span class="hljs-doctag">@param</span> context 表示MapReduce上下文对象</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title">reduce</span><span class="hljs-params">(Text key, Iterable&lt;LongWritable&gt; values, Context context)</span> <span class="hljs-keyword">throws</span> IOException, InterruptedException </span>&#123;<br>        <span class="hljs-keyword">long</span> count = <span class="hljs-number">0</span>;<br>        <span class="hljs-comment">//1.遍历values集合</span><br>        <span class="hljs-keyword">for</span> (LongWritable value : values) &#123;<br>            <span class="hljs-comment">//2.将集合中值相加</span><br>            count+=value.get();<br>        &#125;<br>        <span class="hljs-comment">//3.将k3,v3写入上下文</span><br>        context.write(key,<span class="hljs-keyword">new</span> LongWritable(count));<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="第二步：在job中进行设置"><a href="#第二步：在job中进行设置" class="headerlink" title="第二步：在job中进行设置"></a>第二步：在job中进行设置</h3><ul>
<li>主要变化在于多了<strong>第五步，设置规约类</strong>，其他不变</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">JobMain</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Configured</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Tool</span> </span>&#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">run</span><span class="hljs-params">(String[] strings)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        <span class="hljs-comment">//创建一个任务对象</span><br>        Job job = Job.getInstance(<span class="hljs-keyword">super</span>.getConf(), <span class="hljs-string">&quot;计算单词出现次数&quot;</span>);<br>        <span class="hljs-comment">//打包到集群上面运行时候，必须要添加以下配置，指定程序的main函数</span><br>        job.setJarByClass(JobMain.class);<br><br>        <span class="hljs-comment">//第一步：设置读取文件的类，将文件解析成key，value对</span><br>        job.setInputFormatClass(TextInputFormat.class);<br>        TextInputFormat.addInputPath(job,<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020/wordcount&quot;</span>));<br>        <span class="hljs-comment">//第二步：设置mapper类</span><br>        job.setMapperClass(CombinerMapper.class);<br>            <span class="hljs-comment">//设置map阶段完成之后的输出类型</span><br>        job.setMapOutputKeyClass(Text.class);<br>        job.setMapOutputValueClass(LongWritable.class);<br>        <span class="hljs-comment">//第三步，第四步，第五步，第六步采用默认方式（分区、排序、规约、分组）</span><br>        <span class="hljs-comment">//第五步：设置规约类</span><br>        job.setCombinerClass(MyCombiner.class);<br>        <span class="hljs-comment">//第七步：设置reduce类</span><br>        job.setReducerClass(CombinerReducer.class);<br>            <span class="hljs-comment">//设置reduce阶段完成之后的输出类型</span><br>        job.setOutputKeyClass(Text.class);<br>        job.setOutputValueClass(LongWritable.class);<br>        <span class="hljs-comment">//第八步：设置输出类以及输出路径</span><br>        job.setOutputFormatClass(TextOutputFormat.class);<br>        TextOutputFormat.setOutputPath(job,<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020/wordcount_out&quot;</span>));<br>        <span class="hljs-comment">//任务是否执行成功</span><br>        <span class="hljs-keyword">boolean</span> b = job.waitForCompletion(<span class="hljs-keyword">true</span>);<br>        <span class="hljs-keyword">return</span> b?<span class="hljs-number">0</span>:<span class="hljs-number">1</span>;<br><br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        Configuration configuration = <span class="hljs-keyword">new</span> Configuration();<br>        <span class="hljs-comment">//启动一个任务</span><br>        <span class="hljs-keyword">int</span> run = ToolRunner.run(configuration, <span class="hljs-keyword">new</span> JobMain(), args);<br>        System.exit(run);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<ul>
<li>其他步骤同WordCount案例</li>
</ul>
<hr>
<h2 id="流量统计案例"><a href="#流量统计案例" class="headerlink" title="流量统计案例"></a>流量统计案例</h2><h3 id="数据准备"><a href="#数据准备" class="headerlink" title="数据准备"></a>数据准备</h3><p>有数据文件，内容如下</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs txt">1363157985066	13726230503	00-FD-07-A4-72-B8:CMCC	120.196.100.82	i02.c.aliimg.com	游戏娱乐	24	27	2481	24681	200<br>1363157995052 	13826544101	5C-0E-8B-C7-F1-E0:CMCC	120.197.40.4	jd.com	京东购物	4	0	264	0	200<br>1363157991076 	13926435656	20-10-7A-28-CC-0A:CMCC	120.196.100.99	taobao.com	淘宝购物	2	4	132	1512	200<br>1363154400022 	13926251106	5C-0E-8B-8B-B1-50:CMCC	120.197.40.4	cnblogs.com	技术门户	4	0	240	0	200<br>1363157993044 	18211575961	94-71-AC-CD-E6-18:CMCC-EASY	120.196.100.99	iface.qiyi.com	视频网站	15	12	1527	2106	200<br>1363157995074 	84138413	5C-0E-8B-8C-E8-20:7DaysInn	120.197.40.4	122.72.52.12	未知	20	16	4116	1432	200<br>1363157993055 	13560439658	C4-17-FE-BA-DE-D9:CMCC	120.196.100.99	sougou.com	综合门户	18	15	1116	954	200<br>1363157995033 	15920133257	5C-0E-8B-C7-BA-20:CMCC	120.197.40.4	sug.so.360.cn	信息安全	20	20	3156	2936	200<br>1363157983019 	13719199419	68-A1-B7-03-07-B1:CMCC-EASY	120.196.100.82	baidu.com	综合搜索	4	0	240	0	200<br>1363157984041 	13660577991	5C-0E-8B-92-5C-20:CMCC-EASY	120.197.40.4	s19.cnzz.com	站点统计	24	9	6960	690	200<br>1363157973098 	15013685858	5C-0E-8B-C7-F7-90:CMCC	120.197.40.4	rank.ie.sogou.com	搜索引擎	28	27	3659	3538	200<br>1363157986029 	15989002119	E8-99-C4-4E-93-E0:CMCC-EASY	120.196.100.99	www.umeng.com	站点统计	3	3	1938	180	200<br>1363157992093 	13560439658	C4-17-FE-BA-DE-D9:CMCC	120.196.100.99	zhilian.com	招聘门户	15	9	918	4938	200<br>1363157986041 	13480253104	5C-0E-8B-C7-FC-80:CMCC-EASY	120.197.40.4	csdn.net	技术门户	3	3	180	180	200<br>1363157984040 	13602846565	5C-0E-8B-8B-B6-00:CMCC	120.197.40.4	2052.flash2-http.qq.com	综合门户	15	12	1938	2910	200<br>1363157995093 	13922314466	00-FD-07-A2-EC-BA:CMCC	120.196.100.82	img.qfc.cn	图片大全	12	12	3008	3720	200<br>1363157982040 	13502468823	5C-0A-5B-6A-0B-D4:CMCC-EASY	120.196.100.99	y0.ifengimg.com	综合门户	57	102	7335	110349	200<br>1363157986072 	18320173382	84-25-DB-4F-10-1A:CMCC-EASY	120.196.100.99	input.shouji.sogou.com	搜索引擎	21	18	9531	2412	200<br>1363157990043 	13925057413	00-1F-64-E1-E6-9A:CMCC	120.196.100.55	t3.baidu.com	搜索引擎	69	63	11058	48243	200<br>1363157988072 	13760778710	00-FD-07-A4-7B-08:CMCC	120.196.100.82	http://youku.com/	视频网站	2	2	120	120	200<br>1363157985079 	13823070001	20-7C-8F-70-68-1F:CMCC	120.196.100.99	img.qfc.cn	图片浏览	6	3	360	180	200<br>1363157985069 	13600217502	00-1F-64-E2-E8-B1:CMCC	120.196.100.55	www.baidu.com	综合门户	18	138	1080	186852	200<br></code></pre></td></tr></table></figure>

<p>各字段含义如下</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.14.jpg" srcset="/img/loading.gif" lazyload></p>
<ul>
<li><p>将文件上传到服务器</p>
</li>
<li><p>将文件上传上传到 HDFS</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">hdfs dfs -mkdir /input/flowcount<br>hdfs dfs -put data_flow.dat /input/flowcount<br></code></pre></td></tr></table></figure>

<h3 id="需求一：统计求和"><a href="#需求一：统计求和" class="headerlink" title="需求一：统计求和"></a>需求一：统计求和</h3><p>统计每个手机号的上行流量总和，下行流量总和，上行总流量之和，下行总流量之和<br>分析：以手机号码作为key值，上行流量，下行流量，上行总流量，下行总流量四个字段作为value值，然后以这个key，和value作为map阶段的输出，reduce阶段的输入</p>
<h4 id="步骤分析-4"><a href="#步骤分析-4" class="headerlink" title="步骤分析"></a>步骤分析</h4><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.15.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="第一步：自定义Bean实现Writable接口"><a href="#第一步：自定义Bean实现Writable接口" class="headerlink" title="第一步：自定义Bean实现Writable接口"></a>第一步：自定义Bean实现Writable接口</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FlowBean</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Writable</span> </span>&#123;<br>    <span class="hljs-keyword">private</span> Integer upFlow;<br>    <span class="hljs-keyword">private</span> Integer downFlow;<br>    <span class="hljs-keyword">private</span> Integer upCountFlow;<br>    <span class="hljs-keyword">private</span> Integer downCountFlow;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> Integer <span class="hljs-title">getUpFlow</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> upFlow;<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setUpFlow</span><span class="hljs-params">(Integer upFlow)</span> </span>&#123;<br>        <span class="hljs-keyword">this</span>.upFlow = upFlow;<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> Integer <span class="hljs-title">getDownFlow</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> downFlow;<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setDownFlow</span><span class="hljs-params">(Integer downFlow)</span> </span>&#123;<br>        <span class="hljs-keyword">this</span>.downFlow = downFlow;<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> Integer <span class="hljs-title">getUpCountFlow</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> upCountFlow;<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setUpCountFlow</span><span class="hljs-params">(Integer upCountFlow)</span> </span>&#123;<br>        <span class="hljs-keyword">this</span>.upCountFlow = upCountFlow;<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> Integer <span class="hljs-title">getDownCountFlow</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> downCountFlow;<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setDownCountFlow</span><span class="hljs-params">(Integer downCountFlow)</span> </span>&#123;<br>        <span class="hljs-keyword">this</span>.downCountFlow = downCountFlow;<br>    &#125;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">toString</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> upFlow +<br>                <span class="hljs-string">&quot;\t&quot;</span> + downFlow +<br>                <span class="hljs-string">&quot;\t&quot;</span> + upCountFlow +<br>                <span class="hljs-string">&quot;\t&quot;</span> + downCountFlow;<br>    &#125;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">write</span><span class="hljs-params">(DataOutput dataOutput)</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>        dataOutput.writeInt(upFlow);<br>        dataOutput.writeInt(downFlow);<br>        dataOutput.writeInt(upCountFlow);<br>        dataOutput.writeInt(downCountFlow);<br>    &#125;<br><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">readFields</span><span class="hljs-params">(DataInput dataInput)</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>        <span class="hljs-keyword">this</span>.upFlow = dataInput.readInt();<br>        <span class="hljs-keyword">this</span>.downFlow = dataInput.readInt();<br>        <span class="hljs-keyword">this</span>.upCountFlow = dataInput.readInt();<br>        <span class="hljs-keyword">this</span>.downCountFlow = dataInput.readInt();<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="第二步：Mapper类编写"><a href="#第二步：Mapper类编写" class="headerlink" title="第二步：Mapper类编写"></a>第二步：Mapper类编写</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FlowCountMapper</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Mapper</span>&lt;<span class="hljs-title">LongWritable</span>,<span class="hljs-title">Text</span>, <span class="hljs-title">Text</span>, <span class="hljs-title">FlowBean</span>&gt; </span>&#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title">map</span><span class="hljs-params">(LongWritable key, Text value, Context context)</span> <span class="hljs-keyword">throws</span> IOException, InterruptedException </span>&#123;<br>        <span class="hljs-comment">//1.对每行数据进行字符串拆分</span><br>        String[] split = value.toString().split(<span class="hljs-string">&quot;\t&quot;</span>);<br>        <span class="hljs-comment">//2.获取手机号</span><br>        String phoneNum = split[<span class="hljs-number">1</span>];<br>        <span class="hljs-comment">//3.获取四个流量字段</span><br>        FlowBean flowBean = <span class="hljs-keyword">new</span> FlowBean();<br>        flowBean.setUpFlow(Integer.parseInt(split[<span class="hljs-number">6</span>]));<br>        flowBean.setDownFlow(Integer.parseInt(split[<span class="hljs-number">7</span>]));<br>        flowBean.setUpCountFlow(Integer.parseInt(split[<span class="hljs-number">8</span>]));<br>        flowBean.setDownCountFlow(Integer.parseInt(split[<span class="hljs-number">9</span>]));<br>        <span class="hljs-comment">//4.将k2,v2写入上下文</span><br>        context.write(<span class="hljs-keyword">new</span> Text(phoneNum),flowBean);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="第三步：Reducer类编写"><a href="#第三步：Reducer类编写" class="headerlink" title="第三步：Reducer类编写"></a>第三步：Reducer类编写</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FlowCountReducer</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Reducer</span>&lt;<span class="hljs-title">Text</span>, <span class="hljs-title">FlowBean</span>,<span class="hljs-title">Text</span>, <span class="hljs-title">FlowBean</span>&gt; </span>&#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title">reduce</span><span class="hljs-params">(Text key, Iterable&lt;FlowBean&gt; values, Context context)</span> <span class="hljs-keyword">throws</span> IOException, InterruptedException </span>&#123;<br>        <span class="hljs-comment">//封装新的flowBean</span><br>        FlowBean flowBean = <span class="hljs-keyword">new</span> FlowBean();<br>        Integer upFlow = <span class="hljs-number">0</span> ;<br>        Integer downFlow = <span class="hljs-number">0</span> ;<br>        Integer upCountFlow = <span class="hljs-number">0</span> ;<br>        Integer downCountFlow = <span class="hljs-number">0</span> ;<br>        <span class="hljs-keyword">for</span> (FlowBean value : values) &#123;<br>            upFlow+=value.getUpFlow();<br>            downFlow+=value.getDownFlow();<br>            upCountFlow+=value.getUpCountFlow();<br>            downCountFlow+=value.getDownCountFlow();<br>        &#125;<br>        flowBean.setUpFlow(upFlow);<br>        flowBean.setDownFlow(downFlow);<br>        flowBean.setUpCountFlow(upCountFlow);<br>        flowBean.setDownCountFlow(downCountFlow);<br>        <span class="hljs-comment">//将k3,v3写入上下文</span><br>        context.write(key,flowBean);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="第四步：定义主类job"><a href="#第四步：定义主类job" class="headerlink" title="第四步：定义主类job"></a>第四步：定义主类job</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">JobMain</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Configured</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Tool</span> </span>&#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">run</span><span class="hljs-params">(String[] strings)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        <span class="hljs-comment">//创建一个任务对象</span><br>        Job job = Job.getInstance(<span class="hljs-keyword">super</span>.getConf(), <span class="hljs-string">&quot;流量统计&quot;</span>);<br>        <span class="hljs-comment">//打包到集群上面运行时候，必须要添加以下配置，指定程序的main函数</span><br>        job.setJarByClass(JobMain.class);<br><br>        <span class="hljs-comment">//第一步：设置读取文件的类，将文件解析成key，value对</span><br>        job.setInputFormatClass(TextInputFormat.class);<br>        TextInputFormat.addInputPath(job,<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020/input/flowcount&quot;</span>));<br>        <span class="hljs-comment">//第二步：设置mapper类</span><br>        job.setMapperClass(FlowCountMapper.class);<br>            <span class="hljs-comment">//设置map阶段完成之后的输出类型</span><br>        job.setMapOutputKeyClass(Text.class);<br>        job.setMapOutputValueClass(FlowBean.class);<br>        <span class="hljs-comment">//第三步，第四步，第五步，第六步采用默认方式（分区、排序、规约、分组）</span><br>        <span class="hljs-comment">//第七步：设置reduce类</span><br>        job.setReducerClass(FlowCountReducer.class);<br>            <span class="hljs-comment">//设置reduce阶段完成之后的输出类型</span><br>        job.setOutputKeyClass(Text.class);<br>        job.setOutputValueClass(FlowBean.class);<br>        <span class="hljs-comment">//第八步：设置输出类以及输出路径</span><br>        job.setOutputFormatClass(TextOutputFormat.class);<br>        TextOutputFormat.setOutputPath(job,<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020/output/flowcount_out&quot;</span>));<br>        <span class="hljs-comment">//任务是否执行成功</span><br>        <span class="hljs-keyword">boolean</span> b = job.waitForCompletion(<span class="hljs-keyword">true</span>);<br>        <span class="hljs-keyword">return</span> b?<span class="hljs-number">0</span>:<span class="hljs-number">1</span>;<br><br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        Configuration configuration = <span class="hljs-keyword">new</span> Configuration();<br>        <span class="hljs-comment">//启动一个任务</span><br>        <span class="hljs-keyword">int</span> run = ToolRunner.run(configuration, <span class="hljs-keyword">new</span> JobMain(), args);<br>        System.exit(run);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="第五步：打成jar包上传至服务器，并在服务器运行-2"><a href="#第五步：打成jar包上传至服务器，并在服务器运行-2" class="headerlink" title="第五步：打成jar包上传至服务器，并在服务器运行"></a>第五步：打成jar包上传至服务器，并在服务器运行</h4><p><code>hadoop jar /export/softwares/mapReduce-1.0-SNAPSHOT.jar top.igotcha.mapreduce.flowcount.JobMain</code></p>
<p>生成的结果文件如下</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.16.png" srcset="/img/loading.gif" lazyload></p>
<hr>
<h3 id="需求二：上行流量倒序排序"><a href="#需求二：上行流量倒序排序" class="headerlink" title="需求二：上行流量倒序排序"></a>需求二：上行流量倒序排序</h3><p>分析，以需求一的输出数据作为排序的输入数据，自定义FlowBean，以FlowBean为map输出的key，以手机号作为Map输出的value，因为MapReduce程序会对Map阶段输出的key进行排序</p>
<h4 id="第一步：自定义Bean实现WritableComparable接口"><a href="#第一步：自定义Bean实现WritableComparable接口" class="headerlink" title="第一步：自定义Bean实现WritableComparable接口"></a>第一步：自定义Bean实现WritableComparable接口</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FlowBean</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">WritableComparable</span>&lt;<span class="hljs-title">FlowBean</span>&gt; </span>&#123;<br>    <span class="hljs-keyword">private</span> Integer upFlow;<br>    <span class="hljs-keyword">private</span> Integer downFlow;<br>    <span class="hljs-keyword">private</span> Integer upCountFlow;<br>    <span class="hljs-keyword">private</span> Integer downCountFlow;<br><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> Integer <span class="hljs-title">getUpFlow</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> upFlow;<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setUpFlow</span><span class="hljs-params">(Integer upFlow)</span> </span>&#123;<br>        <span class="hljs-keyword">this</span>.upFlow = upFlow;<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> Integer <span class="hljs-title">getDownFlow</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> downFlow;<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setDownFlow</span><span class="hljs-params">(Integer downFlow)</span> </span>&#123;<br>        <span class="hljs-keyword">this</span>.downFlow = downFlow;<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> Integer <span class="hljs-title">getUpCountFlow</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> upCountFlow;<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setUpCountFlow</span><span class="hljs-params">(Integer upCountFlow)</span> </span>&#123;<br>        <span class="hljs-keyword">this</span>.upCountFlow = upCountFlow;<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> Integer <span class="hljs-title">getDownCountFlow</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> downCountFlow;<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setDownCountFlow</span><span class="hljs-params">(Integer downCountFlow)</span> </span>&#123;<br>        <span class="hljs-keyword">this</span>.downCountFlow = downCountFlow;<br>    &#125;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">toString</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> upFlow +<br>                <span class="hljs-string">&quot;\t&quot;</span> + downFlow +<br>                <span class="hljs-string">&quot;\t&quot;</span> + upCountFlow +<br>                <span class="hljs-string">&quot;\t&quot;</span> + downCountFlow;<br>    &#125;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">write</span><span class="hljs-params">(DataOutput dataOutput)</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>        dataOutput.writeInt(upFlow);<br>        dataOutput.writeInt(downFlow);<br>        dataOutput.writeInt(upCountFlow);<br>        dataOutput.writeInt(downCountFlow);<br>    &#125;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">readFields</span><span class="hljs-params">(DataInput dataInput)</span> <span class="hljs-keyword">throws</span> IOException </span>&#123;<br>        <span class="hljs-keyword">this</span>.upFlow = dataInput.readInt();<br>        <span class="hljs-keyword">this</span>.downFlow = dataInput.readInt();<br>        <span class="hljs-keyword">this</span>.upCountFlow = dataInput.readInt();<br>        <span class="hljs-keyword">this</span>.downCountFlow = dataInput.readInt();<br>    &#125;<br>    <span class="hljs-comment">//按照上行数据包倒序排序</span><br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">compareTo</span><span class="hljs-params">(FlowBean others)</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-keyword">this</span>.getUpFlow().compareTo(others.getUpFlow())*-<span class="hljs-number">1</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="第二步：Mapper编写-1"><a href="#第二步：Mapper编写-1" class="headerlink" title="第二步：Mapper编写"></a>第二步：Mapper编写</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FlowSortMapper</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Mapper</span>&lt;<span class="hljs-title">LongWritable</span>,<span class="hljs-title">Text</span>, <span class="hljs-title">FlowBean</span>,<span class="hljs-title">Text</span>&gt; </span>&#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title">map</span><span class="hljs-params">(LongWritable key, Text value, Context context)</span> <span class="hljs-keyword">throws</span> IOException, InterruptedException </span>&#123;<br>        <span class="hljs-comment">//1.对每行数据进行字符串拆分</span><br>        String[] split = value.toString().split(<span class="hljs-string">&quot;\t&quot;</span>);<br>        <span class="hljs-comment">//2.获取手机号</span><br>        String phoneNum = split[<span class="hljs-number">0</span>];<br>        <span class="hljs-comment">//3.获取四个流量字段</span><br>        FlowBean flowBean = <span class="hljs-keyword">new</span> FlowBean();<br>        flowBean.setUpFlow(Integer.parseInt(split[<span class="hljs-number">1</span>]));<br>        flowBean.setDownFlow(Integer.parseInt(split[<span class="hljs-number">2</span>]));<br>        flowBean.setUpCountFlow(Integer.parseInt(split[<span class="hljs-number">3</span>]));<br>        flowBean.setDownCountFlow(Integer.parseInt(split[<span class="hljs-number">4</span>]));<br>        <span class="hljs-comment">//4.将k2,v2写入上下文</span><br>        context.write(flowBean,<span class="hljs-keyword">new</span> Text(phoneNum));<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="第三步：FlowSortReducer编写"><a href="#第三步：FlowSortReducer编写" class="headerlink" title="第三步：FlowSortReducer编写"></a>第三步：FlowSortReducer编写</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FlowSortReducer</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Reducer</span>&lt;<span class="hljs-title">FlowBean</span>,<span class="hljs-title">Text</span>,<span class="hljs-title">Text</span>, <span class="hljs-title">FlowBean</span>&gt; </span>&#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title">reduce</span><span class="hljs-params">(FlowBean key, Iterable&lt;Text&gt; values, Context context)</span> <span class="hljs-keyword">throws</span> IOException, InterruptedException </span>&#123;<br>        <span class="hljs-keyword">for</span> (Text value : values) &#123;<br>            context.write(value,key);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="第四步：定义主类job-1"><a href="#第四步：定义主类job-1" class="headerlink" title="第四步：定义主类job"></a>第四步：定义主类job</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">JobMain</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Configured</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Tool</span> </span>&#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">run</span><span class="hljs-params">(String[] strings)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        <span class="hljs-comment">//创建一个任务对象</span><br>        Job job = Job.getInstance(<span class="hljs-keyword">super</span>.getConf(), <span class="hljs-string">&quot;流量统计-按上行流量倒序&quot;</span>);<br>        <span class="hljs-comment">//打包到集群上面运行时候，必须要添加以下配置，指定程序的main函数</span><br>        job.setJarByClass(JobMain.class);<br><br>        <span class="hljs-comment">//第一步：设置读取文件的类，将文件解析成key，value对</span><br>        job.setInputFormatClass(TextInputFormat.class);<br>        TextInputFormat.addInputPath(job,<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020/output/flowcount_out&quot;</span>));<br>        <span class="hljs-comment">//第二步：设置mapper类</span><br>        job.setMapperClass(FlowSortMapper.class);<br>            <span class="hljs-comment">//设置map阶段完成之后的输出类型</span><br>        job.setMapOutputKeyClass(FlowBean.class);<br>        job.setMapOutputValueClass(Text.class);<br>        <span class="hljs-comment">//第三步，第四步，第五步，第六步采用默认方式（分区、排序、规约、分组）</span><br>        <span class="hljs-comment">//第七步：设置reduce类</span><br>        job.setReducerClass(FlowSortReducer.class);<br>            <span class="hljs-comment">//设置reduce阶段完成之后的输出类型</span><br>        job.setOutputKeyClass(Text.class);<br>        job.setOutputValueClass(FlowBean.class);<br>        <span class="hljs-comment">//第八步：设置输出类以及输出路径</span><br>        job.setOutputFormatClass(TextOutputFormat.class);<br>        TextOutputFormat.setOutputPath(job,<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020/output/flowsort_out&quot;</span>));<br>        <span class="hljs-comment">//任务是否执行成功</span><br>        <span class="hljs-keyword">boolean</span> b = job.waitForCompletion(<span class="hljs-keyword">true</span>);<br>        <span class="hljs-keyword">return</span> b?<span class="hljs-number">0</span>:<span class="hljs-number">1</span>;<br><br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        Configuration configuration = <span class="hljs-keyword">new</span> Configuration();<br>        <span class="hljs-comment">//启动一个任务</span><br>        <span class="hljs-keyword">int</span> run = ToolRunner.run(configuration, <span class="hljs-keyword">new</span> JobMain(), args);<br>        System.exit(run);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="第五步：打成jar包上传至服务器，并在服务器运行-3"><a href="#第五步：打成jar包上传至服务器，并在服务器运行-3" class="headerlink" title="第五步：打成jar包上传至服务器，并在服务器运行"></a>第五步：打成jar包上传至服务器，并在服务器运行</h4><p><code>hadoop jar /export/softwares/mapReduce-1.0-SNAPSHOT.jar top.igotcha.mapreduce.flowsort.JobMain</code></p>
<p>生成的已排序结果文件如下</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.17.png" srcset="/img/loading.gif" lazyload></p>
<hr>
<h3 id="需求三：手机号码分区"><a href="#需求三：手机号码分区" class="headerlink" title="需求三：手机号码分区"></a>需求三：手机号码分区</h3><p>分析，在需求二的基础上，继续完善，将不同的手机号分到不同的数据文件的当中去，需要自定义分区来实现，将以下数字开头的手机号进行分开</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs">135 开头数据到一个分区文件<br>136 开头数据到一个分区文件<br>137 开头数据到一个分区文件<br>其他分区<br></code></pre></td></tr></table></figure>

<h4 id="第一步：自定义Partitioner"><a href="#第一步：自定义Partitioner" class="headerlink" title="第一步：自定义Partitioner"></a>第一步：自定义Partitioner</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">FlowPartition</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Partitioner</span>&lt;<span class="hljs-title">FlowBean</span>, <span class="hljs-title">Text</span>&gt; </span>&#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">getPartition</span><span class="hljs-params">(FlowBean flowBean, Text text, <span class="hljs-keyword">int</span> i)</span> </span>&#123;<br>        String phoneNum = text.toString();<br>        String phoneStart = phoneNum.substring(<span class="hljs-number">0</span>,<span class="hljs-number">3</span>);<br>        <span class="hljs-keyword">switch</span> (phoneStart)&#123;<br>            <span class="hljs-keyword">case</span> <span class="hljs-string">&quot;135&quot;</span>:<br>                <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>            <span class="hljs-keyword">case</span> <span class="hljs-string">&quot;136&quot;</span>:<br>                <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br>            <span class="hljs-keyword">case</span> <span class="hljs-string">&quot;137&quot;</span>:<br>                <span class="hljs-keyword">return</span> <span class="hljs-number">2</span>;<br>            <span class="hljs-keyword">default</span>:<br>                <span class="hljs-keyword">return</span> <span class="hljs-number">3</span>;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h4 id="第二步：定义主类job"><a href="#第二步：定义主类job" class="headerlink" title="第二步：定义主类job"></a>第二步：定义主类job</h4><p>主要变化在于多了<strong>第三步，设置分区类</strong>，在<strong>第七步：设置reduce类</strong>中<strong>设置reduce个数</strong>，其他不变</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">JobMain</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Configured</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Tool</span> </span>&#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">run</span><span class="hljs-params">(String[] strings)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        <span class="hljs-comment">//创建一个任务对象</span><br>        Job job = Job.getInstance(<span class="hljs-keyword">super</span>.getConf(), <span class="hljs-string">&quot;流量统计-按上行流量倒序&quot;</span>);<br>        <span class="hljs-comment">//打包到集群上面运行时候，必须要添加以下配置，指定程序的main函数</span><br>        job.setJarByClass(JobMain.class);<br><br>        <span class="hljs-comment">//第一步：设置读取文件的类，将文件解析成key，value对</span><br>        job.setInputFormatClass(TextInputFormat.class);<br>        TextInputFormat.addInputPath(job,<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020/output/flowcount_out&quot;</span>));<br>        <span class="hljs-comment">//第二步：设置mapper类</span><br>        job.setMapperClass(FlowSortMapper.class);<br>            <span class="hljs-comment">//设置map阶段完成之后的输出类型</span><br>        job.setMapOutputKeyClass(FlowBean.class);<br>        job.setMapOutputValueClass(Text.class);<br>        <span class="hljs-comment">//第三步，第四步，第五步，第六步采用默认方式（分区、排序、规约、分组）</span><br>        <span class="hljs-comment">//第三步，设置分区类</span><br>        job.setPartitionerClass(FlowPartition.class);<br>        <span class="hljs-comment">//第七步：设置reduce类</span><br>        job.setReducerClass(FlowSortReducer.class);<br>            <span class="hljs-comment">//设置reduce阶段完成之后的输出类型</span><br>        job.setOutputKeyClass(Text.class);<br>        job.setOutputValueClass(FlowBean.class);<br>        <span class="hljs-comment">//设置reduce个数</span><br>        job.setNumReduceTasks(<span class="hljs-number">4</span>);<br>        <span class="hljs-comment">//第八步：设置输出类以及输出路径</span><br>        job.setOutputFormatClass(TextOutputFormat.class);<br>        TextOutputFormat.setOutputPath(job,<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020/output/flowpartition_out&quot;</span>));<br>        <span class="hljs-comment">//任务是否执行成功</span><br>        <span class="hljs-keyword">boolean</span> b = job.waitForCompletion(<span class="hljs-keyword">true</span>);<br>        <span class="hljs-keyword">return</span> b?<span class="hljs-number">0</span>:<span class="hljs-number">1</span>;<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        Configuration configuration = <span class="hljs-keyword">new</span> Configuration();<br>        <span class="hljs-comment">//启动一个任务</span><br>        <span class="hljs-keyword">int</span> run = ToolRunner.run(configuration, <span class="hljs-keyword">new</span> JobMain(), args);<br>        System.exit(run);<br>    &#125;<br>&#125;<br><br></code></pre></td></tr></table></figure>

<h4 id="第三步：打成jar包上传至服务器，并在服务器运行"><a href="#第三步：打成jar包上传至服务器，并在服务器运行" class="headerlink" title="第三步：打成jar包上传至服务器，并在服务器运行"></a>第三步：打成jar包上传至服务器，并在服务器运行</h4><p><strong>保持Bean类、Mapper类和Reducer类不变，上传至服务器并运行</strong>，产生了四个结果文件</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.18.png" srcset="/img/loading.gif" lazyload></p>
<hr>
<h2 id="MapReduce运行机制"><a href="#MapReduce运行机制" class="headerlink" title="MapReduce运行机制"></a>MapReduce运行机制</h2><h3 id="概述-5"><a href="#概述-5" class="headerlink" title="概述"></a>概述</h3><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.19.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="Map阶段-1"><a href="#Map阶段-1" class="headerlink" title="Map阶段"></a>Map阶段</h3><h4 id="概述-6"><a href="#概述-6" class="headerlink" title="概述"></a>概述</h4><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.20.png" srcset="/img/loading.gif" lazyload></p>
<p>整个Map阶段流程大体如上图所示。<br>简单概述：inputFile通过split被逻辑切分为多个split文件，通过Record<strong>按行读取</strong>内容给map（用户自己实现的）进行处理，数据被map处理结束之后交给OutputCollector收集器，对其结果key进行分区（默认使用hash分区），然后写入buffer，每个map task都有一个内存缓冲区，存储着map的输出结果，当缓冲区快满的时候需要将缓冲区的数据以一个临时文件的方式存放到磁盘，当整个map task结束后再对磁盘中这个map task产生的所有临时文件做合并，生成最终的正式输出文件，然后等待reduce task来拉数据</p>
<h4 id="详细步骤"><a href="#详细步骤" class="headerlink" title="详细步骤"></a>详细步骤</h4><ul>
<li>读取数据组件 InputFormat (默认 TextInputFormat) 会通过 getSplits 方法对输入目录中文件进行<strong>逻辑切片规划得到 splits</strong>，有多少个 split 就对应启动多少个<br>MapTask。split 与 block 的对应关系默认是一对一</li>
<li>将输入文件切分为 splits 之后，由 RecordReader 对象 (默认是LineRecordReader)进行读取，以 \n 作为分隔符，<strong>读取一行数据</strong>，返回 &lt;key，value&gt; 。Key 表示每行首字符偏移值，Value 表示这一行文本内容</li>
<li>读取split返回 &lt;key,value&gt;，进入用户自己继承的 Mapper 类中，<strong>执行用户重写的 map 函数</strong>，RecordReader 读取一行这里调用一次</li>
<li>Mapper 逻辑结束之后, 将 Mapper 的每条结果通过 context.write <strong>进行collect数据收集</strong>。在 collect 中, 会先对其进行分区处理，默认使用 HashPartitioner<ul>
<li>MapReduce 提供 Partitioner 接口, 它的作用就是根据 Key 或 Value 及Reducer 的数量来决定当前的这对输出数据最终应该交由哪个 Reduce task<br>处理，默认对 Key Hash 后再以 Reducer 数量取模。默认的取模方式只是为了平均 Reducer 的处理能力，如果用户自己对 Partitioner 有需求，可以自定义后，再到 Job 上进行设置</li>
</ul>
</li>
<li>接下来，会将数据写入内存，内存中这片区域叫做<strong>环形缓冲区</strong>，缓冲区的作用是批量收集Mapper 结果，减少磁盘 IO 的影响。Key/Value 对以及 Partition 的结果都会被写入缓冲区。当然，写入之前，Key 与 Value 值都会被序列化成字节数组<ul>
<li>环形缓冲区其实是一个数组，数组中存放着 Key，Value 的序列化数据和 Key。Value 的元数据信息，包括 Partition，Key 的起始位置，Value 的起始位置以及Value 的长度。环形结构是一个抽象概念</li>
<li>缓冲区是有大小限制，默认是 100MB。当 Mapper 的输出结果很多时，就可能会撑爆内存，所以需要在一定条件下将缓冲区中的数据临时写入磁盘，然后重新利用这块缓冲区。这个从内存往磁盘写数据的过程被称为 Spill，中文可译为<strong>溢写</strong>。这个溢写是由单独线程来完成，不影响往缓冲区写 Mapper 结果的线程。<br>溢写线程启动时不应该阻止 Mapper 的结果输出，所以整个缓冲区有个溢写的比例 spill.percent。这个比例默认是 0.8，也就是当缓冲区的数据已经达到<br>阈值 buffer size * spill percent = 100MB * 0.8 = 80MB ，溢写线程启动，锁定这 80MB 的内存，执行溢写过程。Mapper 的输出结果还可以往剩下的20MB 内存中写，互不影响</li>
</ul>
</li>
<li>当溢写线程启动后，需要对这 80MB 空间内的 Key 做排序 (Sort)。排序是 MapReduce模型默认的行为，这里的排序也是<strong>对序列化的字节做的排序</strong><ul>
<li>如果 Job 设置过 Combiner，那么现在就是使用 Combiner 的时候了。将有相同 Key 的 Key/Value 对的 Value 加起来，减少溢写到磁盘的数据量。Combiner 会优化 MapReduce 的中间结果，所以它在整个模型中会多次使用</li>
<li>那哪些场景才能使用 Combiner 呢？从这里分析，Combiner 的输出是Reducer 的输入，<strong>Combiner 绝不能改变最终的计算结果</strong>。Combiner 只应该用<br>于那种 Reduce 的输入 Key/Value 与输出 Key/Value 类型完全一致，且不影响最终结果的场景。比如累加，最大值等。Combiner 的使用一定得慎重，如果用好，它对 Job 执行效率有帮助，反之会影响 Reducer 的最终结果</li>
</ul>
</li>
<li><strong>合并溢写文件</strong>，每次溢写会在磁盘上生成一个临时文件 (写之前判断是否有 Combiner)，如果 Mapper 的输出结果真的很大，有多次这样的溢写发生，磁盘上相应的就会有多个临时文件存在。当整个数据处理结束之后开始对磁盘中的临时文件进行 Merge 合并，因为<strong>最终的文件只有一个</strong>，写入磁盘，并且为这个文件提供了一个索引文件，以记录每个reduce对应数据的偏移量</li>
</ul>
<h4 id="常用配置"><a href="#常用配置" class="headerlink" title="常用配置"></a>常用配置</h4><table>
<thead>
<tr>
<th>配置</th>
<th>默认值</th>
<th>解释</th>
</tr>
</thead>
<tbody><tr>
<td><code>mapreduce.task.io.sort.mb</code></td>
<td>100</td>
<td>环型缓冲区的内存值大小</td>
</tr>
<tr>
<td><code>mapreduce.map.sort.spill.percent</code></td>
<td>0.8</td>
<td>溢写的比例</td>
</tr>
<tr>
<td><code>mapreduce.cluster.local.dir</code></td>
<td><code>$&#123;hadoop.tmp.dir&#125;/mapred/local</code></td>
<td>溢写数据目录</td>
</tr>
<tr>
<td><code>mapreduce.task.io.sort.factor</code></td>
<td>10</td>
<td>一次合并多少个溢写文件</td>
</tr>
</tbody></table>
<h3 id="Reduce阶段-1"><a href="#Reduce阶段-1" class="headerlink" title="Reduce阶段"></a>Reduce阶段</h3><h4 id="概述-7"><a href="#概述-7" class="headerlink" title="概述"></a>概述</h4><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.21.png" srcset="/img/loading.gif" lazyload></p>
<p>整个Reduce阶段流程大体如上图所示。<br>简单概述：Reduce 大致分为 copy、sort、reduce 三个阶段，重点在前两个阶段。</p>
<p>copy 阶段包含一个 eventFetcher 来获取已完成的 map 列表，由 Fetcher 线程去 copy 数据，在此过程中会启动两个 merge 线程，分别为 inMemoryMerger 和 onDiskMerger，分别将内存中的数据 merge 到磁盘和将磁盘中的数据进行 merge。待数据 copy 完成之后，copy 阶段就完成了，开始进行 sort 阶段，sort 阶段主要是执行 finalMerge 操作，纯粹的 sort 阶段，完成之后就是 reduce 阶段，调用用户定义的 reduce 函数进行处理</p>
<h4 id="详细步骤-1"><a href="#详细步骤-1" class="headerlink" title="详细步骤"></a>详细步骤</h4><ul>
<li><strong>Copy阶段，简单地拉取数据</strong>。Reduce进程启动一些数据copy线程(Fetcher)，通过HTTP方式请求maptask获取属于自己的文件。</li>
<li><strong>Merge阶段</strong>。这里的merge如map端的merge动作，只是数组中存放的是不同map端copy来的数值。Copy过来的数据会先放入内存缓冲区中，这里的缓冲区大小要比map端的更为灵活。merge有三种形式：内存到内存；内存到磁盘；磁盘到磁盘。默认情况下第一种形式不启用。当内存中的数据量到达一定阈值，就启动内存到磁盘的merge。与map 端类似，这也是溢写的过程，这个过程中如果你设置有Combiner，也是会启用的，然后在磁盘中生成了众多的溢写文件。第二种merge方式一直在运行，直到没有map端的数据时才结束，然后启动第三种磁盘到磁盘的merge方式生成最终的文件。</li>
<li><strong>合并排序</strong>。把分散的数据合并成一个大的数据后，还会再对合并后的数据排序。</li>
<li>对排序后的键值对调用<strong>reduce方法</strong>，键相等的键值对调用一次reduce方法，每次调用会产生零个或者多个键值对，最后把这些输出的键值对写入到HDFS文件中。</li>
</ul>
<h3 id="Shuffle阶段-1"><a href="#Shuffle阶段-1" class="headerlink" title="Shuffle阶段"></a>Shuffle阶段</h3><h4 id="概述-8"><a href="#概述-8" class="headerlink" title="概述"></a>概述</h4><p>map 阶段处理的数据如何传递给 reduc 阶段，是 MapReduce 框架中最关键的一个流程，这个流程就叫 <strong>shuffle</strong><br>shuffle: 洗牌、发牌 ——（核心机制：数据<strong>分区，排序，分组，规约</strong>，合并等过程）</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.22.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="详细步骤-2"><a href="#详细步骤-2" class="headerlink" title="详细步骤"></a>详细步骤</h4><p>shuffle 是 Mapreduce 的核心，它分布在 Mapreduce 的 map 阶段和 reduce 阶段。一般把从 Map 产生输出开始到 Reduce 取得数据作为输入之前的过程称作 shuffle。</p>
<ul>
<li><strong>Collect阶段</strong>：将 MapTask 的结果输出到默认大小为 100M 的环形缓冲区，保存的是key/value，Partition 分区信息等。</li>
<li><strong>Spill阶段</strong>：当内存中的数据量达到一定的阀值的时候，就会将数据写入本地磁盘，再将数据写入磁盘之前需要对数据进行一次排序的操作，如果配置了 combiner，还会将有相同分区号和 key 的数据进行排序。</li>
<li><strong>Merge阶段</strong>：把所有溢出的临时文件进行一次合并操作，以确保一个 MapTask 最终只产生一个中间数据文件。</li>
<li><strong>Copy阶段</strong>：ReduceTask 启动 Fetcher 线程到已经完成 MapTask 的节点上复制一份属于自己的数据，这些数据默认会保存在内存的缓冲区中，当内存的缓冲区达到一定的阀值的时候，就会将数据写到磁盘之上。</li>
<li><strong>Merge阶段</strong>：在 ReduceTask 远程复制数据的同时，会在后台开启两个线程对内存到本地的数据文件进行合并操作。</li>
<li><strong>Sort阶段</strong>：在对数据进行合并的同时，会进行排序操作，由于 MapTask 阶段已经对数据进行了局部的排序，ReduceTask 只需保证 Copy 的数据的最终整体有效性即可。</li>
</ul>
<blockquote>
<p>Shuffle 中的缓冲区大小会影响到 mapreduce 程序的执行效率，原则上说，缓冲区越大，磁盘io的次数越少，执行速度就越快</p>
</blockquote>
<h2 id="Join案例"><a href="#Join案例" class="headerlink" title="Join案例"></a>Join案例</h2><h3 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h3><p>假如数据量巨大，两表的数据是以文件的形式存储在 HDFS 中, 需要用 MapReduce 程序来实现以下 SQL 查询运算</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> a.id,a.date,b.name,b.category_id,b.price <span class="hljs-keyword">from</span> t_order a <span class="hljs-keyword">left</span> <span class="hljs-keyword">join</span> t_product b <span class="hljs-keyword">on</span> a.pid <span class="hljs-operator">=</span> b.id<br></code></pre></td></tr></table></figure>

<ul>
<li>订单数据表</li>
</ul>
<table>
<thead>
<tr>
<th>id</th>
<th>date</th>
<th>pid</th>
<th>amount</th>
</tr>
</thead>
<tbody><tr>
<td>1001</td>
<td>20150710</td>
<td>P0001</td>
<td>2</td>
</tr>
<tr>
<td>1002</td>
<td>20150710</td>
<td>P0001</td>
<td>3</td>
</tr>
<tr>
<td>1003</td>
<td>20150710</td>
<td>P0002</td>
<td>3</td>
</tr>
</tbody></table>
<ul>
<li>商品信息表</li>
</ul>
<table>
<thead>
<tr>
<th>id</th>
<th>pname</th>
<th>category_id</th>
<th>price</th>
</tr>
</thead>
<tbody><tr>
<td>P0001</td>
<td>小米5</td>
<td>1000</td>
<td>2000</td>
</tr>
<tr>
<td>P0002</td>
<td>锤子T1</td>
<td>1000</td>
<td>3000</td>
</tr>
</tbody></table>
<ul>
<li>实现机制<br>通过将关联的条件作为map输出的key，将两表满足join条件的数据并携带数据所来源的文件信息，发往同一个reduce task，在reduce中进行数据的串联</li>
</ul>
<h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.23.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="第一步：数据准备-2"><a href="#第一步：数据准备-2" class="headerlink" title="第一步：数据准备"></a>第一步：数据准备</h3><ul>
<li><p>将文件上传到服务器</p>
</li>
<li><p>将文件上传上传到 HDFS</p>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">hdfs dfs -mkdir /input/reducejoin<br>hdfs dfs -put orders.txt /input/reducejoin<br>hdfs dfs -put product.txt /input/reducejoin<br></code></pre></td></tr></table></figure>

<h3 id="第二步：mapper编写"><a href="#第二步：mapper编写" class="headerlink" title="第二步：mapper编写"></a>第二步：mapper编写</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">JoinMapper</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Mapper</span>&lt;<span class="hljs-title">LongWritable</span>, <span class="hljs-title">Text</span>,<span class="hljs-title">Text</span>,<span class="hljs-title">Text</span>&gt; </span>&#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title">map</span><span class="hljs-params">(LongWritable key, Text value, Context context)</span> <span class="hljs-keyword">throws</span> IOException, InterruptedException </span>&#123;<br>        <span class="hljs-comment">//1.判断数据来自哪个文件</span><br>        FileSplit inputSplit = (FileSplit) context.getInputSplit();<br>        String fileName = inputSplit.getPath().getName();<br>        <span class="hljs-keyword">if</span> (fileName.equals(<span class="hljs-string">&quot;orders.txt&quot;</span>))&#123;<br>            <span class="hljs-comment">//获取pid</span><br>            String[] split = value.toString().split(<span class="hljs-string">&quot;,&quot;</span>);<br>            context.write(<span class="hljs-keyword">new</span> Text(split[<span class="hljs-number">2</span>]),value);<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            <span class="hljs-comment">//获取pid</span><br>            String[] split = value.toString().split(<span class="hljs-string">&quot;,&quot;</span>);<br>            context.write(<span class="hljs-keyword">new</span> Text(split[<span class="hljs-number">0</span>]),value);<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="第三步：reducer编写"><a href="#第三步：reducer编写" class="headerlink" title="第三步：reducer编写"></a>第三步：reducer编写</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">JoinReducer</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Reducer</span>&lt;<span class="hljs-title">Text</span>,<span class="hljs-title">Text</span>,<span class="hljs-title">Text</span>,<span class="hljs-title">Text</span>&gt; </span>&#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">void</span> <span class="hljs-title">reduce</span><span class="hljs-params">(Text key, Iterable&lt;Text&gt; values, Context context)</span> <span class="hljs-keyword">throws</span> IOException, InterruptedException </span>&#123;<br>        String first = <span class="hljs-string">&quot;&quot;</span>;<br>        String second = <span class="hljs-string">&quot;&quot;</span>;<br>        <span class="hljs-keyword">for</span> (Text value : values) &#123;<br>            <span class="hljs-keyword">if</span> (value.toString().startsWith(<span class="hljs-string">&quot;p&quot;</span>))&#123;<br>                first = value.toString();<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                second = value.toString();<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (first.equals(<span class="hljs-string">&quot;&quot;</span>))&#123;<br>            context.write(key,<span class="hljs-keyword">new</span> Text(<span class="hljs-string">&quot;NULL&quot;</span>+<span class="hljs-string">&quot;\t&quot;</span>+second));<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            context.write(key,<span class="hljs-keyword">new</span> Text(first+<span class="hljs-string">&quot;\t&quot;</span>+second));<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="第四步：定义主类-描述-Job-并提交-Job-1"><a href="#第四步：定义主类-描述-Job-并提交-Job-1" class="headerlink" title="第四步：定义主类, 描述 Job 并提交 Job"></a>第四步：定义主类, 描述 Job 并提交 Job</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">JobMain</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">Configured</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">Tool</span> </span>&#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> <span class="hljs-title">run</span><span class="hljs-params">(String[] strings)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        <span class="hljs-comment">//创建一个任务对象</span><br>        Job job = Job.getInstance(<span class="hljs-keyword">super</span>.getConf(), <span class="hljs-string">&quot;ReduceJoin&quot;</span>);<br>        <span class="hljs-comment">//打包到集群上面运行时候，必须要添加以下配置，指定程序的main函数</span><br>        job.setJarByClass(JobMain.class);<br><br>        <span class="hljs-comment">//第一步：设置读取文件的类，将文件解析成key，value对</span><br>        job.setInputFormatClass(TextInputFormat.class);<br>        TextInputFormat.addInputPath(job,<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020/input/reduceJoin&quot;</span>));<br>        <span class="hljs-comment">//第二步：设置mapper类</span><br>        job.setMapperClass(JoinMapper.class);<br>        <span class="hljs-comment">//设置map阶段完成之后的输出类型</span><br>        job.setMapOutputKeyClass(Text.class);<br>        job.setMapOutputValueClass(Text.class);<br>        <span class="hljs-comment">//第三步，第四步，第五步，第六步采用默认方式（分区、排序、规约、分组）</span><br>        <span class="hljs-comment">//第七步：设置reduce类</span><br>        job.setReducerClass(JoinReducer.class);<br>        <span class="hljs-comment">//设置reduce阶段完成之后的输出类型</span><br>        job.setOutputKeyClass(Text.class);<br>        job.setOutputValueClass(Text.class);<br>        <span class="hljs-comment">//第八步：设置输出类以及输出路径</span><br>        job.setOutputFormatClass(TextOutputFormat.class);<br>        TextOutputFormat.setOutputPath(job,<span class="hljs-keyword">new</span> Path(<span class="hljs-string">&quot;hdfs://192.168.127.110:8020/output/reduceJoin_out&quot;</span>));<br>        <span class="hljs-comment">//任务是否执行成功</span><br>        <span class="hljs-keyword">boolean</span> b = job.waitForCompletion(<span class="hljs-keyword">true</span>);<br>        <span class="hljs-keyword">return</span> b?<span class="hljs-number">0</span>:<span class="hljs-number">1</span>;<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>&#123;<br>        Configuration configuration = <span class="hljs-keyword">new</span> Configuration();<br>        <span class="hljs-comment">//启动一个任务</span><br>        <span class="hljs-keyword">int</span> run = ToolRunner.run(configuration, <span class="hljs-keyword">new</span> JobMain(), args);<br>        System.exit(run);<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h3 id="第五步：打成jar包上传至服务器，并在服务器运行-4"><a href="#第五步：打成jar包上传至服务器，并在服务器运行-4" class="headerlink" title="第五步：打成jar包上传至服务器，并在服务器运行"></a>第五步：打成jar包上传至服务器，并在服务器运行</h3><p><code> hadoop jar /export/softwares/mapReduce-1.0-SNAPSHOT.jar top.igotcha.mapreduce.join.JobMain</code></p>
<p>生成的结果文件如下</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/5.24.png" srcset="/img/loading.gif" lazyload></p>
<hr>
<h1 id="六、Hive"><a href="#六、Hive" class="headerlink" title="六、Hive"></a>六、Hive</h1><h2 id="数据仓库"><a href="#数据仓库" class="headerlink" title="数据仓库"></a>数据仓库</h2><h3 id="概述-9"><a href="#概述-9" class="headerlink" title="概述"></a>概述</h3><p>数据仓库英文名称为<strong>Data Warehouse</strong>，可简写为DW或DWH。数据仓库的目的是<strong>构建面向分析的集成化数据环境</strong>，为企业提供决策支持（Decision Support）。它出于分析性报告和决策支持目的而创建。<br>数据仓库本身并不“生产”任何数据，同时自身也不需要“消费”任何的数据，数据来源于外部，并且开放给外部应用，这也是为什么叫“仓库”，而不叫“工厂”的原因</p>
<h3 id="特征"><a href="#特征" class="headerlink" title="特征"></a>特征</h3><p>数据仓库是<strong>面向主题</strong>的（Subject-Oriented ）、<strong>集成</strong>的（Integrated）、<strong>非易失</strong>的（Non-Volatile）和<strong>时变</strong>的（Time-Variant ）数据集合，用以支持管理决策。</p>
<h4 id="面向主题"><a href="#面向主题" class="headerlink" title="面向主题"></a>面向主题</h4><p>传统数据库中，最大的特点是面向应用进行数据的组织，各个业务系统可能是相互分离的。而数据仓库则是面向主题的。<strong>主题是一个抽象的概念，是较高层次上企业信息系统中的数据综合、归类并进行分析利用的抽象</strong>。在逻辑意义上，它是对应企业中某一宏观分析领域所涉及的分析对象。<br>操作型处理（传统数据）对数据的划分并不适用于决策分析。而基于主题组织的数据则不同，它们被划分为各自独立的领域，每个领域有各自的逻辑内涵但互不交叉，在抽象层次上对数据进行完整、一致和准确的描述。一些主题相关的数据通常分布在多个操作型系统中。</p>
<h4 id="集成性"><a href="#集成性" class="headerlink" title="集成性"></a>集成性</h4><p>通过对分散、独立、异构的数据库数据进行抽取、清理、转换和汇总便得到了数据仓库的数据，这样保证了数据仓库内的数据关于整个企业的一致性。<br>数据仓库中的综合数据不能从原有的数据库系统直接得到。因此在数据进入数据仓库之前，必然要经过统一与综合，这一步是数据仓库建设中最关键、最复杂的一步，所要完成的工作有：</p>
<ul>
<li>要<strong>统一</strong>源数据中所有<strong>矛盾</strong>之处，如字段的同名异义、异名同义、单位不统一、字长不一致，等等。</li>
<li>进行<strong>数据综合和计算</strong>*。数据仓库中的数据综合工作可以在从原有数据库抽取数据时生成，但许多是在数据仓库内部生成的，即进入数据仓库以后进行综合生成的。</li>
</ul>
<h4 id="非易失性（不可更新性）"><a href="#非易失性（不可更新性）" class="headerlink" title="非易失性（不可更新性）"></a>非易失性（不可更新性）</h4><ul>
<li>操作型数据库主要服务于日常的业务操作，使得数据库需要不断地对数据实时更新，以便迅速获得当前最新数据，不至于影响正常的业务运作。在数据仓库中只要保存过去的业务数据，不需要每一笔业务都实时更新数据仓库，而是根据商业需要每隔一段时间把一批较新的数据导入数据仓库。</li>
<li>数据仓库的数据反映的是<strong>一段相当长的时间内历史数据的内容</strong>，是不同时点的数据库快照的集合，以及基于这些快照进行统计、综合和重组的导出数据。</li>
<li>数据非易失性主要是针对应用而言。数据仓库的用户对数据的操作大多是数据查询或比较复杂的挖掘，一旦数据进入数据仓库以后，一般情况下被较长时间保留。数据仓库中一般有大量的查询操作，但修改和删除操作很少。因此，数据经加工和集成进入数据仓库后是<strong>极少更新</strong>的，通常只需要定期的加载和更新。</li>
</ul>
<h4 id="时变性"><a href="#时变性" class="headerlink" title="时变性"></a>时变性</h4><p>数据仓库包含各种粒度的历史数据。数据仓库中的数据可能与某个特定日期、星期、月份、季度或者年份有关。数据仓库的目的是通过分析企业过去一段时间业务的经营状况，挖掘其中隐藏的模式。虽然数据仓库的用户不能修改数据，但并不是说数据仓库的数据是永远不变的。分析的结果只能反映过去的情况，当业务变化后，挖掘出的模式会失去时效性。因此数据仓库的数据需要更新，以适应决策的需要。从这个角度讲，数据仓库建设是一个项目，更是一个过程 。数据仓库的数据随时间的变化表现在以下几个方面。</p>
<ul>
<li>数据仓库的数据时限一般要远远长于操作型数据的数据时限。</li>
<li>操作型系统存储的是当前数据，而数据仓库中的数据是历史数据。</li>
<li>数据仓库中的数据是按照时间顺序追加的，它们都带有时间属性。</li>
</ul>
<h3 id="数据库与数据仓库的区别"><a href="#数据库与数据仓库的区别" class="headerlink" title="数据库与数据仓库的区别"></a>数据库与数据仓库的区别</h3><p>数据库与数据仓库的区别实际讲的是 OLTP 与 OLAP 的区别。<br><strong>操作型</strong>处理，叫<strong>联机事务处理 OLTP</strong>（On-Line Transaction Processing，），也可以称面向交易的处理系统，它是针对具体业务在数据库联机的日常操作，通常对少数记录进行查询、修改。用户较为关心操作的响应时间、数据的安全性、完整性和并发支持的用户数等问题。传统的数据库系统作为数据管理的主要手段，主要用于操作型处理。<br><strong>分析型</strong>处理，叫<strong>联机分析处理 OLAP</strong>（On-Line Analytical Processing）一般针对某些主题的历史数据进行分析，支持管理决策。</p>
<p>数据仓库的出现，并不是要取代数据库。</p>
<ul>
<li>数据库是面向事务的设计，数据仓库是面向主题设计的。</li>
<li>数据库一般存储业务数据，数据仓库存储的一般是历史数据。</li>
<li>数据库设计是尽量避免冗余，一般针对某一业务应用进行设计，比如一张简单的User表，记录用户名、密码等简单数据即可，符合业务应用，但是不符合分析。数据仓库在设计是有意引入冗余，依照分析需求，分析维度、分析指标进行设计。</li>
<li>数据库是为捕获数据而设计，数据仓库是为分析数据而设计。</li>
</ul>
<p><strong>数据仓库，是在数据库已经大量存在的情况下，为了进一步挖掘数据资源、为了决策需要而产生的，它决不是所谓的“大型数据库”。</strong></p>
<h3 id="数据仓库的架构"><a href="#数据仓库的架构" class="headerlink" title="数据仓库的架构"></a>数据仓库的架构</h3><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/6.1.png" srcset="/img/loading.gif" lazyload></p>
<p>数据仓库的数据来源于不同的源数据，并提供多样的数据应用，数据自下而上流入数据仓库后向上层开放应用，而数据仓库只是中间集成化数据管理的一个平台。<br><strong>源数据层</strong>（ODS） ：此层数据无任何更改，直接沿用外围系统数据结构和数据，不对外开放；为临时存储层，是接口数据的临时存储区域，为后一步的数据处理做准备。<br><strong>数据仓库层</strong>（DW） ：也称为细节层，DW层的数据应该是一致的、准确的、干净的数据，即对源系统数据进行了清洗（去除了杂质）后的数据。<br><strong>数据应用层</strong>（DA或APP） ：前端应用直接读取的数据源；根据报表、专题分析需求而计算生成的数据。</p>
<h3 id="元数据管理"><a href="#元数据管理" class="headerlink" title="元数据管理"></a>元数据管理</h3><p><strong>元数据</strong>（Meta Date），主要记录数据仓库中<strong>模型的定义</strong>、<strong>各层级间的映射关系</strong>、监控数据仓库的<strong>数据状态</strong>及<strong>ETL的任务运行状态</strong>。一般会通过元数据资料库（Metadata Repository）来统一地存储和管理</p>
<p>元数据，其主要目的是<strong>使数据仓库的设计、部署、操作和管理能达成协同和一致</strong>。<br>元数据是数据仓库管理系统的重要组成部分，元数据管理是企业级数据仓库中的关键组件，贯穿数据仓库构建的整个过程，直接影响着数据仓库的构建、使用和维护。</p>
<p>元数据可分为<strong>技术元数据</strong>和<strong>业务元数据</strong>。</p>
<ul>
<li><p>技术元数据为开发和管理数据仓库的IT人员使用，它描述了<strong>与数据仓库开发、管理和维护相关的数据</strong>，包括数据源信息、数据转换描述、数据仓库模型、数据清洗与更新规则、数据映射和访问权限等。</p>
</li>
<li><p>业务元数据为管理层和业务分析人员服务，<strong>从业务角度描述数据</strong>，包括商务术语、数据仓库中有什么数据、数据的位置和数据的可用性等，帮助业务人员更好地理解数据仓库中哪些数据是可用的以及如何使用。<br>由上可见，元数据不仅定义了数据仓库中数据的模式、来源、抽取和转换规则等，而且是整个数据仓库系统运行的基础，元数据把数据仓库系统中各个松散的组件联系起来，组成了一个有机的整体。</p>
</li>
</ul>
<h2 id="概述-10"><a href="#概述-10" class="headerlink" title="概述"></a>概述</h2><p>Hive是基于Hadoop的一个数据仓库工具，可以<strong>将结构化的数据文件映射为一张数据库表</strong>，并提供类SQL查询功能。<br>其本质是<strong>将SQL转换为MapReduce的任务进行运算</strong>，底层由HDFS来提供数据的存储，hive可以理解为一个将SQL转换为MapReduce的任务的工具，甚至更进一步可以说hive就是一个MapReduce的客户端</p>
<h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul>
<li><strong>可扩展</strong><br>Hive可以自由的扩展集群的规模，一般情况下不需要重启服务。</li>
<li><strong>延展性</strong><br>Hive支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。</li>
<li><strong>容错</strong><br>良好的容错性，节点出现问题SQL仍可完成执行。</li>
</ul>
<h3 id="架构-1"><a href="#架构-1" class="headerlink" title="架构"></a>架构</h3><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/6.2.png" srcset="/img/loading.gif" lazyload></p>
<ul>
<li>用户接口： 包括CLI、JDBC/ODBC、WebGUI。其中，CLI(command line interface)为shell命令行；JDBC/ODBC是Hive的JAVA实现，与传统数据库JDBC类似；WebGUI是通过浏览器访问Hive。</li>
<li>元数据存储： 通常是存储在关系数据库如mysql/derby中。Hive 将元数据存储在数据库中。Hive中的元数据包括表的名字，表的列和分区及其属性，表的属性（是否为外部表等），表的数据所在目录等。</li>
<li>解释器、编译器、优化器、执行器: 完成HQL 查询语句从词法分析、语法分析、编译、优化以及查询计划的生成。生成的查询计划存储在HDFS 中，并在随后有MapReduce 调用执行。</li>
</ul>
<h3 id="Hive与Hadoop的关系"><a href="#Hive与Hadoop的关系" class="headerlink" title="Hive与Hadoop的关系"></a>Hive与Hadoop的关系</h3><p>Hive利用HDFS存储数据，利用MapReduce查询分析数据</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/6.3.png" srcset="/img/loading.gif" lazyload></p>
<h2 id="安装-4"><a href="#安装-4" class="headerlink" title="安装"></a>安装</h2><p>选用hive的版本是3.1.0这个release版本，可以兼容对应的hadoop3.x的版本<br>下载地址为：<br><a target="_blank" rel="noopener" href="http://archive.apache.org/dist/hive/hive-3.1.0/apache-hive-3.1.0-bin.tar.gz">http://archive.apache.org/dist/hive/hive-3.1.0/apache-hive-3.1.0-bin.tar.gz</a></p>
<p>下载之后，将安装包上传到<strong>第一台机器</strong>（node01）的/export/softwares目录下面去</p>
<h3 id="第一步：上传并解压安装包"><a href="#第一步：上传并解压安装包" class="headerlink" title="第一步：上传并解压安装包"></a>第一步：上传并解压安装包</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /export/softwares/<br>tar -zxvf apache-hive-3.1.0-bin.tar.gz -C ../servers/<br></code></pre></td></tr></table></figure>

<h3 id="第二步：centos6-9安装mysql"><a href="#第二步：centos6-9安装mysql" class="headerlink" title="第二步：centos6.9安装mysql"></a>第二步：centos6.9安装mysql</h3><ul>
<li><p>在线安装mysql相关的软件包</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">yum install mysql mysql-server mysql-devel<br></code></pre></td></tr></table></figure></li>
<li><p>启动mysql的服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">/etc/init.d/mysqld start<br></code></pre></td></tr></table></figure></li>
<li><p>通过mysql安装自带脚本进行设置</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">/usr/bin/mysql_secure_installation<br></code></pre></td></tr></table></figure>

<ul>
<li>Set root password?     Y  </li>
<li>Remove anonymous users?     Y</li>
<li>Disallow root login remotely?     N</li>
<li>Remove test database and access to it?     N</li>
<li>Reload privilege tables now?     Y</li>
</ul>
</li>
<li><p>进入mysql的客户端然后进行授权</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">mysql -r root -p 123456<br></code></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs mysql">grant all privileges on *.* to &#x27;root&#x27;@&#x27;%&#x27; identified by &#x27;123456&#x27; with grant option;<br>flush privileges;<br></code></pre></td></tr></table></figure></li>
</ul>
<h3 id="第三步：修改hive的配置文件"><a href="#第三步：修改hive的配置文件" class="headerlink" title="第三步：修改hive的配置文件"></a>第三步：修改hive的配置文件</h3><h4 id="修改hive-env-sh"><a href="#修改hive-env-sh" class="headerlink" title="修改hive-env.sh"></a>修改hive-env.sh</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /export/servers/apache-hive-3.1.0-bin/conf<br>cp hive-env.sh.template hive-env.sh<br></code></pre></td></tr></table></figure>

<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sh">HADOOP_HOME=/<span class="hljs-built_in">export</span>/servers/hadoop-3.1.1<br><span class="hljs-built_in">export</span> HIVE_CONF_DIR=/<span class="hljs-built_in">export</span>/servers/apache-hive-3.1.0-bin/conf<br></code></pre></td></tr></table></figure>

<h4 id="修改hive-site-xml"><a href="#修改hive-site-xml" class="headerlink" title="修改hive-site.xml"></a>修改hive-site.xml</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /export/servers/apache-hive-3.1.0-bin/conf<br>vim hive-site.xml<br></code></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt;</span><br><span class="hljs-meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>root<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>123456<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>jdbc:mysql://node01:3306/hive?createDatabaseIfNotExist=true<span class="hljs-symbol">&amp;amp;</span>useSSL=false<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hive.metastore.schema.verification<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>false<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>datanucleus.schema.autoCreateAll<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>node01<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-comment">&lt;!--</span><br><span class="hljs-comment">&lt;property&gt;</span><br><span class="hljs-comment">&lt;name&gt;hive.metastore.uris&lt;/name&gt;</span><br><span class="hljs-comment">&lt;value&gt;thrift://node01:9083&lt;/value&gt;</span><br><span class="hljs-comment">&lt;description&gt;JDBC connect string for a JDBC metastore&lt;/description&gt;</span><br><span class="hljs-comment">&lt;/property&gt;</span><br><span class="hljs-comment">&lt;property&gt;</span><br><span class="hljs-comment">&lt;name&gt;hive.metastore.local&lt;/name&gt;</span><br><span class="hljs-comment">&lt;value&gt;false&lt;/value&gt;</span><br><span class="hljs-comment">&lt;description&gt;this is local store&lt;/description&gt;</span><br><span class="hljs-comment">&lt;/property&gt;</span><br><span class="hljs-comment">--&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br></code></pre></td></tr></table></figure>

<h3 id="第四步：添加mysql的连接驱动包到hive的lib目录下"><a href="#第四步：添加mysql的连接驱动包到hive的lib目录下" class="headerlink" title="第四步：添加mysql的连接驱动包到hive的lib目录下"></a>第四步：添加mysql的连接驱动包到hive的lib目录下</h3><p>hive使用mysql作为元数据存储，必然需要连接mysql数据库，所以需要添加一个mysql的连接驱动包到hive的安装目录下，然后就可以准备启动hive了</p>
<p>将准备好的mysql-connector-java-5.1.38.jar 这个jar包直接上传到/export/servers/apache-hive-3.1.0-bin/lib 这个目录下即可</p>
<h3 id="第五步：配置hive的环境变量"><a href="#第五步：配置hive的环境变量" class="headerlink" title="第五步：配置hive的环境变量"></a>第五步：配置hive的环境变量</h3><p>node01服务器执行以下命令配置hive的环境变量</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">sudo vim /etc/profile<br></code></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs txt">export HIVE_HOME=/export/servers/apache-hive-3.1.0-bin<br>export PATH=:$HIVE_HOME/bin:$PATH<br></code></pre></td></tr></table></figure>



<h2 id="Hive的交互方式"><a href="#Hive的交互方式" class="headerlink" title="Hive的交互方式"></a>Hive的交互方式</h2><h3 id="第一种交互方式：bin-hive"><a href="#第一种交互方式：bin-hive" class="headerlink" title="第一种交互方式：bin/hive"></a>第一种交互方式：bin/hive</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /export/servers/apache-hive-3.1.0-bin/<br>bin/hive<br></code></pre></td></tr></table></figure>

<ul>
<li>创建一个数据库</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> database if <span class="hljs-keyword">not</span> <span class="hljs-keyword">exists</span> mytest;<br></code></pre></td></tr></table></figure>

<h3 id="第二种交互方式：HiveServer2"><a href="#第二种交互方式：HiveServer2" class="headerlink" title="第二种交互方式：HiveServer2"></a>第二种交互方式：HiveServer2</h3><p>hive官方推荐使用hiveserver2的这种交互方式，需要我们启动hiveserver2这个服务端，然后通过客户端去进行连接</p>
<ul>
<li>关闭hive的服务端，在hadoop的配置文件core-site.xml当中添加以下两行配置，然后重启hdfs以及yarn集群</li>
</ul>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.proxyuser.hadoop.hosts<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>*<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.proxyuser.hadoop.groups<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>root<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><br></code></pre></td></tr></table></figure>

<ul>
<li>启动服务端（前台启动命令如下）</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /export/servers/apache-hive-3.1.0-bin/<br>bin/hive --service hiveserver2<br></code></pre></td></tr></table></figure>

<ul>
<li>重新开一个窗口启动客户端进行连接</li>
</ul>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /export/servers/apache-hive-3.1.0-bin<br>bin/beeline<br>!connect jdbc:hive2://node01:10000<br></code></pre></td></tr></table></figure>

<h3 id="第三种交互方式：使用sql语句或者sql脚本进行交互"><a href="#第三种交互方式：使用sql语句或者sql脚本进行交互" class="headerlink" title="第三种交互方式：使用sql语句或者sql脚本进行交互"></a>第三种交互方式：使用sql语句或者sql脚本进行交互</h3><p>不进入hive的客户端直接执行hive的hql语句</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /export/servers/apache-hive-3.1.0-bin<br>bin/hive -e &quot;create database if not exists mytest;&quot;<br></code></pre></td></tr></table></figure>

<p>或者将hql语句写成一个sql脚本然后执行</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /export/servers<br>vim hive.sql<br></code></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> database if <span class="hljs-keyword">not</span> <span class="hljs-keyword">exists</span> mytest;<br>use mytest;<br><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> stu(id <span class="hljs-type">int</span>,name string);<br></code></pre></td></tr></table></figure>

<p>通过hive -f 执行sql脚本</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell">hive -f /export/servers/hive.sql<br></code></pre></td></tr></table></figure>



<h2 id="数据库层面操作"><a href="#数据库层面操作" class="headerlink" title="数据库层面操作"></a>数据库层面操作</h2><h3 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h3><h4 id="创建数据库-1"><a href="#创建数据库-1" class="headerlink" title="创建数据库"></a>创建数据库</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> database if <span class="hljs-keyword">not</span> <span class="hljs-keyword">exists</span> myhive;<br>use myhive;<br></code></pre></td></tr></table></figure>

<blockquote>
<p>hive的表存放位置模式是由hive-site.xml当中的一个属性指定的</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><br><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/user/hive/warehouse<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><br></code></pre></td></tr></table></figure>
</blockquote>
<h4 id="创建数据库并指定位置"><a href="#创建数据库并指定位置" class="headerlink" title="创建数据库并指定位置"></a>创建数据库并指定位置</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> database myhive2 location <span class="hljs-string">&#x27;/myhive2&#x27;</span>;<br></code></pre></td></tr></table></figure>

<h3 id="修改数据库"><a href="#修改数据库" class="headerlink" title="修改数据库"></a>修改数据库</h3><p>可以使用alter database 命令来修改数据库的一些属性。但是<strong>数据库的元数据信息是不可更改的</strong>，包括数据库的名称以及数据库所在的位置</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">alter</span> database myhive2 <span class="hljs-keyword">set</span> dbproperties(<span class="hljs-string">&#x27;createtime&#x27;</span><span class="hljs-operator">=</span><span class="hljs-string">&#x27;20210114&#x27;</span>);<br></code></pre></td></tr></table></figure>

<h3 id="查看数据库详细信息"><a href="#查看数据库详细信息" class="headerlink" title="查看数据库详细信息"></a>查看数据库详细信息</h3><h4 id="查看数据库基本信息"><a href="#查看数据库基本信息" class="headerlink" title="查看数据库基本信息"></a>查看数据库基本信息</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">desc</span> database myhive2;<br></code></pre></td></tr></table></figure>

<h4 id="查看数据库更多详细信息"><a href="#查看数据库更多详细信息" class="headerlink" title="查看数据库更多详细信息"></a>查看数据库更多详细信息</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">desc</span> database extended myhive2;<br></code></pre></td></tr></table></figure>

<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/6.4.png" srcset="/img/loading.gif" lazyload></p>
<h3 id="删除数据库"><a href="#删除数据库" class="headerlink" title="删除数据库"></a>删除数据库</h3><h4 id="删除一个空数据库"><a href="#删除一个空数据库" class="headerlink" title="删除一个空数据库"></a>删除一个空数据库</h4><p><strong>如果数据库下面有数据表，那么就会报错</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">drop</span> database myhive2;<br></code></pre></td></tr></table></figure>

<h4 id="强制删除数据库"><a href="#强制删除数据库" class="headerlink" title="强制删除数据库"></a>强制删除数据库</h4><p><strong>包含数据库下面的表一起删除</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">drop</span> database myhive cascade;<br></code></pre></td></tr></table></figure>

<hr>
<h2 id="数据表层面操作"><a href="#数据表层面操作" class="headerlink" title="数据表层面操作"></a>数据表层面操作</h2><h3 id="创建数据库表"><a href="#创建数据库表" class="headerlink" title="创建数据库表"></a>创建数据库表</h3><h4 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> [<span class="hljs-keyword">EXTERNAL</span>] <span class="hljs-keyword">TABLE</span> [IF <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span>] table_name<br>	[(col_name data_type [COMMENT col_comment], ...)]<br>	[COMMENT table_comment]<br>	[PARTITIONED <span class="hljs-keyword">BY</span> (col_name data_type [COMMENT col_comment], ...)]<br>	[CLUSTERED <span class="hljs-keyword">BY</span> (col_name, col_name, ...)<br>	[SORTED <span class="hljs-keyword">BY</span> (col_name [<span class="hljs-keyword">ASC</span><span class="hljs-operator">|</span><span class="hljs-keyword">DESC</span>], ...)] <span class="hljs-keyword">INTO</span> num_buckets BUCKETS]<br>	[<span class="hljs-type">ROW</span> FORMAT row_format]<br>	[STORED <span class="hljs-keyword">AS</span> file_format]<br>	[LOCATION hdfs_path]<br></code></pre></td></tr></table></figure>

<ul>
<li><p>CREATE TABLE 创建一个指定名字的表。如果相同名字的表已经存在，则抛出异常；用户可以用IF NOT EXISTS 选项来忽略这个异常。</p>
</li>
<li><p>EXTERNAL关键字可以让用户创建一个<strong>外部表</strong>，在建表的同时指定一个指向实际数据的路径（LOCATION）。Hive 创建内部表时，会将数据移动到数据仓库指向的路径；若创建外部表，仅记录数据所在的路径，不对数据的位置做任何改变。在删除表的时候，内部表的元数据和数据会被一起删除，而外部表只删除元数据，不删除数据。</p>
</li>
<li><p>LIKE 允许用户复制现有的表结构，但是不复制数据。</p>
</li>
<li><p>ROW FORMAT DELIMITED [FIELDS TERMINATED BY char] [COLLECTION ITEMS TERMINATED BY char] [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char] | SERDE serde_name [WITH SERDEPROPERTIES (property_name=property_value,property_name=property_value, …)]</p>
<p>用户在建表的时候可以自定义 SerDe 或者使用自带的 SerDe。如果没有指定 ROW FORMAT 或者ROW FORMAT DELIMITED，将会使用自带的 SerDe。在建表的时候，用户还需要为表指定列，用户在指定表的列的同时也会指定自定义的 SerDe，Hive通过 SerDe 确定表的具体的列的数据。</p>
</li>
<li><p>STORED AS SEQUENCEFILE|TEXTFILE|RCFILE  </p>
<p>如果文件数据是纯文本，可以使用 STORED AS TEXTFILE。如果数据需要压缩，使用 STORED AS SEQUENCEFILE。</p>
</li>
<li><p>CLUSTERED BY  </p>
<p>对于每一个表（table）或者分区， Hive可以进一步组织成桶，也就是<strong>说桶是更为细粒度的数据范围划分</strong>。Hive也是 针对某一列进行桶的组织。Hive采用对列值哈希，然后除以桶的个数求余的方式决定该条记录存放在哪个桶当中。<br>把表（或者分区）组织成桶（Bucket）有两个理由：</p>
<ul>
<li>获得更高的查询处理效率。桶为表加上了额外的结构，Hive 在处理有些查询时 能利用这个结构。具体而言，连接两个在（包含连接列的）相同列上划分了桶的表，可以使用 Map 端连接（Map-side join）高效的实现。比如JOIN操作。对于JOIN操作两个表有一个相同的列，如果对这两个表都进行了桶操作。那么将保存相同列值的桶进行JOIN操作就可以，可以大大较少JOIN的数据量。</li>
<li>使取样（sampling）更高效。在处理大规模数据集时，在开发和修改查询的阶段，如果能在数据集的一小部分数据上试运行查询，会带来很多方便。</li>
</ul>
</li>
</ul>
<h4 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs sql">use myhive;<br><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> stu(id <span class="hljs-type">int</span>,name string);<br><span class="hljs-keyword">insert</span> <span class="hljs-keyword">into</span> stu <span class="hljs-keyword">values</span> (<span class="hljs-number">1</span>,&quot;zhangsan&quot;);<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> stu;<br></code></pre></td></tr></table></figure>

<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/6.5.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="数据库表字段类型"><a href="#数据库表字段类型" class="headerlink" title="数据库表字段类型"></a>数据库表字段类型</h4><p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/6.6.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="创建表并指定字段之间的分隔符"><a href="#创建表并指定字段之间的分隔符" class="headerlink" title="创建表并指定字段之间的分隔符"></a>创建表并指定字段之间的分隔符</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> if <span class="hljs-keyword">not</span> <span class="hljs-keyword">exists</span> stu2(id <span class="hljs-type">int</span> ,name string) <span class="hljs-type">row</span> format delimited fields terminated <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;\t&#x27;</span>;<br></code></pre></td></tr></table></figure>



<h4 id="根据查询结果创建表"><a href="#根据查询结果创建表" class="headerlink" title="根据查询结果创建表"></a>根据查询结果创建表</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> stu3 <span class="hljs-keyword">as</span> <span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> stu2; # 通过复制表结构和表内容创建新表<br></code></pre></td></tr></table></figure>

<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/6.7.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="根据已经存在的表结构创建表"><a href="#根据已经存在的表结构创建表" class="headerlink" title="根据已经存在的表结构创建表"></a>根据已经存在的表结构创建表</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> stu4 <span class="hljs-keyword">like</span> stu2;<br></code></pre></td></tr></table></figure>

<hr>
<h3 id="查询表的类型"><a href="#查询表的类型" class="headerlink" title="查询表的类型"></a>查询表的类型</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">desc</span> formatted stu2;<br></code></pre></td></tr></table></figure>

<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/6.8.png" srcset="/img/loading.gif" lazyload></p>
<hr>
<h3 id="修改表"><a href="#修改表" class="headerlink" title="修改表"></a>修改表</h3><h4 id="基本语法"><a href="#基本语法" class="headerlink" title="基本语法"></a>基本语法</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">alter</span> <span class="hljs-keyword">table</span> old_table_name rename <span class="hljs-keyword">to</span> new_table_name;<br></code></pre></td></tr></table></figure>

<h4 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h4><p>把表stu4修改成stu5</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">alter</span> <span class="hljs-keyword">table</span> stu4 rename <span class="hljs-keyword">to</span> stu5;<br></code></pre></td></tr></table></figure>

<hr>
<h3 id="增加-修改列信息"><a href="#增加-修改列信息" class="headerlink" title="增加/修改列信息"></a>增加/修改列信息</h3><h4 id="查询表结构"><a href="#查询表结构" class="headerlink" title="查询表结构"></a>查询表结构</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">desc</span> stu5;<br></code></pre></td></tr></table></figure>

<h4 id="添加列"><a href="#添加列" class="headerlink" title="添加列"></a>添加列</h4> <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">alter</span> <span class="hljs-keyword">table</span> stu5 <span class="hljs-keyword">add</span> columns (sex string);<br></code></pre></td></tr></table></figure>

<h4 id="更新列"><a href="#更新列" class="headerlink" title="更新列"></a>更新列</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">alter</span> <span class="hljs-keyword">table</span> stu5 change <span class="hljs-keyword">column</span> sex sex_new string;<br></code></pre></td></tr></table></figure>

<hr>
<h3 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h3><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">drop</span> <span class="hljs-keyword">table</span> stu5;<br></code></pre></td></tr></table></figure>

<hr>
<h3 id="外部表"><a href="#外部表" class="headerlink" title="外部表"></a>外部表</h3><p>外部表因为是指定其他的hdfs路径的数据加载到表当中来，所以hive表会认为自己不完全独占这份数据，所以<strong>删除hive表的时候，数据仍然存放在hdfs当中，不会删掉</strong></p>
<h4 id="创建外部表"><a href="#创建外部表" class="headerlink" title="创建外部表"></a>创建外部表</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">external</span> <span class="hljs-keyword">table</span> student (s_id string,s_name string,s_birth string , s_sex string ) <span class="hljs-type">row</span> format delimited fields terminated <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;\t&#x27;</span>;<br></code></pre></td></tr></table></figure>

<h4 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h4><ul>
<li><p>将student.csv文件上传至<code>/export/servers/hivedatas</code></p>
</li>
<li><p>加载student.csv文件</p>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">load data <span class="hljs-keyword">local</span> inpath <span class="hljs-string">&#x27;/export/servers/hivedatas/student.csv&#x27;</span> <span class="hljs-keyword">into</span> <span class="hljs-keyword">table</span> student;<br></code></pre></td></tr></table></figure>

<blockquote>
<p>会将linux内文件，复制一份到数据库对应文件夹中</p>
</blockquote>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/6.9.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="加载数据并覆盖已有数据"><a href="#加载数据并覆盖已有数据" class="headerlink" title="加载数据并覆盖已有数据"></a>加载数据并覆盖已有数据</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">load data <span class="hljs-keyword">local</span> inpath <span class="hljs-string">&#x27;/export/servers/hivedatas/student.csv&#x27;</span> overwrite <span class="hljs-keyword">into</span> <span class="hljs-keyword">table</span> student;<br></code></pre></td></tr></table></figure>

<blockquote>
<p>会将linux内文件，复制一份到数据库对应文件夹中</p>
</blockquote>
<h4 id="从hdfs文件系统向表中加载数据"><a href="#从hdfs文件系统向表中加载数据" class="headerlink" title="从hdfs文件系统向表中加载数据"></a>从hdfs文件系统向表中加载数据</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /export/servers/hivedatas<br>hdfs dfs -mkdir -p /hivedatas<br>hdfs dfs -put techer.csv /hivedatas/<br></code></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">load data inpath <span class="hljs-string">&#x27;/hivedatas/techer.csv&#x27;</span> <span class="hljs-keyword">into</span> <span class="hljs-keyword">table</span> teacher;<br></code></pre></td></tr></table></figure>

<blockquote>
<p>需要提前将数据上传到hdfs文件系统，会将hdfs内文件<strong>剪切</strong>到数据库对应文件夹中</p>
</blockquote>
<hr>
<h3 id="分区表"><a href="#分区表" class="headerlink" title="分区表"></a>分区表</h3><p>在大数据中，最常用的一种思想就是<strong>分治</strong>，可以把大的文件切割划分成一个个的小的文件，这样每次操作一个小的文件就会很容易了，同样的道理，在hive当中也是支持这种思想的，可以把大的数据，按照每天，或者每小时进行切分成一个个的小的文件，这样去操作小的文件就会容易很多</p>
<h4 id="创建分区表"><a href="#创建分区表" class="headerlink" title="创建分区表"></a>创建分区表</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> score(s_id string,c_id string, s_score <span class="hljs-type">int</span>) partitioned <span class="hljs-keyword">by</span> (<span class="hljs-keyword">month</span> string) <span class="hljs-type">row</span> format delimited fields terminated <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;\t&#x27;</span>;<br></code></pre></td></tr></table></figure>

<h4 id="创建一个表带多个分区"><a href="#创建一个表带多个分区" class="headerlink" title="创建一个表带多个分区"></a>创建一个表带多个分区</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> score2(s_id string,c_id string, s_score <span class="hljs-type">int</span>) partitioned <span class="hljs-keyword">by</span> (<span class="hljs-keyword">year</span> string,<span class="hljs-keyword">month</span> string,<span class="hljs-keyword">day</span> string) <span class="hljs-type">row</span> format delimited fields terminated <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;\t&#x27;</span>;<br></code></pre></td></tr></table></figure>

<h4 id="加载数据到分区表"><a href="#加载数据到分区表" class="headerlink" title="加载数据到分区表"></a>加载数据到分区表</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">load data <span class="hljs-keyword">local</span> inpath <span class="hljs-string">&#x27;/export/servers/hivedatas/score.csv&#x27;</span> <span class="hljs-keyword">into</span> <span class="hljs-keyword">table</span> score <span class="hljs-keyword">partition</span>(<span class="hljs-keyword">month</span><span class="hljs-operator">=</span><span class="hljs-string">&#x27;201806&#x27;</span>);<br></code></pre></td></tr></table></figure>

<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/6.10.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="加载数据到多分区表"><a href="#加载数据到多分区表" class="headerlink" title="加载数据到多分区表"></a>加载数据到多分区表</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">load data <span class="hljs-keyword">local</span> inpath <span class="hljs-string">&#x27;/export/servers/hivedatas/score.csv&#x27;</span> <span class="hljs-keyword">into</span> <span class="hljs-keyword">table</span> score2 <span class="hljs-keyword">partition</span>(<span class="hljs-keyword">year</span><span class="hljs-operator">=</span><span class="hljs-string">&#x27;2018&#x27;</span>,<span class="hljs-keyword">month</span><span class="hljs-operator">=</span><span class="hljs-string">&#x27;06&#x27;</span>,<span class="hljs-keyword">day</span><span class="hljs-operator">=</span><span class="hljs-string">&#x27;01&#x27;</span>);<br></code></pre></td></tr></table></figure>

<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/6.11.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="多分区表联合查询"><a href="#多分区表联合查询" class="headerlink" title="多分区表联合查询"></a>多分区表联合查询</h4><p><strong>使用 union all</strong></p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> score <span class="hljs-keyword">where</span> <span class="hljs-keyword">month</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;201806&#x27;</span> <span class="hljs-keyword">union</span> <span class="hljs-keyword">all</span> <span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> score <span class="hljs-keyword">where</span> <span class="hljs-keyword">month</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;201806&#x27;</span>;<br></code></pre></td></tr></table></figure>

<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/6.12.png" srcset="/img/loading.gif" lazyload></p>
<h4 id="查看分区"><a href="#查看分区" class="headerlink" title="查看分区"></a>查看分区</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">show</span> partitions score;<br></code></pre></td></tr></table></figure>

<h4 id="添加分区"><a href="#添加分区" class="headerlink" title="添加分区"></a>添加分区</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">alter</span> <span class="hljs-keyword">table</span> score <span class="hljs-keyword">add</span> <span class="hljs-keyword">partition</span>(<span class="hljs-keyword">month</span><span class="hljs-operator">=</span><span class="hljs-string">&#x27;201805&#x27;</span>);<br></code></pre></td></tr></table></figure>

<h4 id="删除分区"><a href="#删除分区" class="headerlink" title="删除分区"></a>删除分区</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">alter</span> <span class="hljs-keyword">table</span> score <span class="hljs-keyword">drop</span> <span class="hljs-keyword">partition</span>(<span class="hljs-keyword">month</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;201806&#x27;</span>);<br></code></pre></td></tr></table></figure>

<hr>
<h3 id="分桶表"><a href="#分桶表" class="headerlink" title="分桶表"></a>分桶表</h3><p>将数据按照指定的字段进行分成多个桶中去，说白了就是将数据按照字段进行划分，可以将数据按照字段划分到多个文件当中去</p>
<ul>
<li><p>开启Hive的分桶功能</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">set</span> hive.enforce.bucketing<span class="hljs-operator">=</span><span class="hljs-literal">true</span>;<br></code></pre></td></tr></table></figure></li>
<li><p>设置Reduce个数</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">set</span> mapreduce.job.reduces<span class="hljs-operator">=</span><span class="hljs-number">3</span>;<br></code></pre></td></tr></table></figure></li>
</ul>
<h4 id="创建桶表"><a href="#创建桶表" class="headerlink" title="创建桶表"></a>创建桶表</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> course (c_id string,c_name string,t_id string) clustered <span class="hljs-keyword">by</span>(c_id) <span class="hljs-keyword">into</span> <span class="hljs-number">3</span> buckets <span class="hljs-type">row</span> format delimited fields terminated <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;\t&#x27;</span>;<br></code></pre></td></tr></table></figure>

<h4 id="数据加载"><a href="#数据加载" class="headerlink" title="数据加载"></a>数据加载</h4><p>桶表的数据加载，由于通过<code>hdfs dfs -put文件</code>或者通过<code>load data</code>无法使用，只能通过<code>insert overwrite创建普通表</code>，并通过<code>insert overwrite</code>的方式将普通表的数据通过查询的方式加载到桶表当中去</p>
<ul>
<li><p>第一步，创建普通表</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> course_common (c_id string,c_name string,t_id string) <span class="hljs-type">row</span> format delimited fields terminated <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;\t&#x27;</span>;<br></code></pre></td></tr></table></figure></li>
<li><p>第二步，普通表中加载数据</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">load data <span class="hljs-keyword">local</span> inpath <span class="hljs-string">&#x27;/export/servers/hivedatas/course.csv&#x27;</span> <span class="hljs-keyword">into</span> <span class="hljs-keyword">table</span> course_common;<br></code></pre></td></tr></table></figure></li>
<li><p>第三步，通过insert overwrite给桶表中加载数据</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">insert</span> overwrite <span class="hljs-keyword">table</span> course <span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> course_common cluster <span class="hljs-keyword">by</span>(c_id);<br></code></pre></td></tr></table></figure></li>
</ul>
<p>操作结果如下：</p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/6.13.png" srcset="/img/loading.gif" lazyload></p>
<p><img src="/2021/01/04/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/6.14.png" srcset="/img/loading.gif" lazyload></p>
<hr>
<h2 id="数据表内层面操作"><a href="#数据表内层面操作" class="headerlink" title="数据表内层面操作"></a>数据表内层面操作</h2><h3 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h3><h4 id="直接向分区表中插入数据"><a href="#直接向分区表中插入数据" class="headerlink" title="直接向分区表中插入数据"></a>直接向分区表中插入数据</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> score3 <span class="hljs-keyword">like</span> score;<br><span class="hljs-keyword">insert</span> <span class="hljs-keyword">into</span> <span class="hljs-keyword">table</span> score3 <span class="hljs-keyword">partition</span>(<span class="hljs-keyword">month</span> <span class="hljs-operator">=</span><span class="hljs-string">&#x27;201807&#x27;</span>) <span class="hljs-keyword">values</span> (<span class="hljs-string">&#x27;001&#x27;</span>,<span class="hljs-string">&#x27;002&#x27;</span>,<span class="hljs-string">&#x27;100&#x27;</span>);<br></code></pre></td></tr></table></figure>

<h4 id="通过查询插入数据"><a href="#通过查询插入数据" class="headerlink" title="通过查询插入数据"></a>通过查询插入数据</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql">load data <span class="hljs-keyword">local</span> inpath <span class="hljs-string">&#x27;/export/servers/hivedatas/score.csv&#x27;</span> overwrite <span class="hljs-keyword">into</span> <span class="hljs-keyword">table</span> score3 <span class="hljs-keyword">partition</span>(<span class="hljs-keyword">month</span><span class="hljs-operator">=</span><span class="hljs-string">&#x27;202101&#x27;</span>);<br></code></pre></td></tr></table></figure>

<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> score4 <span class="hljs-keyword">like</span> score;<br><span class="hljs-keyword">insert</span> overwrite <span class="hljs-keyword">table</span> score4 <span class="hljs-keyword">partition</span>(<span class="hljs-keyword">month</span> <span class="hljs-operator">=</span> <span class="hljs-string">&#x27;202101&#x27;</span>) <span class="hljs-keyword">select</span> s_id,c_id,s_score <span class="hljs-keyword">from</span> score;<br></code></pre></td></tr></table></figure>

<hr>
<h3 id="查询数据"><a href="#查询数据" class="headerlink" title="查询数据"></a>查询数据</h3><h4 id="语法-1"><a href="#语法-1" class="headerlink" title="语法"></a>语法</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> [<span class="hljs-keyword">ALL</span> <span class="hljs-operator">|</span> <span class="hljs-keyword">DISTINCT</span>] select_expr, select_expr, ...<br><span class="hljs-keyword">FROM</span> table_reference<br>[<span class="hljs-keyword">WHERE</span> where_condition]<br>[<span class="hljs-keyword">GROUP</span> <span class="hljs-keyword">BY</span> col_list<br>[<span class="hljs-keyword">HAVING</span> <span class="hljs-keyword">condition</span>]]<br>[CLUSTER <span class="hljs-keyword">BY</span> col_list<span class="hljs-operator">|</span> [DISTRIBUTE <span class="hljs-keyword">BY</span> col_list] [SORT <span class="hljs-keyword">BY</span><span class="hljs-operator">|</span> <span class="hljs-keyword">ORDER</span> <span class="hljs-keyword">BY</span> col_list]]<br>[LIMIT number]<br></code></pre></td></tr></table></figure>

<ul>
<li>order by 会对输入做<strong>全局排序</strong>，因此只有一个reducer，会导致当输入规模较大时，需要较长的计算时间。</li>
<li>sort by不是全局排序，其在数据进入reducer前完成排序。因此，如果用sort by进行排序，并且设置mapred.reduce.tasks&gt;1，则<strong>sort by只保证每个reducer的输出有序，不保证全局有序</strong>。</li>
</ul>
<ol start="3">
<li>distribute by(字段)根据指定的字段将数据<strong>分到不同的reducer</strong>，且分发算法是hash散列。</li>
<li>Cluster by(字段) 除了具有Distribute by的功能外，还会对该字段进行排序。 —&gt; distribute by + sort by</li>
</ol>
<p><strong>因此，如果分桶和sort字段是同一个时，此时， cluster by = distribute by + sort by</strong></p>
<p>分桶表的作用：最大的作用是用来<strong>提高join操作</strong>的效率；</p>
<h4 id="全表查询"><a href="#全表查询" class="headerlink" title="全表查询"></a>全表查询</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> score2;<br></code></pre></td></tr></table></figure>

<h4 id="选择特定列"><a href="#选择特定列" class="headerlink" title="选择特定列"></a>选择特定列</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> s_id ,c_id <span class="hljs-keyword">from</span> score2;<br></code></pre></td></tr></table></figure>

<h4 id="列别名"><a href="#列别名" class="headerlink" title="列别名"></a>列别名</h4><ul>
<li>重命名一个列。</li>
<li>便于计算。</li>
<li>紧跟列名，也可以在列名和别名之间加入关键字<strong>‘AS’</strong></li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> s_id <span class="hljs-keyword">as</span> myid ,c_id <span class="hljs-keyword">from</span> score2;<br></code></pre></td></tr></table></figure>

<h4 id="聚合函数"><a href="#聚合函数" class="headerlink" title="聚合函数"></a>聚合函数</h4><h5 id="求总行数（count）"><a href="#求总行数（count）" class="headerlink" title="求总行数（count）"></a>求总行数（count）</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-built_in">count</span>(<span class="hljs-number">1</span>) <span class="hljs-keyword">from</span> score2;<br></code></pre></td></tr></table></figure>

<h5 id="求分数的最大值（max）"><a href="#求分数的最大值（max）" class="headerlink" title="求分数的最大值（max）"></a>求分数的最大值（max）</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-built_in">max</span>(s_score) <span class="hljs-keyword">from</span> score2;<br></code></pre></td></tr></table></figure>

<h5 id="求分数的最小值（min）"><a href="#求分数的最小值（min）" class="headerlink" title="求分数的最小值（min）"></a>求分数的最小值（min）</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-built_in">min</span>(s_score) <span class="hljs-keyword">from</span> score2;<br></code></pre></td></tr></table></figure>

<h5 id="求分数的总和（sum）"><a href="#求分数的总和（sum）" class="headerlink" title="求分数的总和（sum）"></a>求分数的总和（sum）</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-built_in">sum</span>(s_score) <span class="hljs-keyword">from</span> score2;<br></code></pre></td></tr></table></figure>

<h5 id="求分数的平均值（avg）"><a href="#求分数的平均值（avg）" class="headerlink" title="求分数的平均值（avg）"></a>求分数的平均值（avg）</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-built_in">avg</span>(s_score) <span class="hljs-keyword">from</span> score2;<br></code></pre></td></tr></table></figure>

<h4 id="LIMIT语句"><a href="#LIMIT语句" class="headerlink" title="LIMIT语句"></a>LIMIT语句</h4><ul>
<li>LIMIT子句用于限制返回的行数。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> score2 limit <span class="hljs-number">3</span>;<br></code></pre></td></tr></table></figure>

<h4 id="WHERE语句"><a href="#WHERE语句" class="headerlink" title="WHERE语句"></a>WHERE语句</h4><ul>
<li>使用WHERE 子句，将不满足条件的行过滤掉。</li>
</ul>
<ol start="2">
<li>WHERE 子句紧随 FROM 子句。</li>
</ol>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> score2 <span class="hljs-keyword">where</span> s_score <span class="hljs-operator">&gt;</span> <span class="hljs-number">60</span>;<br></code></pre></td></tr></table></figure>

<h4 id="LIKE-和-RLIKE"><a href="#LIKE-和-RLIKE" class="headerlink" title="LIKE 和 RLIKE"></a>LIKE 和 RLIKE</h4><ul>
<li><p>使用LIKE运算选择类似的值</p>
</li>
<li><p>选择条件可以包含字符或数字:</p>
<ul>
<li>% 代表零个或多个字符(任意个字符)</li>
<li>_ 代表一个字符</li>
</ul>
</li>
<li><p>RLIKE子句是Hive中这个功能的一个扩展，其可以通过Java的正则表达式这个更强大的语言来指定匹配条件</p>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> score2 <span class="hljs-keyword">where</span> s_score <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;8%&#x27;</span>;<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> score2 <span class="hljs-keyword">where</span> s_score <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;_9%&#x27;</span>;<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> score2 <span class="hljs-keyword">where</span> s_score rlike <span class="hljs-string">&#x27;[9]&#x27;</span>;  # 等同于<span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;%9%&#x27;</span><br></code></pre></td></tr></table></figure>

<h4 id="逻辑运算符"><a href="#逻辑运算符" class="headerlink" title="逻辑运算符"></a>逻辑运算符</h4><table>
<thead>
<tr>
<th>操作符</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>AND</td>
<td>逻辑并</td>
</tr>
<tr>
<td>OR</td>
<td>逻辑或</td>
</tr>
<tr>
<td>NOT</td>
<td>逻辑否</td>
</tr>
</tbody></table>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> score2 <span class="hljs-keyword">where</span> s_id <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> (<span class="hljs-string">&#x27;01&#x27;</span>,<span class="hljs-string">&#x27;02&#x27;</span>);<br></code></pre></td></tr></table></figure>



<h4 id="分组查询"><a href="#分组查询" class="headerlink" title="分组查询"></a>分组查询</h4><h5 id="GROUP-BY-语句"><a href="#GROUP-BY-语句" class="headerlink" title="GROUP BY 语句"></a>GROUP BY 语句</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> s_id ,<span class="hljs-built_in">avg</span>(s_score) <span class="hljs-keyword">from</span> score2 <span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> s_id;<br><span class="hljs-keyword">select</span> s_id ,<span class="hljs-built_in">max</span>(s_score) <span class="hljs-keyword">from</span> score2 <span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> s_id;<br></code></pre></td></tr></table></figure>

<h5 id="HAVING-语句"><a href="#HAVING-语句" class="headerlink" title="HAVING 语句"></a>HAVING 语句</h5><ul>
<li>having与where不同点<ul>
<li>where针对<strong>表中的列</strong>发挥作用，查询数据；having针对<strong>查询结果</strong>中的列发挥作用，筛选数据。</li>
<li>where后面不能写分组函数，而having后面可以使用分组函数。</li>
<li>having只用于group by分组统计语句。</li>
</ul>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> s_id ,<span class="hljs-built_in">avg</span>(s_score) <span class="hljs-keyword">from</span> score2 <span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> s_id;<br><span class="hljs-keyword">select</span> s_id ,<span class="hljs-built_in">avg</span>(s_score) avgscore <span class="hljs-keyword">from</span> score2 <span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> s_id <span class="hljs-keyword">having</span> avgscore <span class="hljs-operator">&gt;</span> <span class="hljs-number">85</span>;<br></code></pre></td></tr></table></figure>



<h4 id="JOIN-语句"><a href="#JOIN-语句" class="headerlink" title="JOIN 语句"></a>JOIN 语句</h4><ul>
<li>Hive支持通常的SQL JOIN语句，但是只支持等值连接，不支持非等值连接。</li>
</ul>
<h5 id="内连接"><a href="#内连接" class="headerlink" title="内连接"></a>内连接</h5><ul>
<li>内连接：只有进行连接的两个表中都存在与连接条件相匹配的数据才会被保留下来。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> techer t <span class="hljs-keyword">inner</span> <span class="hljs-keyword">join</span> course c <span class="hljs-keyword">on</span> t.t_id <span class="hljs-operator">=</span> c.t_id;<br></code></pre></td></tr></table></figure>

<h5 id="左外连接"><a href="#左外连接" class="headerlink" title="左外连接"></a>左外连接</h5><ul>
<li>左外连接：JOIN操作符左边表中符合WHERE子句的所有记录将会被返回。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> techer t <span class="hljs-keyword">left</span> <span class="hljs-keyword">join</span> course c <span class="hljs-keyword">on</span> t.t_id <span class="hljs-operator">=</span> c.t_id;<br></code></pre></td></tr></table></figure>

<h5 id="右外连接"><a href="#右外连接" class="headerlink" title="右外连接"></a>右外连接</h5><ul>
<li>右外连接：JOIN操作符右边表中符合WHERE子句的所有记录将会被返回。</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> teacher t <span class="hljs-keyword">right</span> <span class="hljs-keyword">join</span> course c <span class="hljs-keyword">on</span> t.t_id <span class="hljs-operator">=</span> c.t_id;<br></code></pre></td></tr></table></figure>

<h5 id="多表连接"><a href="#多表连接" class="headerlink" title="多表连接"></a>多表连接</h5><ul>
<li>连接 n个表，至少需要n-1个连接条件</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> teacher t <br>	<span class="hljs-keyword">left</span> <span class="hljs-keyword">join</span> course c<br>		<span class="hljs-keyword">on</span> t.t_id <span class="hljs-operator">=</span> c.t_id<br>	<span class="hljs-keyword">left</span> <span class="hljs-keyword">join</span> score s<br>		<span class="hljs-keyword">on</span> s.c_id <span class="hljs-operator">=</span> c.c_id<br>	<span class="hljs-keyword">left</span> <span class="hljs-keyword">join</span> student stu<br>		<span class="hljs-keyword">on</span> s.s_id <span class="hljs-operator">=</span> stu.s_id;<br></code></pre></td></tr></table></figure>



<blockquote>
<p>大多数情况下，Hive会对每对JOIN连接对象启动一个MapReduce任务。</p>
<p>本例中会首先启动一个MapReduce job对表techer和表course进行连接操作，然后会再启动一个MapReduce job将第一个MapReduce job的输出和表score;进行连接操作。</p>
</blockquote>
<h4 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h4><h5 id="全局排序"><a href="#全局排序" class="headerlink" title="全局排序"></a>全局排序</h5><p><strong>Order By：全局排序，一个reduce</strong></p>
<ul>
<li><p>使用 ORDER BY 子句排序</p>
<ul>
<li>ASC（ascend）: 升序（默认）</li>
<li>DESC（descend）: 降序</li>
</ul>
</li>
<li><p>ORDER BY 子句在SELECT语句的结尾。</p>
</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">FROM</span> student s <span class="hljs-keyword">LEFT</span> <span class="hljs-keyword">JOIN</span> score sco <span class="hljs-keyword">ON</span> s.s_id <span class="hljs-operator">=</span> sco.s_id <span class="hljs-keyword">ORDER</span> <span class="hljs-keyword">BY</span> sco.s_score <span class="hljs-keyword">DESC</span>;<br></code></pre></td></tr></table></figure>

<h5 id="多个列排序"><a href="#多个列排序" class="headerlink" title="多个列排序"></a>多个列排序</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> s_id ,<span class="hljs-built_in">avg</span>(s_score) avg <span class="hljs-keyword">from</span> score <span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> s_id <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> s_id,avg;<br></code></pre></td></tr></table></figure>

<h5 id="局部排序"><a href="#局部排序" class="headerlink" title="局部排序"></a>局部排序</h5><p><strong>Sort By：每个MapReduce内部进行排序，对全局结果集来说不是排序。</strong></p>
<ul>
<li>设置reduce个数</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">set</span> mapreduce.job.reduces<span class="hljs-operator">=</span><span class="hljs-number">3</span>;<br></code></pre></td></tr></table></figure>

<ul>
<li>  查看设置reduce个数</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">set</span> mapreduce.job.reduces;<br></code></pre></td></tr></table></figure>

<ul>
<li>查询成绩按照成绩降序排列</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> score sort <span class="hljs-keyword">by</span> s_score;<br></code></pre></td></tr></table></figure>

<ul>
<li>将查询结果导入到文件中（按照成绩降序排列）</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">insert</span> overwrite <span class="hljs-keyword">local</span> directory <span class="hljs-string">&#x27;/export/servers/hivedatas/sort&#x27;</span> <span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> score sort <span class="hljs-keyword">by</span> s_score;<br></code></pre></td></tr></table></figure>

<h5 id="分区排序"><a href="#分区排序" class="headerlink" title="分区排序"></a>分区排序</h5><p><strong>Distribute By：类似MR中partition，进行分区，结合sort by使用。</strong></p>
<blockquote>
<p>注意，Hive要求<strong>DISTRIBUTE BY语句要写在SORT BY语句之前</strong>。<br>对于distribute by进行测试，一定要分配多reduce进行处理，否则无法看到distribute by的效果。</p>
</blockquote>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> score distribute <span class="hljs-keyword">by</span> s_id<br></code></pre></td></tr></table></figure>

<h5 id="CLUSTER-BY"><a href="#CLUSTER-BY" class="headerlink" title="CLUSTER BY"></a>CLUSTER BY</h5><p><strong>当distribute by和sort by字段相同时，可以使用cluster by方式。</strong></p>
<p>cluster by除了具有distribute by的功能外还兼具sort by的功能。但是排序只能是倒序排序，不能指定排序规则为ASC或者DESC。<br>以下两种写法等价</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> score cluster <span class="hljs-keyword">by</span> s_id;<br><span class="hljs-keyword">select</span> <span class="hljs-operator">*</span> <span class="hljs-keyword">from</span> score distribute <span class="hljs-keyword">by</span> s_id sort <span class="hljs-keyword">by</span> s_id;<br></code></pre></td></tr></table></figure>

<hr>
<h2 id="Hive函数"><a href="#Hive函数" class="headerlink" title="Hive函数"></a>Hive函数</h2><h3 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数"></a>内置函数</h3><ul>
<li>查看系统自带的函数</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">show</span> functions;<br></code></pre></td></tr></table></figure>

<ul>
<li>显示自带的函数的用法</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">desc</span> <span class="hljs-keyword">function</span> upper;<br></code></pre></td></tr></table></figure>

<ul>
<li>详细显示自带的函数的用法</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">desc</span> <span class="hljs-keyword">function</span> extended upper;<br></code></pre></td></tr></table></figure>

<ul>
<li>常用内置函数</li>
</ul>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs sql"># 字符串连接函数： concat<br><span class="hljs-keyword">select</span> concat(<span class="hljs-string">&#x27;abc&#x27;</span>,<span class="hljs-string">&#x27;def&#x27;</span>,<span class="hljs-string">&#x27;gh&#x27;</span>);<br>        <br># 带分隔符字符串连接函数： concat_ws<br><span class="hljs-keyword">select</span> concat_ws(<span class="hljs-string">&#x27;,&#x27;</span>,<span class="hljs-string">&#x27;abc&#x27;</span>,<span class="hljs-string">&#x27;def&#x27;</span>,<span class="hljs-string">&#x27;gh&#x27;</span>);<br><br># 类型转换:cast<br><span class="hljs-keyword">select</span> <span class="hljs-built_in">cast</span>(<span class="hljs-number">1.5</span> <span class="hljs-keyword">as</span> <span class="hljs-type">int</span>);<br><br># json解析函数，用来处理json，必须是json格式:get_json_object<br><span class="hljs-keyword">select</span> get_json_object(<span class="hljs-string">&#x27;&#123;&quot;name&quot;:&quot;jack&quot;,&quot;age&quot;:&quot;20&quot;&#125;&#x27;</span>,<span class="hljs-string">&#x27;$.name&#x27;</span>);<br><br># URL解析函数:parse_url<br><span class="hljs-keyword">select</span> parse_url(<span class="hljs-string">&#x27;http://facebook.com/path1/p.php?k1=v1&amp;k2=v2#Ref1&#x27;</span>, <span class="hljs-string">&#x27;HOST&#x27;</span>);<br># 输出facebook.com<br><br># explode：把map集合中每个键值对或数组中的每个元素都单独生成一行的形式<br></code></pre></td></tr></table></figure>

<h3 id="自定义函数"><a href="#自定义函数" class="headerlink" title="自定义函数"></a>自定义函数</h3><ul>
<li><p>Hive 自带了一些函数，比如：max/min等，但是数量有限，自己可以通过自定义UDF来方便的扩展。</p>
</li>
<li><p>当Hive提供的内置函数无法满足业务处理需要时，此时就可以考虑使用用户自定义函数（UDF：user-definedfunction）。</p>
</li>
<li><p>根据用户自定义函数类别分为以下三种：</p>
<ul>
<li>UDF（User-Defined-Function），一进一出</li>
<li>UDAF（User-Defined Aggregation Function），聚集函数，多进一出，类似于： count / max / min</li>
<li>UDTF（User-Defined Table-Generating Functions），一进多出，如 lateral view explore()</li>
</ul>
</li>
<li><p>官方文档地址 <a target="_blank" rel="noopener" href="https://cwiki.apache.org/confluence/display/Hive/HivePlugins">https://cwiki.apache.org/confluence/display/Hive/HivePlugins</a></p>
</li>
</ul>
<ul>
<li><p>编程步骤</p>
<ul>
<li>继承org.apache.hadoop.hive.ql.UDF</li>
<li>需要实现evaluate函数；evaluate函数支持重载；</li>
</ul>
</li>
<li><p>注意事项</p>
<ul>
<li>UDF必须要有返回类型，可以返回null，但是返回类型不能为void；</li>
<li>UDF中常用Text/LongWritable等类型，不推荐使用java类型；</li>
</ul>
</li>
</ul>
<h4 id="UDF-开发实例"><a href="#UDF-开发实例" class="headerlink" title="UDF 开发实例"></a>UDF 开发实例</h4><h5 id="第一步：新建工程，导入Maven依赖"><a href="#第一步：新建工程，导入Maven依赖" class="headerlink" title="第一步：新建工程，导入Maven依赖"></a>第一步：新建工程，导入Maven依赖</h5><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">dependencies</span>&gt;</span><br>	<span class="hljs-comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hive/hive-exec --&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hive<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hive-exec<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.1.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br>	<span class="hljs-comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-common --&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hadoop-common<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.1.1<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">dependencies</span>&gt;</span><br><br><span class="hljs-tag">&lt;<span class="hljs-name">build</span>&gt;</span><br>	<span class="hljs-tag">&lt;<span class="hljs-name">plugins</span>&gt;</span><br>		<span class="hljs-tag">&lt;<span class="hljs-name">plugin</span>&gt;</span><br>			<span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span><br>			<span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>maven-compiler-plugin<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span><br>			<span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>3.0<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><br>			<span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span><br>				<span class="hljs-tag">&lt;<span class="hljs-name">source</span>&gt;</span>1.8<span class="hljs-tag">&lt;/<span class="hljs-name">source</span>&gt;</span><br>				<span class="hljs-tag">&lt;<span class="hljs-name">target</span>&gt;</span>1.8<span class="hljs-tag">&lt;/<span class="hljs-name">target</span>&gt;</span><br>				<span class="hljs-tag">&lt;<span class="hljs-name">encoding</span>&gt;</span>UTF-8<span class="hljs-tag">&lt;/<span class="hljs-name">encoding</span>&gt;</span><br>			<span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span><br>		<span class="hljs-tag">&lt;/<span class="hljs-name">plugin</span>&gt;</span><br>	<span class="hljs-tag">&lt;/<span class="hljs-name">plugins</span>&gt;</span><br><span class="hljs-tag">&lt;/<span class="hljs-name">build</span>&gt;</span><br></code></pre></td></tr></table></figure>

<h5 id="第二步：自定义类继承UDF类"><a href="#第二步：自定义类继承UDF类" class="headerlink" title="第二步：自定义类继承UDF类"></a>第二步：自定义类继承UDF类</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs java"><span class="hljs-comment">// 将字符串第一个字母大写</span><br><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyUDF</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">UDF</span></span>&#123;<br>	<span class="hljs-function"><span class="hljs-keyword">public</span> Text <span class="hljs-title">evaluate</span><span class="hljs-params">(<span class="hljs-keyword">final</span> Text str)</span></span>&#123;<br>		String tmp_str = str.toString();<br>		<span class="hljs-keyword">if</span>(str != <span class="hljs-keyword">null</span> &amp;&amp; !tmp_str.equals(<span class="hljs-string">&quot;&quot;</span>))&#123;<br>			String str_ret = tmp_str.substring(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>).toUpperCase() + tmp_str.substring(<span class="hljs-number">1</span>);<br>			<span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Text(str_ret);<br>		&#125;<br>		<span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Text(<span class="hljs-string">&quot;&quot;</span>);<br>	&#125;<br>&#125;<br></code></pre></td></tr></table></figure>

<h5 id="第三步：项目打包，并上传到hive的lib目录下"><a href="#第三步：项目打包，并上传到hive的lib目录下" class="headerlink" title="第三步：项目打包，并上传到hive的lib目录下"></a>第三步：项目打包，并上传到hive的lib目录下</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell">cd /export/servers/apache-hive-3.1.1-bin/lib<br>mv myudf.jar udf.jar<br></code></pre></td></tr></table></figure>

<h5 id="第四步：添加jar包"><a href="#第四步：添加jar包" class="headerlink" title="第四步：添加jar包"></a>第四步：添加jar包</h5><p>在hive的客户端添加jar包</p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">add</span> jar <span class="hljs-operator">/</span>export<span class="hljs-operator">/</span>servers<span class="hljs-operator">/</span>apache<span class="hljs-operator">-</span>hive<span class="hljs-number">-3.1</span><span class="hljs-number">.1</span><span class="hljs-operator">-</span>bin<span class="hljs-operator">/</span>lib<span class="hljs-operator">/</span>udf.jar;<br></code></pre></td></tr></table></figure>

<h5 id="第五步：设置函数与自定义函数关联"><a href="#第五步：设置函数与自定义函数关联" class="headerlink" title="第五步：设置函数与自定义函数关联"></a>第五步：设置函数与自定义函数关联</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">create</span> temporary <span class="hljs-keyword">function</span> my_upper <span class="hljs-keyword">as</span> <span class="hljs-string">&#x27;top.igotcha.udf.MyUDF&#x27;</span>;<br></code></pre></td></tr></table></figure>

<h5 id="第六步：使用自定义函数"><a href="#第六步：使用自定义函数" class="headerlink" title="第六步：使用自定义函数"></a>第六步：使用自定义函数</h5><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs sql"><span class="hljs-keyword">select</span> my_upper(<span class="hljs-string">&#x27;abc&#x27;</span>);<br></code></pre></td></tr></table></figure>


            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a>
                    
                      <a class="hover-with-bg" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80/">大数据基础</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/Zookeeper/">Zookeeper</a>
                    
                      <a class="hover-with-bg" href="/tags/Hadoop/">Hadoop</a>
                    
                      <a class="hover-with-bg" href="/tags/HDFS/">HDFS</a>
                    
                      <a class="hover-with-bg" href="/tags/MapReduce/">MapReduce</a>
                    
                      <a class="hover-with-bg" href="/tags/Hive/">Hive</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">
                  
                    本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！
                  
                </p>
              
              
                <div class="post-prevnext">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2021/01/11/Java/%E6%A1%86%E6%9E%B6/SpringBoot/SpringBoot%E4%B8%AD%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E7%9A%843%E7%A7%8D%E6%96%B9%E5%BC%8F/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">SpringBoot中异常处理的3种方式</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2020/12/28/Java/Java%E5%AE%B9%E5%99%A8/%E5%AE%B9%E5%99%A8%E6%BA%90%E7%A0%81/">
                        <span class="hidden-mobile">Java 容器</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    

    
      <a id="scroll-top-button" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
    

    
  </main>

  <footer class="text-center mt-5 py-3">
  <div class="footer-content">
    
  </div>
  
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


  

  
</footer>


  <!-- SCRIPTS -->
  
  <script  src="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js" ></script>
<script  src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/img-lazyload.js" ></script>
  



  



  <script  src="https://cdn.jsdelivr.net/npm/tocbot@4.12.0/dist/tocbot.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/anchor-js@4.3.0/anchor.min.js" ></script>



  <script defer src="https://cdn.jsdelivr.net/npm/clipboard@2.0.6/dist/clipboard.min.js" ></script>



  <script  src="/js/local-search.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>


  <script defer src="/js/leancloud.js" ></script>



  <script  src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var title = document.getElementById('subtitle').title;
      
      typing(title)
      
    })(window, document);
  </script>









  <script  src="https://cdn.jsdelivr.net/npm/mermaid@8.8.3/dist/mermaid.min.js" ></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({"theme":"default"});
    }
  </script>




  
    <!-- Baidu Analytics -->
    <script defer>
      var _hmt = _hmt || [];
      (function () {
        var hm = document.createElement("script");
        hm.src = "https://hm.baidu.com/hm.js?cd190160b5401a029cee361d013e32a1";
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(hm, s);
      })();
    </script>
  

  

  

  

  

  





<!-- 主题的启动项 保持在最底部 -->
<script  src="/js/boot.js" ></script>


</body>
</html>
